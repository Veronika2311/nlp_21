{"content": " MassTransit это open source библиотека, разработанная на языке C# для .NET платформы, упрощающая работу с шиной данных, которая используется при построении распределенных приложений и реализации SOA (service oriented architecture). \r\nВ качестве message broker могут выступать RabbitMq, Azure Service Bus или In-Memory менеджер (в случае с In-Memory область видимости ограничивается процессом, в котором проинициализирован экземпляр). Содержание: Команды и события Команды \r\n События \r\n \r\n Контракты сообщений \r\n Роутинг Exchange \r\n Формат сообщения \r\n \r\n Консьюмеры (Consumer) \r\n Конфигурация контейнера DI \r\n Наблюдатели (Observer) \r\n Новое в MassTransit 3.0 \r\n Заключение \r\n Опрос: А какую .NET библиотеку используете вы? \r\n Команды и события \r\nВ библиотеке заложено 2 основных типа сообщений: команды и события. Команды \r\nСигнализируют о необходимости выполнить некое действие. Для наиболее содержательного наименования команды желательно использовать структуру глагол + существительное: \r\nEstimateConnection, SendSms, NotifyCustomerOrderProcessed. \r\nРабота с командами осуществляется с помощью метода Send (интерфейса ISendEndpoint ) и указания получателя endpoint (очереди): Отправка команды private static async Task SendSmsCommand(IBus busControl)\n{\n var command = new SendSmsCommand\n {\n CommandId = Guid.NewGuid(),\n PhoneNumber = \"89031112233\",\n Message = \"Thank you for your reply\"\n };\n\n var endpoint = await busControl.GetSendEndpoint(AppSettings.CommandEndpoint);\n await endpoint.Send(command);\n}\n События \r\nСигнализируют о случившемся событии, которое может быть интересно некоему набору подписчиков (паттерн Observer), которые на эти события реагируют, например: ConnectionEstimated, CallTerminated, SmsSent, CustomerNotified. \r\nРабота с событиями осуществляется с помощью метода Publish (интерфейса IPublishEndpoint ). \r\nВ терминологии заложено и основное различие этих типов сообщений — команда доставляется единственному исполнителю (дабы избежать дублирования выполнения): \r\nИзображение из статьи MassTransit Send vs. Publish \r\nВ то время как событие ориентировано на оповещение n-подписчиков, каждый из которых реагирует на случившееся событие по-своему. \r\nИзображение из статьи MassTransit Send vs. Publish \r\nИными словами, при запущенных n-консьюмеров (от англ. consumer — потребитель, обработчик), обрабатывающих команду, после её публикации только один из них получит сообщение о ней, в то время как сообщение о событии получит каждый. Контракты сообщений \r\nСогласно документации MassTransit, при объявлении контрактов сообщений рекомендуется прибегать к интерфейсам: Контракт : команда на отправку СМС сообщения public interface ISendSms {\n\tGuid CommandId { get; }\n\tstring PhoneNumber { get; }\n\tstring Message { get; }\n}\n \r\nКак упоминалось ранее, отправка команд должна осуществляться исключительно с помощью метода Send (интерфейса IBus) и указания адресата (endpoint). Контракт: событие об успешной отправке СМС сообщения public interface ISmsSent {\n\tGuid EventId { get; }\n\tDateTime SentAtUtc { get; }\t\n}\n \r\nСобытия отправляются с помощью метода Publish. Роутинг \r\nКак распределение сообщений по exchange, так и выбор консьюмеров (о них в этой статье будет рассказано чуть позже) для обработки базируются на runtime типах этих сообщений,- в наименовании используются namespace и имя типа, в случае с generic имя родительского типа и перечень аргументов. Exchange \r\nПри конфигурации receive endpoint ‘a (подключении ранее зарегистрированных консьюмеров) в случае использования в качестве канала доставки сообщений RabbitMq на основании указанных к обработке консьюмерами типов сообщений формируются наименования требуемых exchange, в которые затем эти самые сообщения и будут помещаться. \r\nАналогичные действия на этапе конфигурации send endpoint ‘a выполняются и для команд, для отправки которых также требуются собственные exchange. \r\nНа изображении можно увидеть созданные в рамках моего сценария exchange: \r\nВ том случае, если конфигурируя receive endpoint мы указываем наименование очереди: cfg.ReceiveEndpoint(host, \"play_with_masstransit_queue\", e =&gt; e.LoadFrom(container));\n \r\nто в привязках exchange сообщений можно будет увидеть следующую картину: \r\nИтоговый путь сообщения, тип которого имплементирует ISmsEvent, будет иметь следующий вид: \r\nЕсли же конфигурация осуществляется без указания очереди: cfg.ReceiveEndpoint(host, e=&gt; e.LoadFrom(container));\n \r\nТо имена для последнего exchange и очереди формируются автоматически, а по завершению работы они будут удалены: Формат сообщения \r\nГоворя о формате сообщения, хотелось бы подробнее остановиться на наименовании (или messageType). За его формирование (заголовков urn:message:) ответственна функция GetUrnForType(Type type) . Для примера я добавил для команды ISendSms наследование от ICommand и generic тип: Контракт : команда на отправку СМС сообщения ICommand&lt;string&gt; public interface ICommand&lt;T&gt;\n{\n}\n\npublic interface ISendSms&lt;T&gt; : ICommand&lt;T&gt;\n{\n Guid CommandId { get; }\n string PhoneNumber { get; }\n string Message { get; }\n}\n\nclass SendSmsCommand : ISendSms&lt;string&gt;\n{\n public Guid CommandId { get; set; }\n public string PhoneNumber { get; set; }\n public string Message { get; set; }\n}\n \r\nСформированное сообщение в таком случае будет содержать следующее значение в поле messageType (на основании которого после получения сообщения затем и выбирается ответственный за обработку консьюмер): \"messageType\": [\n \"urn:message:PlayWithMassTransit30.Extension:SendSmsCommand\",\n \"urn:message:PlayWithMassTransit30.Contract.Command:ISendSms[[System:String]]\",\n \"urn:message:PlayWithMassTransit30.Contract.Command:ICommand[[System:String]]\"\n]\n \r\nКроме messageType сообщение содержит информацию о host, которым оно было отправлено: \"host\": {\n \"machineName\": \"DESKTOP-SI9OHUR\",\n \"processName\": \"PlayWithMassTransit30.vshost\",\n \"processId\": 1092,\n \"assembly\": \"PlayWithMassTransit30\",\n \"assemblyVersion\": \"1.0.0.0\",\n \"frameworkVersion\": \"4.0.30319.42000\",\n \"massTransitVersion\": \"3.4.1.808\",\n \"operatingSystemVersion\": \"Microsoft Windows NT 6.2.9200.0\"\n}\n \r\nЗначимую часть payload: \"message\": {\n \"commandId\": \"7388f663-82dc-403a-8bf9-8952f2ff262e\",\n \"phoneNumber\": \"89031112233\",\n \"message\": \"Thank you for your reply\"\n}\n \r\nи иные служебные поля и заголовки. Консьюмеры (Consumer) \r\nКонсьюмер — это класс, который обрабатывает один или несколько типов сообщений, указываемых при объявлении в наследовании интерфейса IConsumer, где T это тип обрабатываемого данным консьюмером сообщения. \r\nПример консьюмера, обрабатывающего команду ISendSms и публикующего событие ISmsSent: SendSmsConsumer: обработчик команды на отправку сообщения public class SendSmsConsumer : IConsumer&lt;ISendSms&lt;string&gt;&gt;\n{\n public SendSmsConsumer(IBusControl busControl)\n {\n _busControl = busControl;\n }\n\n public async Task Consume(ConsumeContext&lt;ISendSms&lt;string&gt;&gt; context)\n {\n var message = context.Message;\n\n Console.WriteLine($\"[IConsumer&lt;ISendSms&gt;] Send sms command consumed\");\n Console.WriteLine($\"[IConsumer&lt;ISendSms&gt;] CommandId: {message.CommandId}\");\n Console.WriteLine($\"[IConsumer&lt;ISendSms&gt;] Phone number: {message.PhoneNumber}\");\n Console.WriteLine($\"[IConsumer&lt;ISendSms&gt;] Message: {message.Message}\");\n\n Console.Write(Environment.NewLine);\n Console.WriteLine(\"Публикация события: Смс сообщение отправлено\");\n await _busControl.SmsSent(DateTime.UtcNow);\n }\n\n private readonly IBus _busControl;\n}\n \r\nПосле того, как мы получили команду на отправку смс сообщения и выполнили требуемые действия, мы формируем и отправляем событие о том, что смс доставлено. \r\nКод отправки сообщений я вынес в отдельный Extension класс над IBusControl, там же находится и имплементация самих сообщений: Методы расширения над IBus для инкапсуляции логики межсистемного взаимодействия public static class BusExtensions\n{\n /// &lt;summary&gt;\n /// Отправка смс сообщения\n /// &lt;/summary&gt;\n /// &lt;param name=\"bus\"&gt;&lt;/param&gt;\n /// &lt;param name=\"host\"&gt;&lt;/param&gt;\n /// &lt;param name=\"phoneNumber\"&gt;&lt;/param&gt;\n /// &lt;param name=\"message\"&gt;&lt;/param&gt;\n /// &lt;returns&gt;&lt;/returns&gt;\n public static async Task SendSms(\n this IBus bus, Uri host, string phoneNumber, string message\n )\n {\n var command = new SendSmsCommand\n {\n CommandId = Guid.NewGuid(),\n PhoneNumber = phoneNumber,\n Message = message\n };\n\n await bus.SendCommand(host, command);\n }\n\n /// &lt;summary&gt;\n /// Публикация события об отправке смс сообщения\n /// &lt;/summary&gt;\n /// &lt;param name=\"bus\"&gt;&lt;/param&gt;\n /// &lt;param name=\"sentAtUtc\"&gt;&lt;/param&gt;\n /// &lt;returns&gt;&lt;/returns&gt;\n public static async Task SmsSent(\n this IBus bus, DateTime sentAtUtc\n )\n {\n var @event = new SmsSentEvent\n {\n EventId = Guid.NewGuid(),\n SentAtUtc = sentAtUtc\n };\n\n await bus.PublishEvent(@event);\n }\n\n /// &lt;summary&gt;\n /// Отправка команды\n /// &lt;/summary&gt;\n /// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n /// &lt;param name=\"bus\"&gt;&lt;/param&gt;\n /// &lt;param name=\"address\"&gt;&lt;/param&gt;\n /// &lt;param name=\"command\"&gt;&lt;/param&gt;\n /// &lt;returns&gt;&lt;/returns&gt;\n private static async Task SendCommand&lt;T&gt;(this IBus bus, Uri address, T command) where T : class\n {\n var endpoint = await bus.GetSendEndpoint(address);\n await endpoint.Send(command);\n }\n\n /// &lt;summary&gt;\n /// Публикация события\n /// &lt;/summary&gt;\n /// &lt;typeparam name=\"T\"&gt;&lt;/typeparam&gt;\n /// &lt;param name=\"bus\"&gt;&lt;/param&gt;\n /// &lt;param name=\"message\"&gt;&lt;/param&gt;\n /// &lt;returns&gt;&lt;/returns&gt;\n private static async Task PublishEvent&lt;T&gt;(this IBus bus, T message) where T : class\n {\n await bus.Publish(message);\n }\n}\n\nclass SendSmsCommand : ISendSms&lt;string&gt;\n{\n public Guid CommandId { get; set; }\n public string PhoneNumber { get; set; }\n public string Message { get; set; }\n}\n\nclass SmsSentEvent : ISmsSent\n{\n public Guid EventId { get; set; }\n public DateTime SentAtUtc { get; set; }\n}\n \r\nНа мой взгляд, данное решение вполне удачно позволяет отделить код бизнес-логики от деталей реализации межсистемного (компонентного) взаимодействия и инкапсулировать их в одном месте. Конфигурация контейнера DI \r\nНа данный момент MassTransit предоставляет возможность использовать следующие популярные контейнеры : Autofac; \r\n Ninject; \r\n StructureMap; \r\n Unity; \r\n Castle Windsor. \r\n \r\nВ случае с UnityContainer потребуется установить nuget package MassTransit.Unity, после чего станет доступен метод расширения LoadFrom: public static class UnityExtensions\n{\n public static void LoadFrom(this IReceiveEndpointConfigurator configurator, IUnityContainer container);\n}\n \r\nПример использования выглядит следующим образом: Конфигурация IBusControl с помощью UnityContainer public static IBusControl GetConfiguredFactory(IUnityContainer container)\n{\n if (container == null)\n {\n throw new ArgumentNullException(nameof(container));\n }\n\n var control = Bus.Factory.CreateUsingRabbitMq(cfg =&gt; {\n var host = cfg.Host(AppSettings.Host, h =&gt; { });\n\n\n // cfg.ReceiveEndpoint(host, e =&gt; e.LoadFrom(container));\n cfg.ReceiveEndpoint(host, \"play_with_masstransit_queue\", e =&gt; e.LoadFrom(container));\n });\n\n control.ConnectConsumeObserver(new ConsumeObserver());\n control.ConnectReceiveObserver(new ReceiveObserver());\n control.ConnectConsumeMessageObserver(new ConsumeObserverSendSmsCommand());\n control.ConnectSendObserver(new SendObserver());\n control.ConnectPublishObserver(new PublishObserver());\n\n return control;\n}\n \r\nВ качестве срока жизни консьюмеров в контейнере документация предлагает использовать ContainerControlledLifetimeManager(). Наблюдатели (Observer) \r\nДля мониторинга процесса обработки сообщений доступно подключение наблюдателей (Observer). Для этого MassTransit предоставляет следующий набор интерфейсов для обработчиков: IReceiveObserver- срабатывает сразу же после получения сообщения и создания RecieveContext; \r\n IConsumeObserver — срабатывает после создания ConsumeContext; \r\n IConsumeMessageObserver&lt;T&gt; — для наблюдения за сообщениями типа T, в методах которого будет доступно строго-типизированное содержимое сообщения; \r\n ISendObserver — для наблюдения за отправляемыми командами; \r\n IPublishObserver — для наблюдения за отправляемыми событиями. \r\n \r\nДля каждого из них интерфейс IBusControl предоставляет собственный метод подключения, выполнение которого должно быть осуществлено непосредственно перед IBusControl.Start(). \r\nВ качестве примера далее представлена реализация ConsumeObserver: Реализация IConsumeObsever public class ConsumeObserver : IConsumeObserver\n{\n public Task PreConsume&lt;T&gt;(ConsumeContext&lt;T&gt; context) where T : class\n {\n Console.WriteLine($\"[ConsumeObserver] PreConsume {context.MessageId}\");\n return Task.CompletedTask;\n }\n\n public Task PostConsume&lt;T&gt;(ConsumeContext&lt;T&gt; context) where T : class\n {\n Console.WriteLine($\"[ConsumeObserver] PostConsume {context.MessageId}\");\n return Task.CompletedTask;\n }\n\n public Task ConsumeFault&lt;T&gt;(ConsumeContext&lt;T&gt; context, Exception exception) where T : class\n {\n Console.WriteLine($\"[ConsumeObserver] ConsumeFault {context.MessageId}\");\n return Task.CompletedTask;\n }\n}\n \r\nЯ не буду приводить код каждого из консьюмеров, т.к. по принципу работы и структуре они схожи. Имплементацию каждого из них можно посмотреть в документации или в исходниках на Github . \r\nИтоговый pipeline получения команды на отправку смс сообщения, её обработки и публикации события о её успешном выполнении выглядит следующим образом: Новое в MassTransit 3.0 \r\nС изменениями, которые коснулись новой версии библиотеки, вы можете ознакомиться в 2-х обзорных статьях автора библиотеки Chris Patterson’а на страницах его блога: MassTransit 3 API Changes и MassTransit v3 Update . Заключение \r\nЗдесь должно было быть сравнение наиболее популярных библиотек для работы с очередями сообщений, однако, я решил оставить это для отдельной статьи. \r\nНадеюсь, мне удалось провести для вас поверхностное знакомство с библиотекой MassTransit, за гранью которого ещё остаются такие интересные вещи, как транзакционность, персистентность (интеграция с NHibernate, MondoDb, EntityFramework), планировщик отправки сообщений (интеграция с Quartz), state machine (Automatonymous и Saga), логирование (Log4Net, NLog), многопоточность и многое другое. \r\nИсходные коды примеров доступны на Github . Используемые материалы: Документация MassTransit . \r\n ", "title": "Опыт использования MassTransit 3.0", "summary": "MassTransit это open source библиотека, разработанная на языке C# для .NET платформы, упрощающая работу с шиной данных, которая используется при построении распределенных приложений и реализации...", "url": "https://habrahabr.ru/post/314080/", "keywords": [".net", "rabbitmq", "masstransit"]}
{"content": " Введение и выбор решения \r\nРано или поздно наступает такой момент в жизни любого сообщества форума, когда для привлечения и удержания людей возникает острая необходимость использования нового инструментария. \r\nИ таким весьма эффективным инструментом является то, что кроется за модным ныне словом геймификация . То есть, использование характерных для игр приемов и подходов в неигровых процессах по привлечению и вовлечению участников сообщества на форуме в создание активного и мощного информационного поля вокруг нашего продукта. \r\nИспользуемый в нашей компании форумный движок XenForo в настоящее время является наиболее популярным и быстро развивающимся. Этот движок по-умолчанию имеет встроенную систему трофеев основанную на собственной, весьма ограниченной, системе критериев. Сама система создания трофеев также имеет ограниченный функционал, например, нет возможности создавать трофей с графическим бейджем, нет возможности создавать скрытые трофеи, и т.д. Для примера приведу скриншоты дефолтной системы трофеев XenForo для трофея Addicted (присваивается в случае достижения 1000 постов): \r\nОпределение критерия для этого трофея выглядит так (таб Award This Trophy If...): \r\nДействительно, вполне возможно создать и использовать геймификацию на основе встроенного инструментария и критериев, но, в конечном счете, это выглядит недостаточно привлекательно и современно. Критериев для получения трофеев также недостаточно. \r\nДвижок XenForo хорош тем, что он имеет весьма серьезное и активное сообщество (имеются и русскоязычные группы), которое постоянно работает над его улучшением. Создана огромная база всевозможных плагинов, стилей, шаблонов и т. д. Они бывают как коммерческие, так и бесплатные. Существуют даже отдельные компании, занимающиеся разработкой и продажей решений для XenForo, например, Brivium . \r\nТаким образом, потратив некоторое время на поиски подходящего решения и запросы сообществу, было определено лучшее на сегодняшний день решение для реализации продвинутой системы трофеев и достижений на платформе XenForo — связка плагинов Master Badge и CTA Criteria . Были опробованы и другие популярные решения, например, Brivium Extra Trophies Awarded , но их функциональность была оценена как недостаточная. \r\nНо вернемся к связке Master Badge и CTA Criteria . Первый плагин представляет собой платное ($35) мощное решение для управления системой достижений и трофеев, а второй плагин — бесплатный увеличитель количества возможных критериев для получения трофея. Оба плагина обновляются нечасто, но в 2016-ом году обновления выходили. С разработчиками легко и просто связаться либо в обсуждении плагина на его странице, либо в приватной переписке. Настройка плагина Master Badge \r\nРазберемся поподробнее с настройкой плагина Master Badge. Первый таб выглядит так: \r\nЗдесь интересна опция «Display user's featured badges in Member Card» и связанная с ней «Featured Badges». В полях ниже можно задать сколько трофеев юзер может отражать на своем Memeber Card в зависимости от своего текущего уровня. Например, для достигнутого 10-го уровня, юзер может на своем Member Card показать 5 заработанных трофеев. Выглядит это вот так: \r\nСледующий таб настройки выглядит так: \r\nТут интерес представляет то, сколько очков нужно набрать до достижения следующего уровня (Points Per Level) и система начисления очков при переходе с уровня на уровень выше (Level Up Options). Имеется даже Level Calculator для вычисления необходимого количества очков для достижения того или иного уровня. \r\nИ третий таб настроек: \r\nТут определяется месторасположение виджетов прогресса (Progress to Next Level) и топа юзеров (Top Level) в сайдбаре форума. Создание системы трофеев \r\nДля начала нужно сказать, что Master Badge определяет две важные сущности — Badge и Trophy. Badge имеет собственные свойства, важнейшее из которых Badge Mode, и может включать в себя трофеи (Trophies). Badge Mode может быть: Visible — все трофеи, входящие в этот Badge, видны. \r\n Step by Step — следующий трофей будет показан только после того, как предыдущий был получен. \r\n Hidden — трофей будет показан только тогда, когда будет получен. \r\n \r\nВнутри Badge мы создаем трофеи. Хотя трофеи можно создавать и не включая их в Badge. В окне создания трофеев имеются три таба. Для нас важны первые два. На первом задается название трофея, его ценность (Trophy Points), его описание, его принадлежность к Badge, его порядок, его иконка: \r\nВторой таб самый важный, здесь задаются критерии получения трофея, и благодаря уже упомянутому плагину CTA Criteria количество этих критериев значительно увеличено, в отличие от умолчательной системы трофеев XenForo. Тут не влезли все возможные критерии, включен только один — достижение 100 лайков: \r\nКритерии для трофея можно комбинировать, что позволяет создавать всевозможные экзотические и редкие трофеи. В итоге формируется определенная структура из Badges и Trophies. Интересной особенностью является также возможность их контроля — выдать трофей определенному пользователю вне очереди, или выдать некий особенный трофей без определенного критерия конкретному пользователю за особые заслуги, можно посмотреть всех пользователей, обладателей трофея, и можно посмотреть иконку трофея: \r\nТаким образом, система позволяет создавать сложные структуры для реализации геймификации на форуме. Вопрос упирается только в фантазию для создания трофеев, и соответствующее графическое оформление иконок трофеев. Подразумевается, что иконки трофеев должны быть выдержаны в едином стиле и выглядеть привлекательно. \r\nНа изображении выше можно видеть следующую тестовую, черновую систему: Бейдж Poster с типом Step-by-Step и трофеями, основанными на критерии количества постов и с соответствующей возрастающей ценностью. \r\n Бейдж Favorite с типом Step-by-Step и трофеями, основанными на критерии количества лайков и с соответствующей возрастающей ценностью. \r\n Бейдж Cool Pleskian с типом Hidden и трофеями за привязку аккаунта к соцсетям, за достижения Ratio (отношение количества лайков к количеству постов) до определенного в критерии уровня (трофей The Most Useful! ) \r\n Бейдж Years of service с типом Step-by-Step и трофеями, основанными на критерии количества дней с момента регистрации на форуме и с соответствующей возрастающей ценностью. \r\n \r\nДополнительно нужно упомянуть следующую техническую деталь. Трофеи и их уровне (Level Points) подсчитываются для пользователей на основе срабатывания соответствующей CronTask, которую при желании можно запустить вручную: Система со стороны обычных пользователей форума \r\nПосле того, как система трофеев настроена и запущена, со стороны пользователей форума она видна вот так: \r\nНа главном меню форума появляется таб Badges с собственными табами Leaderboard и Latest Awarded: \r\nВ профиле каждого пользователя форума так же появляется отдельный таб Badges, где видны его заслуги: \r\nПри этом, пользователь может сам определить, какие трофеи он может разместить под своей аватарой в форумных постах: \r\nВ тредах и постах ваши заслуги будут видны вот так: \r\nпри этом количество позволенных для показа трофеев определяется уровнем пользователя, (Level Points), и зависит от настроек плагина Master Badge, о чем было сказано выше. Факт получения каждого нового трофея пользователь увидит в виде соответствующего Alert в верхнем правом углу форума. О провокационности и результатах \r\nТехнические вопросы реализации безусловно важны, но не менее важная часть системы — ее наполнение. Создать запоминающиеся, креативные и яркие иконки трофеев с не менее зажигательными описаниями очень нетривиальная задача. Как вызвать острое желание пользователя получить тот или иной трофей путем его визуализации и вербализации — тема отдельного исследования. Скажу лишь, что изрядная доля геймерского опыта, озорства, и даже здоровой провокационности тут просто необходима. При этом важно не перейти некоторую грань, чтобы оставаться в рамках политкорректности, религиозной и расовой терпимости. Особенно это важно на форумах с многонациональным и многоконфессиональным составом сообщества. \r\nКак небольшой пример такого подхода могу привести пару трофеев с нашего форума: Когда зарегистрированный пользователь заходит на форум из результатов поиска Google, он получает трофей LMGTFY (Let Me Google This For You) имеющий описание «You know the forum has its own search, right?» и иконку в виде Блица из мультика Зверополис. Если пользователь включил для себя двухфакторную авторизацию, то он получит трофей Better Safe Than Sorry с описанием «Enabled two-factor authentication because why not» и иконкой защищающего профилактического резинового изделия. \r\nПодобный подход, как правило, вызывает позитивную реакцию сообщества, особенно, когда такие трофеи сделаны скрытыми и вручаются пользователям неожиданно для них. \r\nО результатах внедрения этой реализации геймификации с точки зрения заявленных в начале статьи целей говорить пока рано, но тенденция устойчивого роста активности на форуме заметна. Сейчас, после пары месяцев со времени запуска системы, сложно оценить долю геймификации в этом, но по мере накопления статистических данных, ее влияние можно будет попробовать оценить более детально. \r\nЕсли у вас есть опыт по внедрению, оценке и использованию систем геймификации в профильных сообществах, делитесь, пожалуйста в комментариях.", "title": "Геймификация форума на движке XenForo", "summary": " Введение и выбор решения\r\nРано или поздно наступает такой момент в жизни любого сообщества форума, когда для привлечения и удержания людей возникает острая необходимость использования нового...", "url": "https://habrahabr.ru/company/plesk/blog/313732/", "keywords": ["геймификация", "xenforo", "форумные движки", "форум", "привлечение пользователей", "gamification"]}
{"content": " \r\nНа сегодняшний день процедура реализации «failover» в Postgresql является одной из самых простых и интуитивно понятных. Для ее реализации необходимо определиться со сценариями файловера — это залог успешной работы кластера, протестировать его работу. В двух словах — настраивается репликация, чаще всего асинхронная, и в случае отказа текущего мастера, другая нода(standby) становится текущем «мастером», другие ноды standby начинают следовать за новым мастером. \r\nНа сегодняшний день repmgr поддерживает сценарий автоматического Failover — autofailover, что позволяет поддерживать кластер в рабочем состоянии после выхода из строя ноды-мастера без мгновенного вмешательства сотрудника, что немаловажно, так как не происходит большого падения UPTIME. Для уведомлений используем telegram. \r\n Появилась необходимость в связи с развитием внутренних сервисов реализовать систему хранения БД на Postgresql + репликация + балансировка + failover(отказоустойчивость). Как всегда в интернете вроде бы что то и есть, но всё оно устаревшее или на практике не реализуемое в том виде, в котором оно представлено. Было решено представить данное решение, чтобы в будущем у специалистов, решивших реализовать подобную схему было представление как это делается, и чтобы новичкам было легко это реализовать следуя данной инструкции. Постарались описать все как можно подробней, вникнуть во все нюансы и особенности. \r\n Итак, что мы имеем: 5 VM с debian 8,Postgresql 9.6 + repmgr (для управления кластером), балансировка и HA на базе HAPROXY (ПО для обеспечения балансировки и высокой доступности web приложения и баз данных) и легковесного менеджера подключений Pgbouncer, keepalived для миграции ip адреса(VIP) между нодами,5-я witness нода для контроля кластера и предотвращения “split brain” ситуаций, когда не могла быть определена следующая мастер нода после отказа текущего мастера. Уведомления через telegram( без него как без рук). \r\n Пропишем ноды /etc/hosts — для удобства, так как в дальнейшем все будет оперировать с доменными именами. файл /etc/hosts 10.1.1.195 - pghost195\n10.1.1.196 - pghost196\n10.1.1.197 - pghost197\n10.1.1.198 - pghost198\n10.1.1.205 - pghost205\n \r\nVIP 10.1.1.192 — запись, 10.1.1.202 — roundrobin(балансировка/только чтение). Установка Postgresql 9.6 pgbouncer haproxy repmgr \r\nСтавим на все ноды Установка Postgresql-9.6 и repmgr debian 8 touch /etc/apt/sources.list.d/pgdg.list\necho “deb http://apt.postgresql.org/pub/repos/apt/ jessie-pgdg main” &gt; /etc/apt/sources.list.d/pgdg.list\nwget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | apt-key add -\napt-get update\nwget http://ftp.ru.debian.org/debian/pool/main/p/pkg-config/pkg-config_0.28-1_amd64.deb\ndpkg -i pkg-config_0.28-1_amd64.deb\napt-get install postgresql-9.6-repmgr libevent-dev -y\n \r\nОтключаем автозапуск Postgresql при старте системы — всеми процессами будет управлять пользователь postgres. Так же это необходимо, для того, чтобы бы не было ситуаций, когда у нас сможет оказаться две мастер-ноды, после восстановления одной после сбоя питания, например. Как отключить автозапуск nano /etc/postgresql/9.6/main/start.conf \nзаменяем auto на manual\n \r\nТак же будем использовать chkconfig для контроля и управления автозапуска. Установка chkconfig apt-get install chkconfig -y \n \r\nСмотрим автозапуск Скрытый текст /sbin/chkconfig --list\n \r\nОтключаем Скрытый текст update-rc.d postgresql disable\n \r\nСмотрим postgresql теперь Скрытый текст /sbin/chkconfig --list postgresql\n \r\nГотово. Идём далее. Настройка ssh соединения без пароля — между всеми нодами(делаем на всех серверах) \r\nНастроим подключения между всеми серверами и к самому себе через пользователя postgres(через пользователя postgres подключается также repmgr). \r\nУстановим пакеты, которые нам понадобятся для работы(сразу ставим) Ставим ssh и rsync apt-get install openssh-server rsync -y\n \r\nДля начала установим ему локальный пароль для postgres (сразу проделаем это на всех нодах). Скрытый текст passwd postgres \n \r\nВведем новый пароль. \r\nОк. \r\nДалее настроим ssh соединение Скрытый текст su postgres\ncd ~\nssh-keygen\n \r\nГенерируем ключ — без пароля. \r\nСтавим ключ на другие ноды Скрытый текст ssh-copy-id -i ~/.ssh/id_rsa.pub postgres@pghost195\nssh-copy-id -i ~/.ssh/id_rsa.pub postgres@pghost196\nssh-copy-id -i ~/.ssh/id_rsa.pub postgres@pghost197\nssh-copy-id -i ~/.ssh/id_rsa.pub postgres@pghost198\nssh-copy-id -i ~/.ssh/id_rsa.pub postgres@pghost205\n \r\nДля того чтобы ssh не спрашивала доверяете ли вы хосту и не выдавала другие предупреждения и ограничения, касающиеся политики безопасности, можем добавить в файл Скрытый текст nano /etc/ssh/ssh_config\n StrictHostKeyChecking no\n UserKnownHostsFile=/dev/null\n \r\nРестартуем ssh. Данная опция удобная когда вы не слишком заботитесь о безопасности, например для тестирования кластера. \r\nПерейдем на ноду 2,3,4 и всё повторим. Теперь мы можем гулять без паролей между нодами для переключения их состояния(назначения нового мастера и standby). Ставим pgbouncer из git \r\nУстановим необходимые пакеты для сборки Скрытый текст apt-get install libpq-dev checkinstall build-essential libpam0g-dev libssl-dev libpcre++-dev libtool automake checkinstall gcc+ git -y \ncd /tmp\n git clone https://github.com/pgbouncer/pgbouncer.git\n cd pgbouncer\ngit submodule init\ngit submodule update\n./autogen.sh\nwget https://github.com/libevent/libevent/releases/download/release-2.0.22-stable/libevent-2.0.22-stable.tar.gz\ntar -xvf libevent-2.0.22-stable.tar.gz\ncd libevent*\n./configure\ncheckinstall\ncd ..\n \r\nЕсли хотите postgresql с PAM авторизацией — то ставим еще дом модуль и при configure ставим --with-pam Скрытый текст ./configure --prefix=/usr/local --with-libevent=libevent-prefix --with-pam\n make -j4\nmkdir -p /usr/local/share/doc;\nmkdir -p /usr/local/share/man;\ncheckinstall\n \r\nСтавим версию — 1.7.2 (на ноябрь 2016 года). \r\nГотово. Видим Скрытый текст Done. The new package has been installed and saved to\n /tmp/pgbouncer/pgbouncer_1.7.2-1_amd64.deb\n You can remove it from your system anytime using: \ndpkg -r pgbouncer_1.7.2-1_amd64.deb \n \r\nОбязательно настроим окружение — добавим переменную PATH=/usr/lib/postgresql/9.6/bin:$PATH(на каждой ноде). \r\nДобавим в файл ~/.bashrc Скрытый текст su postgres\ncd ~\nnano .bashrc\n \r\nВставим код Скрытый текст PATH=$PATH:/usr/lib/postgresql/9.6/bin\nexport PATH\nexport PGDATA=\"$HOME/9.6/main\"\n \r\nСохранимся. \r\nСкопируем файл на .bashrc другие ноды Скрытый текст su postgres\ncd ~\nscp .bashrc postgres@pghost195:/var/lib/postgresql\nscp .bashrc postgres@pghost196:/var/lib/postgresql\nscp .bashrc postgres@pghost197:/var/lib/postgresql\nscp .bashrc postgres@pghost198:/var/lib/postgresql\nscp .bashrc postgres@pghost205:/var/lib/postgresql\n Настройке сервера в качестве мастера(pghost195) \r\nОтредактируем конфиг /etc/postgresql/9.6/main/postgresql.conf — Приводим к виду необходимые опции(просто добавим в конец файла). Скрытый текст listen_addresses='*'\nwal_level = 'hot_standby'\narchive_mode = on\nwal_log_hints = on\nwal_keep_segments = 0\narchive_command = 'cd .'\nmax_replication_slots = 5 # Максимальное количество standby нод, подключенных к мастеру.\nhot_standby = on\nshared_preload_libraries = 'repmgr_funcs, pg_stat_statements' ####подключаемая библиотека repmgr и статистики postgres\nmax_connections = 800\nmax_wal_senders = 10#максимальное количество одновременных подключений от резервных серверов или клиентов потокового резервного копирования\nport = 5433\npg_stat_statements.max = 10000\npg_stat_statements.track = all\n \r\nКак мы видим — будем запускать postgresql на порту 5433 — потому-что дефолтный порт для приложений будем использовать для других целей — а именно для балансировки, проксирования и failover’a. Вы же можете использовать любой порт, как вам удобно. \r\nНастроим файл подключений \r\nnano /etc/postgresql/9.6/main/pg_hba.conf \r\nПриведем к виду Скрытый текст # IPv6 local connections:\nhost all all ::1/128 md5\n\nlocal all postgres peer\nlocal all all peer\nhost all all 127.0.0.1/32 md5\n\n#######################################Тут мы настроили соединения для управления репликацией и управления состоянием нод (MASTER, STAND BY).\nlocal replication repmgr trust\nhost replication repmgr 127.0.0.1/32 trust\nhost replication repmgr 10.1.1.0/24 trust\nlocal repmgr repmgr trust\nhost repmgr repmgr 127.0.0.1/32 trust\nhost repmgr repmgr 10.1.1.0/24 trust\n######################################\nhost all all 0.0.0.0/32 md5 #######Подключение для всех по паролю\n#####################################\n \r\nПрименим права к конфигам, иначе будет ругаться на pg_hba.conf Скрытый текст chown -R -v postgres /etc/postgresql\n \r\nСтартуем postgres(от postgres user). Скрытый текст pg_ctl -D /etc/postgresql/9.6/main --log=/var/log/postgresql/postgres_screen.log start\n \r\nНастройка пользователей и базы на Master-сервере(pghost195). Скрытый текст su postgres \ncd ~\n \r\nСоздадим пользователя repmgr. Скрытый текст psql\n# create role repmgr with superuser noinherit;\n# ALTER ROLE repmgr WITH LOGIN;\n# create database repmgr;\n# GRANT ALL PRIVILEGES on DATABASE repmgr to repmgr;\n# ALTER USER repmgr SET search_path TO repmgr_test, \"$user\", public;\n \r\nСоздадим пользователя test_user с паролем 1234 Скрытый текст create user test_user;\nALTER USER test_user WITH PASSWORD '1234';\n \r\nКонфигурируем repmgr на master Скрытый текст nano /etc/repmgr.conf\n \r\nСодержимое Скрытый текст cluster=etagi_test\nnode=1\nnode_name=node1\nuse_replication_slots=1\nconninfo='host=pghost195 port=5433 user=repmgr dbname=repmgr'\npg_bindir=/usr/lib/postgresql/9.6/bin\n \r\nСохраняемся. \r\nРегистрируем сервер как мастер. Скрытый текст su postgres\nrepmgr -f /etc/repmgr.conf master register\n \r\nСмотрим наш статус Скрытый текст repmgr -f /etc/repmgr.conf cluster show\n \r\nВидим Скрытый текст Role | Name | Upstream | Connection String\n----------+-------|----------|--------------------------------------------------\n* master | node1 | | host=pghost195 port=5433 user=repmgr dbname=repmgr\n \r\nИдем дальше. Настройка слейвов(standby) — pghost196,pghost197,pghost198 \r\nКонфигурируем repmgr на slave1(pghost197) \r\nnano /etc/repmgr.conf — создаем конфиг \r\nСодержимое Скрытый текст cluster=etagi_test\nnode=2\nnode_name=node2\nuse_replication_slots=1\nconninfo='host=pghost196 port=5433 user=repmgr dbname=repmgr'\npg_bindir=/usr/lib/postgresql/9.6/bin\n \r\nСохраняемся. \r\nРегистрируем сервер как standby Скрытый текст su postgres\ncd ~/9.6/\nrm -rf main/*\nrepmgr -h pghost1 -p 5433 -U repmgr -d repmgr -D main -f /etc/repmgr.conf --copy-external-config-files=pgdata --verbose standby clone\npg_ctl -D /var/lib/postgresql/9.6/main --log=/var/log/postgresql/postgres_screen.log start\n \r\nБудут скопированы конфиги на основании которых будет происходит переключение состояний master и standby серверов. \r\nПросмотрим файлы, которые лежат в корне папки /var/lib/postgresql/9.6/main — обязательно должны быть эти файлы. Скрытый текст PG_VERSION backup_label\npg_hba.conf pg_ident.conf postgresql.auto.conf postgresql.conf recovery.conf\n \r\nРегистрируем сервер в кластере Скрытый текст su postgres\nrepmgr -f /etc/repmgr.conf standby register; repmgr -f /etc/repmgr.conf cluster show\nПросмотр состояния кластера\nrepmgr -f /etc/repmgr.conf cluster show\nВидим\n\n&lt;spoiler title=\"\"&gt;\n&lt;source lang=\"bash\"&gt;\nRole | Name | Upstream | Connection String\n----------+-------|----------|--------------------------------------------------\n* master | node195 | | host=pghost195 port=5433 user=repmgr dbname=repmgr\n standby | node196 | node1 | host=pghost196 port=5433 user=repmgr dbname=repmgr\n Настройка второго stand-by — pghost197 Конфигурируем repmgr на pghost197 \r\nnano /etc/repmgr.conf — создаем конфиг \r\nСодержимое Скрытый текст cluster=etagi_test\nnode=3\nnode_name=node3\nuse_replication_slots=1\nconninfo='host=pghost197 port=5433 user=repmgr dbname=repmgr'\npg_bindir=/usr/lib/postgresql/9.6/bin\n \r\nСохраняемся. \r\nРегистрируем сервер как standby Скрытый текст su postgres\ncd ~/9.6/\nrm -rf main/*\nrepmgr -h pghost195 -p 5433 -U repmgr -d repmgr -D main -f /etc/repmgr.conf --copy-external-config-files=pgdata --verbose standby clone\n \r\nили Скрытый текст repmgr -D /var/lib/postgresql/9.6/main -f /etc/repmgr.conf -d repmgr -p 5433 -U repmgr -R postgres --verbose --force --rsync-only --copy-external-config-files=pgdata standby clone -h pghost195\n \r\nДанная команда с опцией -r/--rsync-only — используется в некоторых случаях, например, когда копируемый каталог данных — это каталог данных отказавшего сервера с активным узлом репликации. \r\nТакже будут скопированы конфиги на основании которых будет происходит переключение состояний master и standby серверов. \r\nПросмотрим файлы, которые лежат в корне папки /var/lib/postgresql/9.6/main — обязательно должны быть следующие файлы: Скрытый текст PG_VERSION backup_label\npg_hba.conf pg_ident.conf postgresql.auto.conf postgresql.conf recovery.conf\n \r\nСтартуем postgres(от postgres) Скрытый текст pg_ctl -D /var/lib/postgresql/9.6/main --log=/var/log/postgresql/postgres_screen.log start\n \r\nРегистрируем сервер в кластере Скрытый текст su postgres\nrepmgr -f /etc/repmgr.conf standby register\n \r\nПросмотр состояния кластера Скрытый текст repmgr -f /etc/repmgr.conf cluster show\n \r\nВидим Скрытый текст Role | Name | Upstream | Connection String\n----------+-------|----------|--------------------------------------------------\n* master | node1 | | host=pghost1 port=5433 user=repmgr dbname=repmgr\n standby | node2 | node1 | host=pghost2 port=5433 user=repmgr dbname=repmgr\n standby | node3 | node1 | host=pghost2 port=5433 user=repmgr dbname=re\n Настройка каскадной репликации. \r\nВы также можете настроить каскадную репликацию. Рассмотрим пример. Конфигурируем repmgr на pghost198 от pghost197 \r\nnano /etc/repmgr.conf — создаем конфиг. Содержимое Скрытый текст cluster=etagi_test\nnode=4\nnode_name=node4\nuse_replication_slots=1\nconninfo='host=pghost198 port=5433 user=repmgr dbname=repmgr'\npg_bindir=/usr/lib/postgresql/9.6/bin\nupstream_node=3\n \r\nСохраняемся. Как мы видим, что в upstream_node мы указали node3, которой является pghost197. \r\nРегистрируем сервер как standby от standby Скрытый текст su postgres\ncd ~/9.6/\nrm -rf main/*\nrepmgr -h pghost197 -p 5433 -U repmgr -d repmgr -D main -f /etc/repmgr.conf --copy-external-config-files=pgdata --verbose standby clone\n \r\nСтартуем postgres(от postgres) Скрытый текст pg_ctl -D /var/lib/postgresql/9.6/main --log=/var/log/postgresql/postgres_screen.log start\n \r\nРегистрируем сервер в кластере Скрытый текст su postgres\nrepmgr -f /etc/repmgr.conf standby register\n \r\nПросмотр состояния кластера Скрытый текст repmgr -f /etc/repmgr.conf cluster show\n \r\nВидим Скрытый текст Role | Name | Upstream | Connection String\n----------+-------|----------|--------------------------------------------------\n* master | node1 | | host=pghost195 port=5433 user=repmgr dbname=repmgr\n standby | node2 | node1 | host=pghost196 port=5433 user=repmgr dbname=repmgr\n standby | node3 | node1 | host=pghost197 port=5433 user=repmgr dbname=repmgr\n standby | node4 | node3 | host=pghost198 port=5433 user=repmgr dbname=repmgr\n Настройка Автоматического Failover'а. \r\nИтак мы закончили настройку потоковой репликации. Теперь перейдем к настройка автопереключения — активации нового мастера из stand-by сервера. Для этого необходимо добавить новые секции в файл /etc/repmgr.conf на stand-by серверах. На мастере этого быть не должно! \r\n! Конфиги на standby (slave’s) должны отличаться — как в примере ниже. Выставим разное время(master_responce_timeout)! \r\nДобавляем строки на pghost196 в /etc/repmgr.conf Скрытый текст #######АВТОМАТИЧЕСКИЙ FAILOVER#######ТОЛЬКО НА STAND BY##################\nmaster_response_timeout=20\nreconnect_attempts=5\nreconnect_interval=5\nfailover=automatic\npromote_command='sh /etc/postgresql/failover_promote.sh'\nfollow_command='sh /etc/postgresql/failover_follow.sh'\n#loglevel=NOTICE\n#logfacility=STDERR\n#logfile='/var/log/postgresql/repmgr-9.6.log'\npriority=90 # a value of zero or less prevents the node being promoted to master\n \r\nДобавляем строки на pghost197 в /etc/repmgr.conf Скрытый текст #######АВТОМАТИЧЕСКИЙ FAILOVER#######ТОЛЬКО НА STAND BY##################\nmaster_response_timeout=20\nreconnect_attempts=5\nreconnect_interval=5\nfailover=automatic\npromote_command='sh /etc/postgresql/failover_promote.sh'\nfollow_command='sh /etc/postgresql/failover_follow.sh'\n#loglevel=NOTICE\n#logfacility=STDERR\n#logfile='/var/log/postgresql/repmgr-9.6.log'\npriority=70 # a value of zero or less prevents the node being promoted to master\n \r\nДобавляем строки на pghost198 в /etc/repmgr.conf Скрытый текст #######АВТОМАТИЧЕСКИЙ FAILOVER#######ТОЛЬКО НА STAND BY##################\nmaster_response_timeout=20\nreconnect_attempts=5\nreconnect_interval=5\nfailover=automatic\npromote_command='sh /etc/postgresql/failover_promote.sh'\nfollow_command='sh /etc/postgresql/failover_follow.sh'\n#loglevel=NOTICE\n#logfacility=STDERR\n#logfile='/var/log/postgresql/repmgr-9.6.log'\npriority=50 # a value of zero or less prevents the node being promoted to master\n \r\nКак мы видим все настройки автофейоловера идентичны, разница только в priority. Если 0, то данный Standby никогда не станет Master. Данный параметр будет определять очередность срабатывания failover’a, т.е. меньшее число говорит о большем приоритете, значит после отказа master сервера его функции на себя возьмет pghost197. \r\nТакже необходимо добавить следующие строки в файл /etc/postgresql/9.6/main/postgresql.conf (только на stand-by сервера!!!!!!) Скрытый текст shared_preload_libraries = 'repmgr_funcs'\n \r\nДля запуска демона детектирования автоматического переключения необходимо: Скрытый текст su postgres\nrepmgrd -f /etc/repmgr.conf -p /var/run/postgresql/repmgrd.pid -m -d -v &gt;&gt; /var/log/postgresql/repmgr.log 2&gt;&amp;1\n \r\nПроцесс repmgrd будет запущен как демон. Смотрим Скрытый текст ps aux | grep repmgrd\n \r\nВидим Скрытый текст postgres 2921 0.0 0.0 59760 5000 ? S 16:54 0:00 /usr/lib/postgresql/9.6/bin/repmgrd -f /etc/repmgr.conf -p /var/run/postgresql/repmgrd.pid -m -d -v\npostgres 3059 0.0 0.0 12752 2044 pts/1 S+ 16:54 0:00 grep repmgrd\n \r\nВсё ок. Идём дальше. \r\nПроверим работу автофейловера Скрытый текст su postgres\npsql repmgr\nrepmgr # SELECT * FROM repmgr_etagi_test.repl_nodes ORDER BY id;\n\n\n id | type | upstream_node_id | cluster | name | conninfo | slot_name | priority | active \n----+---------+------------------+------------+-------+---------------------------------------------------+---------------+----------+--------\n 1 | master | | etagi_test | node1 | host=pghost195 port=5433 user=repmgr dbname=repmgr | repmgr_slot_1 | 100 | t\n 2 | standby | 1 | etagi_test | node2 | host=pghost196 port=5433 user=repmgr dbname=repmgr | repmgr_slot_2 | 100 | t\n 3 | standby | 1 | etagi_test | node3 | host=pghost197 port=5433 user=repmgr dbname=repmgr | repmgr_slot_3 | 100 | t\n \r\nПока все нормально — теперь проведем тест. Остановим мастер — pghost195 Скрытый текст su postgres\npg_ctl -D /etc/postgresql/9.6/main -m immediate stop\n \r\nВ логах на pghost196 Скрытый текст tail -f /var/log/postgresql/*\n \r\nВидим Скрытый текст [2016-10-21 16:58:34] [NOTICE] promoting standby\n[2016-10-21 16:58:34] [NOTICE] promoting server using '/usr/lib/postgresql/9.6/bin/pg_ctl -D /var/lib/postgresql/9.6/main promote'\n[2016-10-21 16:58:36] [NOTICE] STANDBY PROMOTE successful\n \r\nВ логах на pghost197 Скрытый текст tail -f /var/log/postgresql/*\n \r\nВидим Скрытый текст 2016-10-21 16:58:39] [NOTICE] node 2 is the best candidate for new master, attempting to follow...\n[2016-10-21 16:58:40] [ERROR] connection to database failed: could not connect to server: Connection refused\n\tIs the server running on host \"pghost195\" (10.1.1.195) and accepting\n\tTCP/IP connections on port 5433?\n\n[2016-10-21 16:58:40] [NOTICE] restarting server using '/usr/lib/postgresql/9.6/bin/pg_ctl -w -D /var/lib/postgresql/9.6/main -m fast restart'\n[2016-10-21 16:58:42] [NOTICE] node 3 now following new upstream node 2\n \r\nВсё работает. У нас новый мастер — pghost196, pghost197,pghost198 — теперь слушает stream от pghost2. Возвращение упавшего мастера в строй! \r\nНельзя просто так взять и вернуть упавший мастер в строй. Но он вернется в качестве слейва. \r\nPostgres должна быть остановлена перед процедурой возвращения. На ноде, которая отказала создаем скрипт. В этом скрипт уже настроено уведомление телеграмм, и настроена проверка по триггеру — если создан файл /etc/postgresql/disabled, то восстановление не произойдет. Так же создадим файл /etc/postgresql/current_master.list с содержимым — именем текущего master. /etc/postgresql/current_master.list pghost196\n \r\nНазовем скрипт «register.sh» и разместим в каталоге /etc/postgresql \r\nСкрипт восстановления ноды в кластер в качестве standby /etc/postgresql/register.sh. \ntrigger=\"/etc/postgresql/disabled\"\nTEXT=\"'`hostname -f`_postgresql_disabled_and_don't_be_started.You_must_delete_file_/etc/postgresql/disabled'\"\nTEXT\nif [ -f \"$trigger\" ]\nthen\n\techo \"Current server is disabled\"\n\tsh /etc/postgresql/telegram.sh $TEXT\nelse\n\npkill repmgrd\npg_ctl stop\nrm -rf /var/lib/postgresql/9.6/main/*;\nmkdir /var/run/postgresql/9.6-main.pg_stat_tmp;\n#repmgr -D /var/lib/postgresql/9.6/main -f /etc/repmgr.conf -d repmgr -p 5433 -U repmgr -R postgres --verbose --force --rsync-only --copy-external-config-files=pgdata standby clone -h $(cat /etc/postgresql/current_master.list);\nrepmgr -h $(cat /etc/postgresql/current_master.list) -p 5433 -U repmgr -d repmgr -D /var/lib/postgresql/9.6/main -f /etc/repmgr.conf --copy-external-config-files=pgdata --verbose standby clone\n/usr/lib/postgresql/9.6/bin/pg_ctl -D /var/lib/postgresql/9.6/main --log=/var/log/postgresql/postgres_screen.log start;\n/bin/sleep 5;\nrepmgr -f /etc/repmgr.conf --force standby register;\necho \"Вывод состояния кластера\";\nrepmgr -f /etc/repmgr.conf cluster show;\nsh /etc/postgresql/telegram.sh $TEXT\nsh /etc/postgresql/repmgrd.sh;\nps aux | grep repmgrd;\nfi\n \r\nКак вы видите у нас также есть в скрипте файл repmgrd.sh и telegram.sh. Они также должны находится в каталоге /etc/postgresql. /etc/postgresql/repmgrd.sh #!/bin/bash\npkill repmgrd\nrm /var/run/postgresql/repmgrd.pid;\nrepmgrd -f /etc/repmgr.conf -p /var/run/postgresql/repmgrd.pid -m -d -v &gt;&gt; /var/log/postgresql/repmgr.log 2&gt;&amp;1;\nps aux | grep repmgrd;\n \r\nСкрипт для отправки в телеграмм. telegram.sh. \nUSERID=\"Юзер_ид_пользователей_телеграм_через_пробел\"\nCLUSTERNAME=\"PGCLUSTER_RIES\"\nKEY=\"Ключ_бота_телеграм\"\nTIMEOUT=\"10\"\nEXEPT_USER=\"root\"\nURL=\"https://api.telegram.org/bot$KEY/sendMessage\"\nDATE_EXEC=\"$(date \"+%d %b %Y %H:%M\")\"\nTMPFILE='/etc/postgresql/ipinfo-$DATE_EXEC.txt'\n IP=$(echo $SSH_CLIENT | awk '{print $1}')\n PORT=$(echo $SSH_CLIENT | awk '{print $3}')\n HOSTNAME=$(hostname -f)\n IPADDR=$(hostname -I | awk '{print $1}')\n curl http://ipinfo.io/$IP -s -o $TMPFILE\n #ORG=$(cat $TMPFILE | jq '.org' | sed 's/\"//g')\n TEXT=$1\n for IDTELEGRAM in $USERID\n do\n curl -s --max-time $TIMEOUT -d \"chat_id=$IDTELEGRAM&amp;disable_web_page_preview=1&amp;text=$TEXT\" $URL &gt; /dev/null\n done\n rm $TMPFILE\n\n \r\nОтредактируем конфиг repmgr на упавшем мастере /etc/repmgr.conf cluster=etagi_cluster1\nnode=1\nnode_name=node195\nuse_replication_slots=1\nconninfo='host=pghost195 port=5433 user=repmgr dbname=repmgr'\npg_bindir=/usr/lib/postgresql/9.6/bin\n#######АВТОМАТИЧЕСКИЙ FAILOVER#######ТОЛЬКО НА STAND BY##################\n\nmaster_response_timeout=20\nreconnect_attempts=5\nreconnect_interval=5\nfailover=automatic\npromote_command='sh /etc/postgresql/failover_promote.sh'\nfollow_command='sh /etc/postgresql/failover_follow.sh'\n#loglevel=NOTICE\n#logfacility=STDERR\n#logfile='/var/log/postgresql/repmgr-9.6.log'\npriority=95 # a value of zero or less prevents the node being promoted to master\n \r\nСохранимся. Теперь запустим наш скрипт, на отказавшей ноде. Не забываем про права(postgres) для файлов. \r\nsh /etc/postgresq/register.sh \r\nУвидим Скрытый текст [2016-10-31 15:19:53] [NOTICE] notifying master about backup completion...\nЗАМЕЧАНИЕ: команда pg_stop_backup завершена, все требуемые сегменты WAL заархивированы\n[2016-10-31 15:19:54] [NOTICE] standby clone (using rsync) complete\n[2016-10-31 15:19:54] [NOTICE] you can now start your PostgreSQL server\n[2016-10-31 15:19:54] [HINT] for example : pg_ctl -D /var/lib/postgresql/9.6/main start\n[2016-10-31 15:19:54] [HINT] After starting the server, you need to register this standby with \"repmgr standby register\"\nсервер запускается\n[2016-10-31 15:19:59] [NOTICE] standby node correctly registered for cluster etagi_cluster1 with id 2 (conninfo: host=pghost196 port=5433 user=repmgr dbname=repmgr)\nВывод состояния кластера\nRole | Name | Upstream | Connection String\n----------+---------|----------|----------------------------------------------------\n* standby | node195 | | host=pghost195 port=5433 user=repmgr dbname=repmgr\n master | node196 | node195 | host=pghost197 port=5433 user=repmgr dbname=repmgr\n standby | node197 | node195 | host=pghost198 port=5433 user=repmgr dbname=repmgr\n standby | node198 | node195 | host=pghost196 port=5433 user=repmgr dbname=repmgr\npostgres 11317 0.0 0.0 4336 716 pts/0 S+ 15:19 0:00 sh /etc/postgresql/repmgrd.sh\npostgres 11322 0.0 0.0 59548 3632 ? R 15:19 0:00 /usr/lib/postgresql/9.6/bin/repmgrd -f /etc/repmgr.conf -p /var/run/postgresql/repmgrd.pid -m -d -v\npostgres 11324 0.0 0.0 12752 2140 pts/0 S+ 15:19 0:00 grep repmgrd\npostgres 11322 0.0 0.0 59548 4860 ? S 15:19 0:00 /usr/lib/postgresql/9.6/bin/repmgrd -f /etc/repmgr.conf -p /var/run/postgresql/repmgrd.pid -m -d -v\npostgres 11327 0.0 0.0 12752 2084 pts/0 S+ 15:19 0:00 grep repmgrd\n \r\nКак мы видим скрипт отработал, мы получили уведомления и увидели состояние кластера. Реализации процедуры Switchover(смены мастера вручную). \r\nДопустим наступила такая ситуация, когда вам необходимо поменять местами мастер и определенный standby. Допустим хотим сделать мастером pghost195 вместо ставшего по фейловеру pghost196, после его восстановления в качестве слейва. Наши шаги. \r\nНа pghost195 Скрытый текст su postgres\nrepmgr -f /etc/repmgr.conf standby switchover \nВидим\n[2016-10-26 15:29:42] [NOTICE] replication slot \"repmgr_slot_1\" deleted on former master\n[2016-10-26 15:29:42] [NOTICE] switchover was successful\n \r\nТеперь нам необходимо дать команду репликам, кроме старого мастера, дать команду на перенос на новый мастер \r\nНа pghost197 Скрытый текст su postgres\nrepmgr -f /etc/repmgr.conf standby follow\nrepmgr -f /etc/repmgr.conf cluster show;\n \r\nВидим что мы следуем за новым мастером. \r\nНа pghost198 — то же самое Скрытый текст su postgres\nrepmgr -f /etc/repmgr.conf standby follow\nrepmgr -f /etc/repmgr.conf cluster show;\n \r\nВидим что мы следуем за новым мастером. \r\nНа pghost196 — он был предыдущим мастером, у которого мы отобрали права Скрытый текст su postgres\nrepmgr -f /etc/repmgr.conf standby follow\n \r\nВидим ошибку Скрытый текст [2016-10-26 15:35:51] [ERROR] Slot 'repmgr_slot_2' already exists as an active slot\n \r\nCтопаем pghost196 Скрытый текст pg_ctl stop\n \r\nДля ее исправления идем на phgost195(новый мастер) Скрытый текст su postgres\npsql repmgr\n#select pg_drop_replication_slot('repmgr_slot_2');\n \r\nВидим Скрытый текст pg_drop_replication_slot \n--------------------------\n(1 row)\n \r\nИдем на pghost196, и делаем все по аналогии с пунктом. Создание и использование witness ноды \r\nWitness нода используется для управления кластером, в случае наступления файловера и выступает своего рода арбитром, следит за тем чтобы не наступали конфликтные ситуации при выборе нового мастера. Она не является активной нодой в плане использования как standby сервера, может быть установлена на той же ноде что и postgres или на отдельной ноде. \r\nДобавим еще одну ноду pghost205 для управления кластером( настройка абсолютно аналогична настройке слейва), толь будет отличаться способ копирования: Скрытый текст repmgr -h pghost195 -p 5433 -U repmgr -d repmgr -D main -f /etc/repmgr.conf --force --copy-external-config-files=pgdata --verbose witness create;\nили\nrepmgr -D /var/lib/postgresql/9.6/main -f /etc/repmgr.conf -d repmgr -p 5433 -U repmgr -R postgres --verbose --force --rsync-only --copy-external-config-files=pgdata witness create -h pghost195;\n \r\nУвидим вывод Скрытый текст 2016-10-26 17:27:06] [WARNING] --copy-external-config-files can only be used when executing STANDBY CLONE\n[2016-10-26 17:27:06] [NOTICE] using configuration file \"/etc/repmgr.conf\"\nФайлы, относящиеся к этой СУБД, будут принадлежать пользователю \"postgres\".\nОт его имени также будет запускаться процесс сервера.\nКластер баз данных будет инициализирован с локалью \"ru_RU.UTF-8\".\nКодировка БД по умолчанию, выбранная в соответствии с настройками: \"UTF8\".\nВыбрана конфигурация текстового поиска по умолчанию \"russian\".\n\n\nКонтроль целостности страниц данных отключен.\n\n\nисправление прав для существующего каталога main... ок\nсоздание подкаталогов... ок\nвыбирается значение max_connections... 100\nвыбирается значение shared_buffers... 128MB\nвыбор реализации динамической разделяемой памяти ... posix\nсоздание конфигурационных файлов... ок\nвыполняется подготовительный скрипт ... ок\nвыполняется заключительная инициализация ... ок\nсохранение данных на диске... ок\n\n\nПРЕДУПРЕЖДЕНИЕ: используется проверка подлинности \"trust\" для локальных подключений.\nДругой метод можно выбрать, отредактировав pg_hba.conf или используя ключи -A,\n--auth-local или --auth-host при следующем выполнении initdb.\n\n\nГотово. Теперь вы можете запустить сервер баз данных:\n\n\n /usr/lib/postgresql/9.6/bin/pg_ctl -D main -l logfile start\n\n\nожидание запуска сервера....СООБЩЕНИЕ: система БД была выключена: 2016-10-26 17:27:07 YEKT\nСООБЩЕНИЕ: Защита от наложения мультитранзакций сейчас включена\nСООБЩЕНИЕ: система БД готова принимать подключения\nСООБЩЕНИЕ: процесс запуска автоочистки создан\n готово\nсервер запущен\nWarning: Permanently added 'pghost1,10.1.9.1' (ECDSA) to the list of known hosts.\nreceiving incremental file list\npg_hba.conf\n 1,174 100% 1.12MB/s 0:00:00 (xfr#1, to-chk=0/1)\nСООБЩЕНИЕ: получен SIGHUP, файлы конфигурации перезагружаются\nсигнал отправлен серверу\n[2016-10-26 17:27:10] [NOTICE] configuration has been successfully copied to the witness\n\n/usr/lib/postgresql/9.6/bin/pg_ctl -D /var/lib/postgresql/9.6/main -l logfile start\n \r\nГотово. Идем далее. Правим файл repmgr.conf для witness ноды \r\nОтключаем автоматический файловер на ноде witness nano /etc/repmgr.conf cluster=etagi_test\nnode=5\nnode_name=node5\nuse_replication_slots=1\nconninfo='host=pghost205 port=5499 user=repmgr dbname=repmgr'\npg_bindir=/usr/lib/postgresql/9.6/bin\n\n#######FAILOVER#######ТОЛЬКО НА WITNESS NODE#######\nmaster_response_timeout=50\nreconnect_attempts=3\nreconnect_interval=5\nfailover=manual\npromote_command='repmgr standby promote -f /etc/repmgr.conf'\nfollow_command='repmgr standby follow -f /etc/repmgr.conf'\n \r\nНа witness ноде обязательно изменить порт на 5499 в conninfo. \r\nОбязательно (пере)запускаем repmgrd на всех нодах, кроме мастера Скрытый текст su postgres\npkill repmgr\nrepmgrd -f /etc/repmgr.conf -p /var/run/postgresql/repmgrd.pid -m -d -v &gt;&gt; /var/log/postgresql/repmgr.log 2&gt;&amp;1\nps aux | grep repmgr\n Настройка менеджера соединений Pgbouncer и балансировки через Haproxy. Отказоустойчивости через Keepalived. Настройка Pgbouncer \r\nPgbouncer мы уже установили заранее. Для чего он нужен… Зачем Pgbouncer Мультиплексором соединений. Он выглядит как обычный процесс Postgres, но внутри он управляет очередями запросов что позволяет в разы ускорить работу сервера. Из тысяч запросов поступивших к PgBouncer до базы данных дойдет всего несколько десятков. \n \r\nПерейдем к его настройке. \r\nСкопируем установленный pgbouncer в папку /etc/(для удобства) Скрытый текст cp -r /usr/local/share/doc/pgbouncer /etc\ncd /etc/pgbouncer\n \r\nПриведем к виду файл в nano /etc/pgbouncer/pgbouncer.ini [databases]\n################################ПОДКЛ К БАЗЕ###########\nweb1 = host = localhost port=5433 dbname=web1\nweb2 = host = localhost port=5433 dbname=web2\n#######################################################\n[pgbouncer]\nlogfile = /var/log/postgresql/pgbouncer.log\npidfile = /var/run/postgresql/pgbouncer.pid\nlisten_addr = *\nlisten_port = 6432\nauth_type = trust\nauth_file = /etc/pgbouncer/userlist.txt\n\n;;; Pooler personality questions\n\n; When server connection is released back to pool:\n; session - after client disconnects\n; transaction - after transaction finishes\n; statement - after statement finishes\npool_mode = session\nserver_reset_query = DISCARD ALL\nmax_client_conn = 500\ndefault_pool_size = 30\n \r\nОтредактируем файл /etc/pgbouncer/userlist.txt \"test_user\" \"passworduser\"\n\"postgres\" \"passwordpostgres\"\n\"pgbouncer\" \"fake\"\n \r\nПрименим права Скрытый текст chown -R postgres /etc/pgbouncer\n \r\nПосле редактирования запустим командой как демон (-d) Запуск pgbouncer su postgres\npkill pgbouncer\npgbouncer -d --verbose /etc/pgbouncer/pgbouncer.ini \n \r\nСмотрим порт Скрытый текст netstat -4ln | grep 6432\n \r\nСмотрим лог Скрытый текст tail -f /var/log/postgresql/pgbouncer.log\n \r\nПробуем подключиться. Повторяем все тоже на всех нодах. Установка и настройка Haproxy. \r\nСтавим Xinetd и Haproxy Скрытый текст apt-get install xinetd haproxy -y\n \r\nДобавляем строку в конец файла Скрытый текст nano /etc/services\npgsqlchk 23267/tcp # pgsqlchk\n \r\nУстанавливаем скрипт для проверки состояния postgres — pgsqlcheck nano /opt/pgsqlchk #!/bin/bash\n# /opt/pgsqlchk \n# This script checks if a postgres server is healthy running on localhost. It will\n# return:\n#\n# \"HTTP/1.x 200 OK\\r\" (if postgres is running smoothly)\n#\n# - OR -\n#\n# \"HTTP/1.x 500 Internal Server Error\\r\" (else)\n#\n# The purpose of this script is make haproxy capable of monitoring postgres properly\n#\n#\n# It is recommended that a low-privileged postgres user is created to be used by\n# this script.\n# For eg. create user pgsqlchkusr login password 'pg321';\n#\n \nPGSQL_HOST=\"localhost\"\nPGSQL_PORT=\"5433\"\nPGSQL_DATABASE=\"template1\"\nPGSQL_USERNAME=\"pgsqlchkusr\"\nexport PGPASSWORD=\"pg321\"\n \nTMP_FILE=\"/tmp/pgsqlchk.out\"\nERR_FILE=\"/tmp/pgsqlchk.err\"\n \n \n#\n# We perform a simple query that should return a few results :-p\n#\npsql -h $PGSQL_HOST -p $PGSQL_PORT -U $PGSQL_USERNAME \\\n $PGSQL_DATABASE -c \"show port;\" &gt; $TMP_FILE 2&gt; $ERR_FILE\n \n#\n# Check the output. If it is not empty then everything is fine and we return\n# something. Else, we just do not return anything.\n#\nif [ \"$(/bin/cat $TMP_FILE)\" != \"\" ]\nthen\n # Postgres is fine, return http 200\n /bin/echo -e \"HTTP/1.1 200 OK\\r\\n\"\n /bin/echo -e \"Content-Type: Content-Type: text/plain\\r\\n\"\n /bin/echo -e \"\\r\\n\"\n /bin/echo -e \"Postgres is running.\\r\\n\"\n /bin/echo -e \"\\r\\n\"\nelse\n # Postgres is down, return http 503\n /bin/echo -e \"HTTP/1.1 503 Service Unavailable\\r\\n\"\n /bin/echo -e \"Content-Type: Content-Type: text/plain\\r\\n\"\n /bin/echo -e \"\\r\\n\"\n /bin/echo -e \"Postgres is *down*.\\r\\n\"\n /bin/echo -e \"\\r\\n\"\nfi\n \r\nСоответственно нам необходимо добавить пользователя pgsqlchkusr для проверки состояния postgres Скрытый текст plsq\n#create user pgsqlchkusr;\n#ALTER ROLE pgsqlchkusr WITH LOGIN;\n#ALTER USER pgsqlchkusr WITH PASSWORD 'pg321';\n#\\q\n \r\nДелаем скрипт исполняемым и даем права временных файлам — иначе check не сработает. Скрытый текст chmod +x /opt/pgsqlchk;touch /tmp/pgsqlchk.out; touch /tmp/pgsqlchk.err; chmod 777 /tmp/pgsqlchk.out; chmod 777 /tmp/pgsqlchk.err;\n \r\nСоздаем конфиг файл xinetd для pgsqlchk nano /etc/xinetd.d/pgsqlchk \n# /etc/xinetd.d/pgsqlchk\n# # default: on\n# # description: pqsqlchk\nservice pgsqlchk\n{\n flags = REUSE\n socket_type = stream\n port = 23267\n wait = no\n user = nobody\n server = /opt/pgsqlchk\n log_on_failure += USERID\n disable = no\n only_from = 0.0.0.0/0\n per_source = UNLIMITED\n\n}\n \r\nСохраняемся. Настраиваем haproxy. \r\nРедактируем конфиг — удалим старый и вставим это содержимое. Этот конфиг для первой ноды, на которой крутится мастер, на данный момент допустим, что это pghost195. Соответственно для данного хоста мы сделаем активным в пуле соединений свой-же хост, работающий на порте 6432(через pgbouncer). nano /etc/haproxy/haproxy.cfg \nglobal\nlog 127.0.0.1 local0\nlog 127.0.0.1 local1 notice\n#chroot /usr/share/haproxy\nchroot /var/lib/haproxy\npidfile /var/run/haproxy.pid\n\nuser postgres\ngroup postgres\ndaemon\nmaxconn 20000\ndefaults\nlog global\nmode http\noption tcplog\noption dontlognull\nretries 3\noption redispatch\ntimeout connect 30000ms\ntimeout client 30000ms\ntimeout server 30000ms\n\nfrontend stats-front\nbind *:8080\nmode http\ndefault_backend stats-back\n\nfrontend pxc-onenode-front\nbind *:5432\nmode tcp\ndefault_backend pxc-onenode-back\n\nbackend stats-back\nmode http\nstats uri /\nstats auth admin:adminpassword\n\nbackend pxc-onenode-back\n mode tcp\n balance leastconn\n option httpchk\n default-server port 6432 inter 2s downinter 5s rise 3 fall 2 slowstart 60s maxqueue 128 weight 100\n server pghost195 10.1.1.195:6432 check port 23267 \n \r\nСам порт haproxy для подключения к базе крутится на порте 5432. Админка доступна на порте 8080. Пользователь admin с паролем adminpassword. \r\nРестартим сервисы Скрытый текст /etc/init.d/xinetd restart;\n/etc/init.d/haproxy restart;\n \r\nТоже самое делаем еще на всех нодах. На той ноде, которую вы хотите сделать балансировщиком, например pghost198(запросы на нее будут идти только на чтение) конфиг haproxy приводим к такому виду. nano /etc/haproxy/haproxy.cfg global\nlog 127.0.0.1 local0\nlog 127.0.0.1 local1 notice\n#chroot /usr/share/haproxy\nchroot /var/lib/haproxy\npidfile /var/run/haproxy.pid\nuser postgres\ngroup postgres\ndaemon\nmaxconn 20000\ndefaults\nlog global\nmode http\noption tcplog\noption dontlognull\nretries 3\noption redispatch\ntimeout connect 30000ms\ntimeout client 30000ms\ntimeout server 30000ms\n\nfrontend stats-front\nbind *:8080\nmode http\ndefault_backend stats-back\n\nfrontend pxc-onenode-front\nbind *:5432\nmode tcp\ndefault_backend pxc-onenode-back\n\nbackend stats-back\nmode http\nstats uri /\nstats auth admin:adminpassword\n\nbackend pxc-onenode-back\n mode tcp\n balance roundrobin\n option httpchk\n default-server port 6432 inter 2s downinter 5s rise 3 fall 2 slowstart 60s maxqueue 128 weight 100\n server pghost196 10.1.1.196:6432 check port 23267\n server pghost197 10.1.1.196:6432 check port 23267\n server pghost198 10.1.1.196:6432 check port 23267\n \r\nСтатистику смотри на hostip :8080 Установка keepalived. \r\nKeepalived позволяет использовать виртуальный ip адрес (VIP) и в случае выходы из строя одной из нод(выключение питания или другое событие) ip адрес перейдет на другую ноду. Например у нас будет VIP 10.1.1.192 между нодой pghost195,pghost196,pghost197. Соответвенно при выключение питании на ноде pghost195 нода pghost196 автоматически присвоит себе ip addr 10.1.1.192 и так как она является второй в приоритете на продвижение к роли мастера станет доступной для записи благодаря или haproxy или pgbouncer — тут все зависит от вашего выбора. В нашем сценарии — это Haproxy. \r\nСтавим keepalived Скрытый текст apt-get install keepalived -y\n \r\nНастраиваем keepalived. На всех нодах в /etc/sysctl.conf добавим Скрытый текст net.ipv4.ip_forward=1\n \r\nЗатем Скрытый текст sysctl -p\n \r\nНА 1-ой ноде(pghost195) nano /etc/keepalived/keepalived.conf ! this is who emails will go to on alerts\n notification_email {\n admin@domain.com\n\n ! add a few more email addresses here if you would like\n }\n notification_email_from servers@domain.com\n ! I use the local machine to relay mail\n smtp_server smt.local.domain\n smtp_connect_timeout 30\n ! each load balancer should have a different ID\n ! this will be used in SMTP alerts, so you should make\n ! each router easily identifiable\n lvs_id LVS_HAPROXY-pghost195\n}\n\n}\nvrrp_instance haproxy-pghost195 {\n interface eth0\n state MASTER\n virtual_router_id 192\n priority 150\n ! send an alert when this instance changes state from MASTER to BACKUP\n smtp_alert\n authentication {\n auth_type PASS\n auth_pass passwordforcluster\n }\n track_script {\n chk_http_port\n }\n virtual_ipaddress {\n 10.1.1.192/32 dev eth0\n }\n notify_master \"sh /etc/postgresql/telegram.sh 'MASTER pghost195.etagi.com получил VIP'\" \n notify_backup \"sh /etc/postgresql/telegram.sh 'BACKUP pghost195.etagi.com получил VIP'\"\n notify_fault \"sh /etc/postgresql/telegram.sh 'FAULT pghost195.etagi.com получил VIP'\"\n\n}\n \r\nРестартим \r\n/etc/init.d/keepalived restart \r\nНастраиваем keepalived на 2-ой ноде(pghost196) nano /etc/keepalived/keepalived.conf ! this is who emails will go to on alerts\n notification_email {\n admin@domain.com\n\n ! add a few more email addresses here if you would like\n }\n notification_email_from servers@domain.com\n ! I use the local machine to relay mail\n smtp_server smt.local.domain\n smtp_connect_timeout 30\n ! each load balancer should have a different ID\n ! this will be used in SMTP alerts, so you should make\n ! each router easily identifiable\n lvs_id LVS_HAPROXY-pghost196\n}\n\n}\nvrrp_instance haproxy-pghost196 {\n interface eth0\n state MASTER\n virtual_router_id 192\n priority 80\n ! send an alert when this instance changes state from MASTER to BACKUP\n smtp_alert\n authentication {\n auth_type PASS\n auth_pass passwordforcluster\n }\n track_script {\n chk_http_port\n }\n virtual_ipaddress {\n 10.1.1.192/32 dev eth0\n }\n notify_master \"sh /etc/postgresql/telegram.sh 'MASTER pghost196.etagi.com получил VIP'\" \n notify_backup \"sh /etc/postgresql/telegram.sh 'BACKUP pghost196.etagi.com получил VIP'\"\n notify_fault \"sh /etc/postgresql/telegram.sh 'FAULT pghost196.etagi.com получил VIP'\"\n\n}\n \r\nНастраиваем keepalived на 3-ой ноде(pghost197) nano /etc/keepalived/keepalived.conf ! this is who emails will go to on alerts\n notification_email {\n admin@domain.com\n\n ! add a few more email addresses here if you would like\n }\n notification_email_from servers@domain.com\n ! I use the local machine to relay mail\n smtp_server smt.local.domain\n smtp_connect_timeout 30\n ! each load balancer should have a different ID\n ! this will be used in SMTP alerts, so you should make\n ! each router easily identifiable\n lvs_id LVS_HAPROXY-pghost197\n}\n\n}\nvrrp_instance haproxy-pghost197 {\n interface eth0\n state MASTER\n virtual_router_id 192\n priority 50\n ! send an alert when this instance changes state from MASTER to BACKUP\n smtp_alert\n authentication {\n auth_type PASS\n auth_pass passwordforcluster\n }\n track_script {\n chk_http_port\n }\n virtual_ipaddress {\n 10.1.1.192/32 dev eth0\n }\n notify_master \"sh /etc/postgresql/telegram.sh 'MASTER pghost197.etagi.com получил VIP'\" \n notify_backup \"sh /etc/postgresql/telegram.sh 'BACKUP pghost197.etagi.com получил VIP'\"\n notify_fault \"sh /etc/postgresql/telegram.sh 'FAULT pghost197.etagi.com получил VIP'\"\n\n}\n \r\nРестартим Скрытый текст /etc/init.d/keepalived restart\n \r\nКак мы видим, мы также можем использовать скрипты, например для уведомления при изменении состояния. Смотрим следующую секцию Скрытый текст notify_master \"sh /etc/postgresql/telegram.sh 'MASTER pghost195.etagi.com получил VIP'\" \n notify_backup \"sh /etc/postgresql/telegram.sh 'BACKUP pghost195.etagi.com получил VIP'\"\n notify_fault \"sh /etc/postgresql/telegram.sh 'FAULT pghost195.etagi.com получил VIP'\"\n \r\nТак же из конфига видно что мы настроили VIP на 10.1.8.111 который будет жить на eth0. В случае падения ноды pghost195 он перейдет на pghost196, т.е. подключение мы так же будем настраивать через IP 10.1.1.192. так же установим на pghost197, только изменим vrrp_instance и lvs_id LVS_. \r\nНа нодах pghost196,pghost197 отключим keepalived. Он будет запускаться только после процедуры failover promote, которая описана в файле. Мы указали Скрытый текст promote_command='sh /etc/postgresql/failover_promote.sh'\nfollow_command='sh /etc/postgresql/failover_follow.sh'\n \r\nв файле /etc/repmgr.conf (см. в конфигах выше). \r\nДанные скрипты будут запускаться при возникновении failover ситуации -отказе мастера. \r\npromote_command='sh /etc/postgresql/failover_promote.sh — выпоняет номинированный на master host, \r\nfollow_command='sh /etc/postgresql/failover_follow.sh' — исполняют ноды, которые следуют за мастером. \r\nКонфиги promote_command='sh /etc/postgresql/failover_promote.sh' #!/bin/bash\nCLHOSTS=\"pghost195 pghost196 pghost197 pghost198 pghost205 \"\nrepmgr standby promote -f /etc/repmgr.conf;\necho \"Отправка оповещений\";\nsh /etc/postgresql/failover_notify_master.sh;\necho \"Выводим список необходимых хостов в файл\"\nrepmgr -f /etc/repmgr.conf cluster show | grep node | awk ' {print $7} ' | sed \"s/host=//g\" | sed '/port/d' &gt; /etc/postgresql/cluster_hosts.list\nrepmgr -f /etc/repmgr.conf cluster show | grep FAILED | awk ' {print $6} ' | sed \"s/host=//g\" | sed \"s/&gt;//g\" &gt; /etc/postgresql/failed_host.list\nrepmgr -f /etc/repmgr.conf cluster show | grep master | awk ' {print $7} ' | sed \"s/host=//g\" | sed \"s/&gt;//g\" &gt; /etc/postgresql/current_master.list\nrepmgr -f /etc/repmgr.conf cluster show | grep standby | awk ' {print $7} ' | sed \"s/host=//g\" | sed '/port/d' &gt; /etc/postgresql/standby_host.list\n\n####КОПИРУЮ ИНФО ФАЙЛЫ И ФАЙЛЫ-ТРИГГЕРЫ НА ДРУГИЕ НОДЫ КЛАСТЕРА#####################\nfor CLHOST in $CLHOSTS\ndo\nrsync -arvzSH --include \"*.list\" --exclude \"*\" /etc/\\postgresql/ postgres@$CLHOST:/etc/postgresql/\ndone\n\necho \"Начинаю процедуру восстановления упавшего сервера,если не триггера /etc/postgresql/disabled\"\n\nfor FH in $(cat /etc/postgresql/failed_host.list)\ndo\nssh postgres@$FH &lt;&lt;OFF\nsh /etc/postgresql/register.sh;\necho \"Рестартуем repmgrd на других нодах\"\nsh /etc/postgresql/repmgrd.sh;\nsh /etc/postgresql/failover_notify_restoring_ended.sh;\nOFF\ndone\n\n\necho \"Стопаем repmgrd на ноде, ставшей мастером\"\npkill repmgrd\n\necho \"Работаем с Keepalived\"\n\n follow_command='sh /etc/postgresql/failover_follow.sh' repmgr standby follow -f /etc/repmgr.conf;\necho \"Отправка оповещений\";\nsh /etc/postgresql/failover_notify_standby.sh;\npkill repmgrd;\nrepmgrd -f /etc/repmgr.conf -p /var/run/postgresql/repmgrd.pid -m -d -v &gt;&gt; /var/log/postgresql/repmgr.log 2&gt;&amp;1;\n \r\nСкрипт остановки мастера — принудительного failover, удобно использовать для тестирования процедур «перевыборов» в кластере. follow_command='sh /etc/postgresql/stop_master.sh' #!/bin/bash \r\nrepmgr -f /etc/repmgr.conf cluster show | grep master | awk ' {print $7} ' | sed «s/host=//g» | sed «s/&gt;//g» &gt; /etc/postgresql/current_master.list \r\nfor CURMASTER in $(cat /etc/postgresql/current_master.list) \r\ndo \r\nssh postgres@$CURMASTER &lt;&lt;OFF \r\ncd ~/9.6; \r\n/usr/lib/postgresql/9.6/bin/pg_ctl -D /etc/postgresql/9.6/main -m immediate stop; \r\ntouch /etc/postgresql/disabled; \r\nOFF \r\nsh /etc/postgresql/telegram.sh «ТЕКУЩИЙ МАСТЕР ОСТАНОВЛЕН» \r\ndone \r\nС помощью скриптов можно понять логику работу и настроить сценарии под себя. Как мы видим из кода, нам будет необходим доступ к root пользователю от пользователя postgres. Получаем его таким же образом — через ключи. Доступ к root от postgres su postgres\nssh-copy-id -i ~/.ssh/id_rsa.pub root@pghost195\nssh-copy-id -i ~/.ssh/id_rsa.pub root@pghost196\nssh-copy-id -i ~/.ssh/id_rsa.pub root@pghost197\nssh-copy-id -i ~/.ssh/id_rsa.pub root@pghost198\nssh-copy-id -i ~/.ssh/id_rsa.pub root@pghost205\n \r\nПовторяем на всех нодах. Для особых параноиков, можем настроить скрипт проверки состояний и добавить его в крон например раз в 2 минуты. Сделать это можно без, используя конструкции и используя полученные значения из файлов. Скрытый текст repmgr -f /etc/repmgr.conf cluster show | grep node | awk ' {print $7} ' | sed \"s/host=//g\" | sed '/port/d' &gt; /etc/postgresql/cluster_hosts.list\nrepmgr -f /etc/repmgr.conf cluster show | grep FAILED | awk ' {print $6} ' | sed \"s/host=//g\" | sed \"s/&gt;//g\" &gt; /etc/postgresql/failed_host.list\nrepmgr -f /etc/repmgr.conf cluster show | grep master | awk ' {print $7} ' | sed \"s/host=//g\" | sed \"s/&gt;//g\" &gt; /etc/postgresql/current_master.list\nrepmgr -f /etc/repmgr.conf cluster show | grep standby | awk ' {print $7} ' | sed \"s/host=//g\" | sed '/port/d' &gt; /etc/postgresql/standby_host.list\n Дополнения и устранение неисправностей. Сбор статистики запросов в базу \r\nМы добавили библиотеку pg_stat_statements( необходимо сделать рестарт) Скрытый текст su postgres\ncd ~\npg_ctl restart;\n \r\nДалее активируем расширение: Скрытый текст # CREATE EXTENSION pg_stat_statements;\n \r\nПример собранной статистики: Скрытый текст # SELECT query, calls, total_time, rows, 100.0 * shared_blks_hit /\n nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent\n FROM pg_stat_statements ORDER BY total_time DESC LIMIT 10;\n \r\nДля сброса статистики есть команда pg_stat_statements_reset: Скрытый текст # SELECT pg_stat_statements_reset();\n Удаление ноды из кластера если она ‘FAILED’ Скрытый текст DELETE FROM repmgr_etagi_test.repl_nodes WHERE name = 'node1';\n \r\nгде — etagi_test — название кластера; \r\nnode1 — имя ноды в кластере Проверка состояния репликации Скрытый текст plsq\n#SELECT EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp()))::INT;\n\n 00:00:31.445829\n(1 строка)\n \r\nЕсли в базе давно не было Insert’ов — то это значение будет увеличиваться. На hiload базах это значение будет стремиться к нулю. Устранение ошибки Slot 'repmgr_slot_номер слота' already exists as an active slot \r\nОстанавливаем postgresql на той ноде, на которой возникла ошибка Скрытый текст su postgres\npg_ctl stop;\n \r\nНа ноде master'e Скрытый текст su postgres \npsql repmgr\n#select pg_drop_replication_slot('repmgr_slot_4');\n Устранение ошибки ОШИБКА: база данных «dbname» занята другими пользователями \r\nДля того чтобы удалить базу данных на мастере необходимо отключить всех пользователей, спользующих данную базу а затем удалить ее. Скрытый текст plsq\n# SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'dbname';\n# DROP DATABASE dbname;\n Устранение ошибки INSERT или UPDATE в таблице «repl_nodes» нарушает ограничение внешнего ключа ОШИБКА: INSERT или UPDATE в таблице «repl_nodes» нарушает ограничение внешнего ключа «repl_nodes_upstream_node_id_fkey». DETAIL: Ключ (upstream_node_id)=(-1) отсутствует в таблице «repl_nodes». \r\nЕсли у вас возникла данная ошибка при попытке ввести упавшую ноду обратно в кластер то необходимо провести процедуру switchover любой ноды в кластере(standby) Скрытый текст repmgr -f /etc/repmgr.conf standby switchover\n \r\nStandby станет мастером. На “Старом Мастере” ставшем standby Скрытый текст repmgr -f /etc/repmgr.conf standby follow\n Ошибка ВАЖНО: не удалось открыть каталог \"/var/run/postgresql/9.6-main.pg_stat_tmp\": \r\nПросто создаем каталог Скрытый текст su postgres\nmkdir -p /var/run/postgresql/9.6-main.pg_stat_tmp\n Устранение ошибки при регистрации кластера no password supplied. \r\nПри регистрации кластера после того как мы слили с ноды данные бывает возникает ошибка \r\n“no password supplied”. Не стали с ней долго разбираться, помогла перезагрузка, видимо какой-то сервис не смог нормально загрузиться. Backup кластера Бэкап кластера делается командой pg_dumpall | gzip -c &gt; filename.gz\n Скрипт бэкапа баз данных Postgres backup_pg.sh #!/bin/bash\nDBNAMES=\"db1 db2 db3\" \nDATE_Y=`/bin/date '+%y'`\nDATE_M=`/bin/date '+%m'`\nDATE_D=`/bin/date '+%d'`\nSERVICE=\"pgdump\"\n#DB_NAME=\"repmgr\";\n\n#`psql -l | awk '{print $1}' `\nfor DB_NAME in $DBNAMES\ndo\n\techo \"CREATING DIR /Backup/20${DATE_Y}/${DATE_M}/${DATE_D}/${DB_NAME} \"\n\tBACKUP_DIR=\"/Backup/20${DATE_Y}/${DATE_M}/${DATE_D}/${DB_NAME}\"\n\tmkdir -p $BACKUP_DIR;\n\t\tpg_dump -Fc --verbose ${DB_NAME} | gzip &gt; $BACKUP_DIR/${DB_NAME}.gz\n\t\t# Делаем dump базы без даты, для того что дальше извлечь их нее функции\n\t\tpg_dump -Fc -s -f $BACKUP_DIR/${DB_NAME}_only_shema ${DB_NAME} \n\t\t/bin/sleep 2;\n\t\t# Создаем список функция\n\t\tpg_restore -l $BACKUP_DIR/${DB_NAME}_only_shema | grep FUNCTION &gt; $BACKUP_DIR/function_list\n\t\tdone\n\n\n\n##Как восстановить функции\n\n#########################\n#pg_restore -h localhost -U username -d имя_базы -L function_list db_dump\n########################\n\n\n### КАК ВОССТАНОВИТЬ ОДНУ ТАБЛИЦУ ИЗ БЭКАПА, например таблицу payment.\n#pg_restore --dbname db1 --table=table1 имядампаБД\n####ЕСЛИ ЖЕ ВЫ ХОТИТЕ СЛИТЬ ТАБЛИЦУ В ПУСТУЮ БАЗУ, ТО НЕОБХОДИМО ВОССОЗДАТЬ СТРУКТУРУ БД\n###pg_restore --dbname ldb1 имядампаБД_only_shema\n Заключение \r\nИтак, что мы получили в итоге: \r\n — кластер master-standby из четырех нод; \r\n — автоматический failover в случае отказа мастера(с помощью repmgr’a); \r\n — балансировку нагрузки(на чтение) через haproxy и pgbouncer(менеджер сеансов); \r\n — отсутствие единой точки отказа — keepalived переносит ip адрес на другую ноду, которая была автоматически “повышена” до мастера в случае отказа; \r\n — процедура восстановления(возвращение отказавшего сервера в кластер) не является трудоемкой — если разобраться); \r\n — гибкость системы — repmgr позволяет настроить и другие события в случае наступления инцидента с помощью bash скриптов; \r\n — возможность настроить систему “под себя”. \r\nДля начинающего специалиста настройка данной схемы может показаться немного сложной, на практике же, один раз стоит со всем хорошо разобраться и вы сможете создать HA системы на базе Postgresql и сами управлять сценариями реализации механизма Failover.", "title": "Кластер высокой доступности на postgresql 9.6 + repmgr + pgbouncer + haproxy + keepalived + контроль через telegram", "summary": "\r\nНа сегодняшний день процедура реализации «failover» в Postgresql является одной из самых простых и интуитивно понятных. Для ее реализации необходимо определиться со сценариями файловера — это...", "url": "https://habrahabr.ru/company/etagi/blog/314000/", "keywords": ["postgresq", "haproxy", "pgbouncer", "keepalived", "repmgr", "cluster", "HA", "failover", "replication"]}
{"content": "Как часто, программируя очередную бизнес-фичу, вы ловили себя на мысли: есть же на Земле люди, которые пишут базы данных, распознают лица на фотографиях, делают фреймворки и реализуют интересные алгоритмы. Почему в моей работе всё сводится к перекладыванию из одной таблицы БД в другую, вызову http-сервисов, верстке html-формы и прочей «бизнес-лапше»? Может быть я занимаюсь чем-то не тем или работаю не в той компании? \r\nХорошая новость в том, что интересные задачи окружают нас повсюду. Сильное желание и смелость творят чудеса на пути к цели — задача любого масштаба станет вам под силу, стоит просто начать её делать. \r\nНедавно мы написали синтаксический анализатор языка запросов 1С и его транслятор в обычный SQL. Это позволило нам выполнять запросы к 1С без участия 1С :) Минимальная рабочая версия на regexp-ах получилась недели за две. Ещё месяц ушёл на полноценный парсер через грамматики, разгребание нюансов структуры БД разных 1С-объектов и реализацию специфических операторов и функций. В результате решение поддерживает практически все конструкции языка, исходный код выложен на GitHub . \r\nПод катом мы расскажем, зачем нам это понадобилось, как удалось, а так же затронем несколько интересных технических подробностей. С чего всё началось? \r\nМы работаем в крупной бухгалтерской компании Кнопка . У нас обслуживается 1005 клиентов, работают 75 бухгалтеров и 11 разработчиков. Наши бухгалтеры ведут учёт тысячи клиентских баз в системе 1С: Бухгалтерия . Для управления базами мы используем облачную технологию 1cFresh, данные для неё храним в PostgreSQL. Самый сложный этап в работе бухгалтера — это отчётность. Казалось бы, 1С умеет готовить любую отчётность, но для этого ей необходимо актуальное состояние базы. Кто-то должен завести в систему все первичные документы, импортировать банковскую выписку, создать и провести необходимые учётные документы. При этом сроки сдачи отчётности в нашем любимом государстве строго ограничены, поэтому бухгалтеры обычно живут от одного бессонного цейтнота до другого. Мы задумались: как можно облегчить бухгалтерам жизнь? \r\nОказалось, что много проблем с отчётностью возникает из-за мелких ошибок в бухгалтерской базе: дубликаты контрагента или договора; \r\n дубликаты первичных документов; \r\n контрагент без ИНН; \r\n документ с датой из далёкого прошлого или будущего. \r\n Перечисленные проблемы легко найти с помощью языка запросов 1С, поэтому появилась идея сделать автоматизированный аудит клиентских баз. Мы написали несколько запросов и стали выполнять их каждую ночь на всех базах 1С. Найденные проблемы мы показывали бухгалтерам в удобной гугло-табличке, и всячески призывали к тому, чтобы табличка оставалась пустой. \r\nВыполнять эти запросы через стандартное COM апи 1С — не лучшая идея. Во-первых, это долго — обойти тысячу баз и запустить на каждой из них все запросы занимает 10 часов. Во-вторых, это существенно нагружает сервер 1С, которому обычно и так несладко живётся. Неприятно ради аудита замедлять текущую ежедневную работу людей. \r\nМежду тем, типичный запрос 1С выглядит так: select\n\tdoc.Дата as Date,\n\tdoc.Номер as Number,\n\tdoc.Организация.ИНН as Inn,\n\tdoc.Контрагент.ИНН as CounterpartyInn,\n\tПредставление(doc.Контрагент.ЮридическоеФизическоеЛицо) as CounterpartyType,\n\tdoc.НазначениеПлатежа as Description,\n\tdoc.СуммаДокумента as Sum\nfrom Документ.ПоступлениеНаРасчетныйСчет doc\nwhere\nnot doc.ДоговорКонтрагента.ПометкаУдаления\nand doc.Проведен\nand doc.видоперации = Значение(Перечисление.ВидыОперацийПоступлениеДенежныхСредств.ОплатаПокупателя)\t\nand ГОД(doc.Дата) = ГОД(&amp;Now)\n \r\nНесмотря на то, что это очень похоже на SQL, такую штуку не получится просто так взять и запустить напрямую через БД. Реальных причин тому три: Магические имена таблиц и колонок в базе. Это легко решается, так как 1С документирует их соответствие именам из запроса. \r\n Вложенные свойства. Например, doc.Организация.ИНН в SQL соответствует left join двух табличек Документ.ПоступлениеНаРасчетныйСчет и Справочник.Организации . \r\n Специфические для 1С операторы и функции , такие как Значение, Представление и Год . Их тоже нужно дополнительно транслировать в соответствующие конструкции СУБД. \r\n \r\nОсознав всё это, мы написали утилиту , которая преобразовывает запрос с диалекта 1С в обычный SQL, запускает его параллельно на всех физических серверах PostgreSQL, результат объединяет и складывает в отдельную таблицу в MS SQL. В результате время сбора данных сократилось с 10 часов до 3 минут. Регулярные выражения \r\nВ первой версии логику преобразования запроса мы реализовали целиком через regexp-ы. В COM апи 1С есть функция ПолучитьСтруктуруХраненияБазыДанных . Она возвращает информацию о том, каким таблицам и полям соответствуют объекты и свойства в 1С запросе. Используя несколько regexp-шаблонов, мы просто заменяли одни имена на другие. Этого удалось довольно легко достичь при условии, что все обращения к объектам и свойствам имели псевдонимы. \r\nБольше всего хлопот доставили вложенные свойства. 1С хранит их в связанных таблицах, поэтому приходилось исходное имя объекта в конструкции from заменять на подзапрос, в котором были все нужные left join-ы . Пример запроса select\ndoc.Контрагент.ИНН\nfrom Документ.ПоступлениеТоваровУслуг doc\n\n-- конвертировалось в\n\nselect\n\tdoc.gen0\nfrom (select\n\ttContractor.inn gen0\nfrom tDoc\nleft join tContractor on tDoc.contractorId = tContractor.id) doc\n \r\nКроме переименования свойств и генерации left join -ов, транслятор применял ещё ряд преобразований. Так, например, все join -ы в исходном запросе приходилось снабжать дополнительным условием на равенство поля Область (area) . Дело в том, что в одной базе данных PostgreSQL у нас живут несколько клиентских баз 1C, и данные одного клиента от данных другого отличаются специальным идентификатором, который 1С называет областью . В базе 1С создает ряд индексов по умолчанию. Все они первым компонентом ключа имеют область, так как все запросы выполняются в рамках одного клиента. Чтобы наши запросы использовали стандартные индексы, и чтобы не думать об этом при их написании, мы стали добавлять это условие автоматически при трансляции запроса. Использование regexp-ов оказалось верным решением , так как позволило быстро получить конечный результат и понять, что из всей этой затеи получается что-то полезное. Всем советуем proof of concept-ы и эксперименты делать именно так — максимально простыми подручными средствами. А что может быть проще и эффективнее при работе с текстами, чем regexp-ы? \r\nКонечно, есть и недостатки. Первый и очевидный — это срезанные углы и ограничения синтаксиса. Regexp-ы для свойств и таблиц требовали расстановки псевдонимов в запросе и, вообще, могли случайно заматчиться с какой-нибудь другой конструкцией, например, константной строкой. \r\nДругая проблема — смешение логики синтаксического анализа текста и его преобразование по нужным правилам. Каждый раз, реализуя новую фичу, нужно было изобретать и новую адскую смесь regexp-ов с вызовами IndexOf на строках, которая вычленит соответствующие элементы в исходном запросе. \r\nТак, например, выглядел код, который добавлял условие на равенство областей ко всем join-ам: private string PatchJoin(string joinText, int joinPosition, string alias)\n{\n var fromPosition = queryText.LastIndexOf(\"from\", joinPosition, StringComparison.OrdinalIgnoreCase);\n if (fromPosition &lt; 0)\n throw new InvalidOperationException(\"assertion failure\");\n var tableMatch = tableNameRegex.Match(queryText, fromPosition);\n if (!tableMatch.Success)\n throw new InvalidOperationException(\"assertion failure\");\n var mainTableAlias = tableMatch.Groups[3].Value;\n var mainTableEntity = GetQueryEntity(mainTableAlias);\n var joinTableEntity = GetQueryEntity(alias);\n var condition = string.Format(\"{0}.{1} = {2}.{3} and \", mainTableAlias,\n mainTableEntity.GetAreaColumnName(), alias, joinTableEntity.GetAreaColumnName());\n return joinText + condition;\n}\n \r\nВ коде хотелось иметь дело с объектной моделью исходного запроса, с ColumnReference и JoinClause , а вместо этого были только найденные regexp-ами подстроки и смещения в тексте запроса. \r\nСогласитесь, что такой вариант выглядит гораздо проще и понятнее предыдущего: private void PatchJoin(SelectClause selectClause, JoinClause joinClause)\n{\n joinClause.Condition = new AndExpression\n {\n Left = new EqualityExpression\n {\n Left = new ColumnReferenceExpression\n {\n Name = PropertyNames.area,\n Table = selectClause.Source\n },\n Right = new ColumnReferenceExpression\n {\n Name = PropertyNames.area,\n Table = joinClause.Source\n }\n },\n Right = joinClause.Condition\n };\n}\n \r\nТакая объектная модель называется Abstract syntax tree ( AST ). AST \r\nИнтересно, что впервые AST у нас появилось не при парсинге исходного запроса, а наоборот, при форматировании результата в SQL. Дело в том, что логика конструирования подзапроса для вложенных свойств становилась довольно витиеватой, и для её упрощения (и в соответствии с SRP ) мы разбили весь процесс на два этапа: вначале создаем дерево объектов, описывающих подзапрос, затем отдельно сериализуем его в SQL. В какой-то момент мы осознали, что это и есть AST, и для решения проблем с regexp-ами нужно просто научиться создавать его для исходного запроса. \r\nТермин AST широко используется при обсуждении нюансов синтаксического анализа. Деревом оно называется потому что этой структурой данных хорошо описываются типичные для языков программирования конструкции, обычно обладающие свойством рекурсивности и отсутствия циклов (хотя это и не всегда справедливо ). \r\nДля примера рассмотрим такой запрос: select p.surname as 'person surname'\nfrom persons p\nwhere p.name = 'иван'\n \r\nВ виде AST он выглядит так: На рисунке узлы — экземпляры классов, стрелочки и подписи — свойства этих классов. \r\nТакую объектную модель можно собрать через код следующим образом: var table = new TableDeclarationClause\n{\n Name = \"PersonsTable\",\n Alias = \"t\"\n};\nvar selectClause = new SelectClause\n{\n FromExpression = table,\n WhereExpression = new EqualityExpression\n {\n Left = new ColumnReferenceExpression\n {\n Table = table,\n Name = \"name\"\n },\n Right = new LiteralExpression\n {\n Value = \"иван\"\n }\n }\n};\nselectClause.Fields.Add(new SelectFieldExpression\n{\n Expression = new ColumnReferenceExpression\n {\n Table = table,\n Name = \"surname\"\n }\n});\n \r\nСтоит отметить, что приведённый пример AST не является единственно правильным. Конкретная структура классов и связей между ними определяется спецификой задачи. Основная цель любого AST — облегчить решение задачи, сделать выполнение типичных операций максимально удобным. Поэтому чем оно будет проще и естественнее описывать конструкции искомого языка, тем лучше. \r\nПереход от regexp-ов к AST позволил избавиться от многих хаков, сделать код чище и понятнее. Вместе с тем, теперь наша утилита должна была знать обо всех конструкциях исходного языка, чтобы создать для них соответствующий узел в дереве. Для этого пришлось написать грамматику языка запросов 1С и парсер для неё. Грамматики \r\nИтак, в какой-то момент стало понятно, что нам нужно AST исходного запроса. В интернете есть много библиотек, которые умеют парсить SQL и создавать AST для него, но при более пристальном взгляде они оказываются либо платными , либо поддерживают лишь подмножество SQL. К тому же не понятно, как их приспособить для распознавания 1С-диалекта SQL, ведь он содержит ряд специфических расширений. \r\nПоэтому мы решили написать свой парсер. Синтаксические анализаторы обычно начинают делать с описания грамматики того языка, который требуется распознать. Формальная грамматика — классический инструмент описания структуры языков программирования. Её основу составляют правила вывода, то есть рекурсивные определения каждой языковой конструкции. \r\nНапример, такими правилами можно описать язык арифметических выражений: E → number | (E) | E + E | E - E | E * E | E / E \r\nТакую запись можно читать следующим образом: любое число (number) — это выражение (E) ; \r\n если выражение заключено в скобки, то всё это, вместе со скобками — тоже выражение; \r\n два выражения, соединенные арифметической операцией, так же составляют выражение. \r\n \r\nСимволы, для которых определены правила вывода, называют нетерминалами . Символы, для которых не определены правила, и которые являются элементами языка — терминалами . Применяя правила, из нетерминалов можно получать строки, состоящие из других нетерминалов и терминалов, пока не останутся только терминалы. В примере выше E — это нетерминал, а символы +, -, *, / и number — терминалы, образующие язык арифметических выражений. \r\nСуществуют специальные инструменты — генераторы синтаксических анализаторов, которые по описанию языка, заданному в виде грамматики, умеют генерировать распознающий этот язык код. Самые известные из них — это yacc , bison и antlr . Для C# есть менее распространённая библиотека Irony . Про неё уже была небольшая статья на Хабре , а вот пост Скотта Хансельмана про неё. \r\nОсновная фишка библиотечки Irony в том, что правила грамматики можно описывать прямо на C# , используя перегрузку операторов. В итоге получается вполне симпатичный DSL , по форме очень похожий на классическую форму записи правил: var e = new NonTerminal(\"expression\");\nvar number = new NumberLiteral(\"number\");\ne.Rule = e + \"+\" + e | e + \"-\" + e | e + \"*\" + e | e + \"/\" + e | \"(\" + e + \")\" | number;\n \r\nСимвол | означает, что может применяться любой из вариантов правила (логический or).Символ + — конкатенация, символы должны следовать друг за другом. \r\nIrony разделяет понятия Parse Tree и Abstract Syntax Tree . Parse Tree — это артефакт процесса распознания текста, результат последовательного применения правил грамматики. В его внутренних узлах стоят нетерминалы, а в потомки попадают символы из правых частей соответствующих правил. \r\nНапример, выражению 1+(2+3) при применении правил: e 1 : E → E + E e 2 : E → (E) e 3 : E → number \r\nсоответствует такое Parse Tree: \r\nParse Tree не зависят от конкретного языка и в Irony описываются одним классом ParseTreeNode . Abstract Syntax Tree наоборот, целиком определяется конкретной задачей, и состоит из специфичных для этой задачи классов и связей между ними. \r\nНапример, AST для грамматики выше может состоять всего из одного класса BinaryOperator : public enum OperatorType\n{\n Plus,\n Minus,\n Mul,\n Div\n}\npublic class BinaryOperator\n{\n public object Left { get; set; }\n public object Right { get; set; }\n public OperatorType Type { get; set; }\n}\n \r\nСвойства Left и Right имеют тип object , т.к. они могут ссылаться либо на число, либо на другой BinaryOperator : \r\nIrony позволяет создать AST последовательно, поднимаясь от листьев к корню, одновременно с применением правил грамматики. Для этого на каждый нетерминал можно навесить делегат AstNodeCreator , который Irony вызовет в момент применения любого из сопоставленных этому нетерминалу правил. Этот делегат должен на основе переданного ParseTreeNode создать соответствующий ему узел AST и положить ссылку на него обратно в ParseTreeNode . К моменту вызова делегата все дочерние узлы Parse Tree уже обработаны и AstNodeCreator для них уже был вызван, поэтому в теле делегата мы можем пользоваться уже заполненным свойством AstNode дочерних узлов. \r\nКогда мы таким образом доходим до корневого нетерминала, в его AstNode образуется корневой узел AST, в нашем случае — SqlQuery . \r\nДля грамматики арифметических выражений выше AstNodeCreator может выглядеть так: var e = new NonTerminal(\"expression\",\ndelegate(AstContext context, ParseTreeNode node)\n{\n //соответствует правилу E → number,\n if (node.ChildNodes.Count == 1)\n {\n node.AstNode = node.ChildNodes[0].Token.Value;\n return;\n }\n //правила вида E → E op E\n if (node.ChildNodes[0].AstNode != null &amp;&amp; node.ChildNodes[2].AstNode != null)\n {\n node.AstNode = new BinaryOperator\n {\n Left = node.ChildNodes[0].AstNode,\n Operator = node.ChildNodes[1].FindTokenAndGetText(),\n Right = node.ChildNodes[2].AstNode\n };\n return;\n }\n //правило со скобками\n node.AstNode = node.ChildNodes[1].AstNode;\n});\n \r\nИтак, с помощью Irony мы научились конструировать AST по исходному запросу. Остался лишь один большой вопрос — как эффективно структурировать код для преобразования AST, ведь в конечном счете из исходного AST нам нужно получить AST результирующего SQL запроса. В этом нам поможет паттерн Visitor. Visitor \r\nПаттерн Visitor (или double dispatch ) — один из самых сложных в GoF и, возможно поэтому, один из самых редко используемых. За свой опыт мы видели только одно активное его применение — для преобразования различных AST. Конкретный пример — это класс ExpressionVisitor в .NET, который неизбежно возникает , когда делаешь linq provider или просто хочешь немного подправить генерируемые компилятором expression tree . Какую проблему решают visitor-ы? \r\nСамая естественная и необходимая вещь, которую часто приходится делать при работе с AST — это превращать его в строку. Возьмем к примеру наш AST: после замены русских имён таблиц на английские, генерации left join-ов и преобразования 1С-операторов в операторы БД, на выходе нам нужно получить строку, которую мы сможем отдать на выполнение в PostgreSQL. \r\nВозможный вариант решения этой задачи таков: internal class SelectClause : ISqlElement\n{\n //...\n public void BuildSql(StringBuilder target)\n {\n target.Append(\"select \");\n for (var i = 0; i &lt; Fields.Count; i++)\n {\n if (i != 0)\n target.Append(\",\");\n Fields[i].BuildSql(target);\n }\n target.Append(\"\\r\\nfrom \");\n From.BuildSql(target);\n foreach (var c in JoinClauses)\n {\n target.Append(\"\\r\\n\");\n c.BuildSql(target);\n }\n }\n}\n \r\nПро этот код можно сделать два важных наблюдения: все узлы дерева должны иметь метод BuildSql , чтобы рекурсия работала; \r\n метод BuildSql на SelectClause перевызывает BuildSql на всех дочерних узлах. \r\n \r\nТеперь рассмотрим другую задачу. Допустим нам нужно добавить условие на равенство поля area между основной таблицей и всеми приджойненными, чтобы попадать в индексы PostgreSQL. Для этого нам нужно пробежаться по всем JoinClause в запросе, но, учитывая возможные подзапросы, нам нужно не забыть заглянуть и во все остальные узлы. \r\nЭто означает, что если следовать той же структуре кода, что и выше, то мы должны будем: добавить метод AddAreaToJoinClause во все узлы дерева; \r\n его реализации на всех узлах, кроме JoinClause , должны будут пробросить вызов своим потомкам. \r\n \r\nПроблема с этим подходом ясна — чем больше у нас будет различных логических операций над деревом, тем больше будет методов в узлах, и тем больше копипаста между этими методами. Visitor-ы решают эту проблему за счёт следующего: Логические операции перестают быть методами на узлах, а становятся отдельными объектами — наследниками абстрактного класса SqlVisitor (см. рисунок ниже). \r\n Каждому типу узла соответствует отдельный метод Visit в базовом SqlVisitor-е , например, VisitSelectClause(SelectClause clause) или VisitJoinClause(JoinClause clause) . \r\n Методы BuildSql и AddAreaToJoinClause заменяются на один общий метод Accept . \r\n Каждый узел реализует его путем проброса на соответствующий метод на SqlVisitor-е , который приходит параметром. \r\n Конкретные операции наследуются от SqlVisitor и переопределяют только те методы, которые им интересны. \r\n Реализации методов Visit в базовом SqlVisitor-е просто перевызывают Visit для всех дочерних узлов, за счёт этого устраняется дублирование кода. \r\n \r\nПример с сериализацией в SQL адаптируется следующим образом: internal interface ISqlElement\n{\n void Accept(SqlVisitor visitor);\n}\n\n\ninternal class SqlVisitor\n{\n public virtual void Visit(ISqlElement sqlElement)\n {\n sqlElement.Accept(this);\n }\n\n\n public virtual void VisitSelectClause(SelectClause selectClause)\n {\n }\n //...\n}\n\n\ninternal class SqlFormatter : SqlVisitor\n{\n private readonly StringBuilder target = new StringBuilder();\n\n\n public override void VisitSelectClause(SelectClause selectClause)\n {\n target.Append(\"select \");\n for (var i = 0; i &lt; selectClause.Fields.Count; i++)\n {\n if (i != 0)\n target.Append(\",\");\n Visit(selectClause.Fields[i]);\n }\n target.Append(\"\\r\\nfrom \");\n Visit(selectClause.Source);\n foreach (var c in selectClause.JoinClauses)\n {\n target.Append(\"\\r\\n\");\n Visit(c);\n }\n }\n}\n\n\ninternal class SelectClause : ISqlElement\n{\n //...\n public void Accept(SqlVisitor visitor)\n {\n visitor.VisitSelectClause(this);\n }\n}\n \r\nНазвание double dispatch вполне точно описывает эту схему: Первый dispatch происходит в классе SqlVisitor при переходе от Visit к Accept на конкретном узле, в этот момент становится известен тип узла. \r\n Второй dispatch следует за первым при переходе от Accept на узле к конкретному методу на SqlVisitor , здесь становится известна операция, которую нужно применить к выбранному узлу. \r\n Итого \r\nВ статье подробно описан рецепт приготовления транслятора языка запросов 1С в запросы SQL. Мы прошли через эксперименты с регулярными выражениями, получив работающий прототип и подтверждение того, что штука полезная и стоит двигаться дальше. И когда на код стало невозможно смотреть без стыда и боли, а жонглирование с regexp-ами не приводило к нужному результату, мы сделали серьёзный шаг — перешли к AST и грамматикам. Далее с помощью visitor-ов мы научились преобразовывать AST, реализуя тем самым логику перевода с одного языка на другой. \r\nСтоит отметить, что этот путь мы не проходили в одиночку, и даже не пришлось открывать Dragon Book . Для синтаксического анализа и построения AST мы использовали готовую библиотеку Irony, которая позволила не изобретать велосипед, а сразу перейти к решению прикладной задачи. \r\nПрактический результат для компании заключается в сокращении скорости получения данных с 10 часов до 3 минут. Это позволило нашим аналитикам быстро ставить эксперименты и проверять гипотезы о бизнесе клиентов и работе бухгалтеров. Это особенно удобно, так как клиентов у нас много, а их базы распределены между пятью физическими серверами PostgreSQL. Резюмируя всё вышесказанное: Ставьте эксперименты и получайте proof of concept максимально быстро и дешево. \r\n Ставьте амбициозные цели, и двигайтесь к ним маленькими шагами, постепенно дотачивая инструмент до нужного состояния. \r\n Для большинства задач уже есть готовое решение, или хотя бы фундамент. \r\n Синтаксический анализ и грамматики применимы в обычных бизнес-приложениях. \r\n Решайте конкретную задачу, а общее решение придёт само. \r\n \r\nКод бибилиотеки и примеры использования ждут вас на GitHub . \r\nНа досуге советуем почитать: 99,99% задач не имеют решения потому, что люди не верят в это \r\n Зачем команда Джоэла Спольски написала собственный компилятор? \r\n Пост Скотта Хансельмана о библиотеке Irony \r\n ", "title": "Как перестать бояться и полюбить синтаксический анализ?", "summary": "Как часто, программируя очередную бизнес-фичу, вы ловили себя на мысли: есть же на Земле люди, которые пишут базы данных, распознают лица на фотографиях, делают фреймворки и реализуют интересные...", "url": "https://habrahabr.ru/company/knopka/blog/314030/", "keywords": ["irony", ".net", "c#", "грамматический разбор", "синтаксический анализ", "1с", "бухгалтерия", "бухгалтерия и программисты", "sql", "анализатор кода", "грамматический парсер", "грамматики", "регулярные выражения", "regexp"]}
{"content": "Индустрия звука, о которая была у всех на слуху в 80-е, практически полностью ушла из поля зрения СМИ за исключением ряда специализированных изданий. К сожалению, сегодня люди, не связанные с аудио индустрией, даже не подозревают о возможностях, которые дают новые аудиотехнологии. Отсюда появляется множество мифов, сложившихся вокруг современных аудиосистем. \r\nМы в Аудиомании делимся своим опытом со всеми, кому интересна эта тема, рассказываем об аудиотехнике и даем возможность получать информацию «из первых рук». Наша компания выбрала для себя следующий девиз: «хороший звук от А до Я»; поэтому мы постараемся говорить простыми словами, дать ответы на базовые вопросы и познакомить вас с миром современной аудиотехники. Фото PRODennis Skley Follow / CC Какие параметры необходимо учитывать при выборе аудиосистем? \r\nБытует мнение, что качество звука напрямую зависит от цены или диапазона частот той или иной аудиосистемы. Многие удивляются тому, что на сайте Аудиомании мы отказались от сравнения акустики и наушников по характеристикам. Дело в том, что это практически бесполезно. \r\nБезусловно, при выборе вы можете обращать внимание на частотный диапазон, мощность и сопротивление, но наушники, как и динамики, обладают десятками различных параметров. Пытаться уложить их все в голове и сравнить — задача на любителя. \r\nВ ситуации, когда мы сравниваем только по частотным характеристикам и цене, может получится так, что относительно дешевая колонка воспроизводит больший диапазон частот, чем дорогая. Однако, если мы посмотрим на кривую амплитудно-частотных характеристик (АЧХ), на то, какие частоты и как воспроизводятся, картина получится другая. \r\nЗначит ли это, что звучание очень дорогой акустики вам гарантированно понравится? Ответ на этот вопрос вам нужно найти самостоятельно. На практике. Шуорум Аудиомании на м. Электрозаводская \r\nНе стоит делать выбор, полагаясь только на рекламу или мнение других людей, поскольку требования к звучанию тех или иных произведений у всех разные. Прежде чем покупать аудиотехнику, необходимо проверить ее в работе — послушать любимую музыку, звучание которой вам хорошо известно. \r\nК сожалению, обычные магазины обычно не предоставляют подобных услуг. Для этого созданы специальные шоурумы, где можно в комфортных условиях послушать выбранную аудиосистему. Нужно ли покупать профессиональную аудиотехнику для домашнего использования? \r\nМногие любители хорошего звука ошибочно полагают, что профессиональная аудиотехника является «более качественной» и должна стоить дороже, чем любительская. В действительности, все немного иначе, а «профессиональной» аудиотехника называется не потому, что она чем-то выгодно отличается, а от слова «профессия». \r\nКак можно быстро определить, является ли та или иная система «профессиональной»? Например, по внешнему виду: профессиональные акустические системы и аппаратура редко обладают дизайнерскими изысками, а в их отделке, как правило, не используют дорогие материалы. \r\nБезошибочно определить класс, к которому относится техника, можно по используемым соединителям и разъемам. Например, разъемы типа Speakon  используют преимущественно в профессиональных аудиосистемах. Круглые снаружи, они совершенно не похожи на те привычные клеммы и зажимные колодки, которые в основном используются для домашних акустических систем. \r\nДело в нагрузке, на которую рассчитана та или иная техника. Вспомните любой магазин, ресторан или фитнес клуб — там всегда играет музыка. Для таких задач используется профессиональное оборудование, которое предусматривают постоянную нагрузку. \r\nТут стоит обратить внимание на мощность систем. Если нужно озвучить большое пространство — необходима большая мощность. Если же речь идет о маленьком помещении, то можно ограничиться настенными акустическими системами. Наши решения для фонового озвучивания помещений \r\nСистемы типа public address или аппаратура для проведения вечерних мероприятий значительно отличаются от аудиотехники для дома. Как по своим задачам, так и по параметрам и характеру звучания. \r\nВ отличие от профессиональных систем, современный Hi-Fi не рассчитан на постоянную работу и требует иных условий эксплуатации, хотя при обычном домашнем использовании такие системы могут работать без потери качества до 20 лет. \r\nМало кто захочет рисковать своей домашней аудиосистемой и использовать ее на открытом воздухе. Для этой задачи есть специальные влагозащитные и морозоустойчивые акустические системы. Пример такой системы: всепогодная акустика Tannoy DVS 4 \r\nОни могут быть выполнены даже в виде камней и использоваться в качестве украшения ландшафта. При этом такие системы работают при любой погоде круглый год. Зачем нужны усилители для наушников? \r\nСтоит помнить, что высокое качество звука зависит не только от наушников. Даже самые лучшие из них не способны обеспечить достойный звук без качественного источника и усилителя. Смартфоны и ноутбуки обычно оснащают маломощными усилителями и за редким исключением не способны обеспечить по-настоящему качественное звучание через штатный выход. \r\nСигнал с таких устройств можно усилить, особенно если вы предпочитаете полноразмерные стереонаушники. Кроме того, на некоторых из усилителей расположены такие элементы управления, как, например, регулятор громкости. Таким образом, вам не нужно каждый раз доставать смартфон из кармана, чтобы убавить звук или ответить на звонок. Внешний ЦАП Arcam rPac \r\nСуществуют также усилители со встроенными цифро-аналоговыми преобразователями (ЦАП), то есть гибридные устройства. На улице их можно использовать как усилитель звука, а дома, подключив в компьютеру, – как звуковую плату. Внешние ЦАП удобны тем, что могут быть подключены к любому устройству, имеющему цифровой выход, а большинство ЦАП могут подключаться и по USB. Могут ли нанести вред здоровью внутриканальные наушники? \r\nСледует сразу отметить, что сам факт использования наушников не наносит вред органам слуха. Это миф, ведь в таком случае были бы вредны и беруши, и рабочие шумозащитные наушники, и плотные шапки, которые давят на область ушной раковины. Внутриканальные наушники Fischer Audio Leggiero в корпусе из эбенового дерева \r\nПотенциальный вред от наушников может быть связан с громкостью передаваемого звука: «Действительно, если использовать вставные наушники, не внутриканальные, в метро, добавлять громкость, а ещё и подключить усилитель, «раскачав» его на полную катушку, то есть риск ослабить свой слух, потому что организм будет защищаться. – говорит Тимофей Шиколенков , директор по маркетингу и развитию бизнеса компании Аудиомания. – Громкие звуки очень вредны для ушей, гораздо вреднее, чем какие-то мнимые проблемы, которые могут возникнуть в процессе надевания или ношения наушников». \r\nПри этом многие убеждены в том, что маленькие внутриканальные наушники не обладают глубоким и качественным басом по определению. В действительности, есть множество устройств доказывают обратное. Например: внутриканальные наушники Denon AH-C101 P.S. Многие из мифов нашли свои ответы в выпусках нашей тематической передачи « Звук », а на непосредственные вопросы клиентов мы оперативно отвечаем в специальном разделе на нашем сайте. Если интересно Наш Аудиодайджест на GT: [ #11: Аналоговое звучание и кино ] \r\n [ #10: Интервью, винил и руководства ] \r\n [ #9: Советы меломанам и «cделай сам» ] \r\n ", "title": "Мифы и реальность: Что нужно знать о современных аудиосистемах", "summary": "Индустрия звука, о которая была у всех на слуху в 80-е, практически полностью ушла из поля зрения СМИ за исключением ряда специализированных изданий. К сожалению, сегодня люди, не связанные с аудио...", "url": "https://geektimes.ru/company/audiomania/blog/282058/", "keywords": ["аудиомания", "мифы и реальность", "акустика", "аудиотехника"]}
{"content": "Эффективность рассылки в качестве маркетингового инструмента и канала продаж никто не отрицает, но остается вопрос, как сделать ее еще более эффективной. Использование специальных сервисов, верстка, яркие картинки, интерактивные письма — все усилия будут напрасны, если само письмо не несет никакой полезной информации. \r\nПоэтому одна из основных проблем — выбор интересной читателям, актуальной, важной темы. О том, что может оказаться эффективнее: шпионаж за конкурентами или, например, подарок за прочтение письма — расскажем сегодня. Фото Steven Depolo CC / Flickr С чего начать: общие советы по поиску темы \r\nУ любой рассылки должна быть определенная тема, нельзя писать обо всем подряд. Это понимают все, но вот прийти к выбору этой темы иногда бывает непросто. Команда британского облачного сервиса для email-маркетинга FreshMail предлагает подробный how-to-гайд по созданию рассылок. В качестве отправной точки предлагается задать себе вопрос (конец второй главы): какой ценный контент у вас есть? \r\nЕсли ответ – «никакого», то подумайте еще. Подойдут обучающие видео, истории успеха, инфографика, удачные кейсы, курсы и любая другая полезная для клиентов информация. Следующим шагом, описанным в третьей главе, станет формулировка цели: чего вы планируете достичь этой рассылкой, и что получатель поймет после прочтения письма. \r\nОпределившись, хотите ли вы увеличить продажи или повысить лояльность клиентов, сфокусируйтесь на каком-то аспекте своей работы, как это предлагают сделать австралийские эксперты в пошаговой стратегии по созданию рассылок (см. «Step 3»). Это может быть описание мероприятия, которое проводит ваша компания, сбор средств на благотворительность (почему бы и нет – если вы действительно этим занимаетесь) или новое направление деятельности. \r\nЗатем продумайте, какую дополнительную информацию можно включить в рассылку. У вас накопились положительные отзывы пользователей? О вас написали в СМИ? Или вы подготовили годовой отчет? Почему бы не рассказать об этом клиентам. А может стоит предложить им получение членства или бонус за вступление в группу вашей компании в социальной сети. Еще один вариант — попросить подписчиков заполнить анкету или поучаствовать в исследовании. \r\nЧтобы подобрать тему письма, попробуйте сначала определиться с форматом рассылки. Удачный пример использования формата в качестве определяющего фактора при выборе темы — «поведенческая» рассылка (про другие приемы персонализации читайте в нашем прошлом материале ). \r\nПисьмо на основе действий пользователя на сайте может здорово освежить общение, вызвать положительные эмоции и даже повысить конверсию. Пример – в рассказе директора по контенту сервиса для email-маркетинга Vero Джимми Дэли (Jimmy Daly). Сервис бронирования жилья Airbnb заметил, что Джимми просматривал квартиру на сайте, но не забронировал ее. Поэтому они прислали письмо, где рассказали больше о просмотренной квартире и предложили альтернативные варианты. \r\nПохожим образом поступает оптика Warby Parker (мы подробно рассказывали об этом кейсе в блоге, см. пункт 5 тут ). Компания напоминает клиенту об окончании срока действия рецепта и предлагает купить линзы до его истечения или записаться к офтальмологу еще раз. \r\nДругой удачный формат для рассылки — письмо-история, которое получится легко привязать к самому продукту или определенному событию (подробнее читайте по ссылке под пунктом «Infotainment secret #2»). Людям нравится читать интересные качественные истории, поэтому стоит попробовать использовать такой развлекательный контент для увеличения продаж, чтобы разнообразить таким образом формат рассылок. Фото Chris Isherwood CC / Flickr Пользователь — наше все \r\nВ первую очередь любая рассылка направлена на получателей, поэтому чтобы выбрать тему, которая заинтересует именно ваших клиентов, нужно «знать их в лицо». Мы уже писали о том, что выбор контента и темы должен зависеть в первую очередь от целевой аудитории. \r\nЭксперт в области SMM и контент-маркетинга и блогер Сюзанна Гебауэр (Susanna Gebauer) в своей статье согласна с нами, но добавляет важную информацию о портрете типичного клиента, к которому должны быть обращены все ваши письма. Чем больше данных у вас есть (пол, возраст, семейный статус, занимаемая должность, интересы и т. д.), тем больше вероятность того, что ваша рассылка понравится получателям. \r\nПосле выделения особенностей вашей целевой аудитории, определите ее желания и потребности. Следующий шаг — понять, что может заинтересовать этих людей, и что вы можете им предложить. Но что делать, если ваша аудитория неоднородна? Создайте портреты типичных представителей для каждой группы клиентов и используйте инструмент сегментации, чтобы отправлять им разные рассылки. Подбирайте разные темы, типы контента, язык письма и даже картинки для разных групп. \r\nКроме портрета пользователя необходимо понимать, как получатели воспринимают электронные письма. На помощь опять приходит инструкция по созданию хороших рассылок от FreshMail (часть «The scanning age»): большинство людей не читают письма, а «сканируют» их, обращая внимания только на заголовки, графики, списки. Поэтому у рассылки есть примерно 3 или 4 секунды, чтобы заинтересовать пользователя. Выбирая тему, будьте уверены, что она сможет сделать это. Фото Johan Hansson CC / Flickr Что нужно пользователям \r\nЕще один значимый критерий выбора темы — она должна быть полезна для читателей. Следует признать, что людям свойственно быть эгоистичными и всем гораздо интереснее читать о себе, чем о вас. \r\nЖелание рассказывать только о своем продукте автор нескольких книг о копирайтинге и маркетинге Роберт В. Блай (Robert W. Bly) перечисляет среди ошибок (в тексте источника пункт №10): «Вы, как и ваш продукт, история и философия вашей компании, совершенно не интересуете читателей. Когда ваш подписчик открывает письмо, он хочет знать, что полезного там есть именно для него и что такого вы можете ему предложить, чего нет у ваших конкурентов». \r\nМы выяснили, что скучные новости компании никого не интересуют, но подписчикам важна и приятна обратная связь. Поэтому можно рассказать о том, что вы внедрили новую функцию по просьбе аудитории. Чтобы выбрать тему, необходимо понять, какая проблема волнует ваших клиентов. Письмо должно предложить решение этой проблемы. \r\nО продукте важно писать в системе координат покупателя, которому интересны преимущества товара или услуги, а не его свойства. Например, текстовый редактор позволяет работать с текстом в электронном виде. Переведем на язык клиента и получим: «Текстовый редактор сэкономит вам много времени и повысит эффективность работы». \r\nМаркетолог, копирайтер и писатель Хэннеке Дуистермаэт (Henneke Duistermaat) делится длинным списком секретов правильной рассылки. Она считает (см. пункт 3 и 8 в источнике), что если вам нечего сказать клиентам, не отправляйте рассылку, лучше подождите, пока у вас появится какая-то важная информация. Кроме того, попробуйте вознаградить подписчика за прочтение письма: дайте полезный совет или лайфхак по использованию вашего продукта, обучающее видео или бесплатный образец товара. Отталкиваясь от такого контента, выйти на определенную тему становится проще. Фото Johan Hansson CC / Flickr Что еще может помочь \r\nЕсли предыдущие рекомендации не помогли вам определиться с выбором темы, то остается только один выход — просто спросите у пользователей, о чем им было бы интересно читать в вашей рассылке. Можно включить опрос прямо в письмо, а можно воспользоваться специальными сервисами. Например, если ваша компания представлена в социальных сетях, то опросите клиентов через Facebook или Twitter. \r\nКстати, Роберт В. Блай приводит в своей статье интересный кейс о важности прямого диалога с читателями. Он говорит о Элвине Айкоффе (Alvin Eicoff), создателе телевизионной рекламы и авторе фразы «… или мы вернем вам деньги». Тот в одноименной книге рассказывает про пример успешной рекламы крысиного яда на радио: на обычных потребителей она отлично действовала, но на сельскохозяйственном рынке кампания провалилась. \r\nАйкофф лично поехал общаться с фермерами и выяснил, что проблема крыс оказалась весьма деликатной — потенциальные покупатели не заказывали яд, так как соседи могли бы увидеть товар и узнать про грызунов на ферме. Добавив в рекламу информацию о том, что крысиный яд доставляется в запакованном бумажном пакете, Айкофф смог в разы увеличить продажи. \r\nСегодня поговорить с пользователями и узнать их мнение и пожелания можно, не вставая с места. Так почему бы не воспользоваться такой возможностью? Единственный минус этого подхода — отвечать будут наиболее активные и лояльные пользователи, а чтобы привлечь внимание остальной части аудитории, придется пойти по другому пути. \r\nК счастью, узнавать, какие темы вызывают интерес у пользователей, необязательно напрямую: сегодня существуют инструменты для анализа конверсии рассылок. Вы поймете, на чтение каких писем получатели потратили больше времени, и сможете определиться с темой и контентом будущих писем (подробнее о том, как понравится пользователям читайте тут ). \r\nСамый распространенный аналитический инструмент — это, пожалуй, Google Analytics, который легко интегрируется с сервисами почтовых рассылок. Или воспользуйтесь отдельными инструментами для анализа, выбор которых сегодня огромен. \r\nИногда подглядеть интересные варианты тем и контента можно у конкурентов. Подпишитесь на их рассылку, изучите материалы в блогах и социальных сетях — если ваша целевая аудитория совпадает, то по количеству лайков и репостов получится выбрать волнующую для клиентов тему. Уже известная нам Хэннеке Дуистермаэт рекомендует (п.16) на всякий случай подписаться на несколько по-настоящему хороших рассылок и черпать идеи оттуда. Такой вариант тоже имеет место, но, скорее всего, он будет менее эффективным в сравнении с изучением своих подписчиков. Подведем итоги \r\nВыбор темы рассылки — задача действительно непростая, но вполне решаемая. Для этого достаточно выполнить несколько пунктов: \r\n1. Подумайте, что интересного вы можете рассказать пользователям (новости, инфографика, полезные советы или последние события из жизни вашей компании – все это может пойти в дело, если правильно подать материал: думайте о том, какую пользу он может дать вашему подписчику) \r\n2. Определите цель рассылки (чего хотите добиться в результате вы? А что получит ваш читатель?) \r\n3. Продумайте формат письма и возможное наполнение (исходите из того, какой актуальный дополнительный материал у вас есть сейчас: в результате вы можете остановиться на информационном письме, поведенческой рассылке или даже письме-истории) \r\n4. Изучите вашего потребителя, определите его потребности (полезно сформировать портрет аудитории и использовать инструменты ее сегментирования) \r\n5. Спросите у подписчиков, о чем они хотели бы читать (для этого можно спросить читателей напрямую, а можно воспользоваться сервисами анализа конверсии) \r\n6. Используйте аналитические инструменты \r\n7. Изучайте ваших конкурентов и просто удачные примеры рассылок \r\nЕсли вы до сих пор не знаете, о чем писать, попробуйте поискать вдохновение в блоге американского сервиса VerticalResponse: в этой статье целых 75 примеров интересных тем от инструкции по выбору подарка до подборки полезных сервисов. О чем еще можно почитать в нашем блоге на тему улучшения рассылок Холодная рассылка: как сделать ее теплее \r\n Как повысить открываемость email рассылки \r\n «Пишите письма»: Три техники верстки хороших email’ов \r\n Причины, почему ваша рассылка не работает \r\n ", "title": "Как выбрать тему для email-рассылки: универсальные правила и источники вдохновения", "summary": "Эффективность рассылки в качестве маркетингового инструмента и канала продаж никто не отрицает, но остается вопрос, как сделать ее еще более эффективной. Использование специальных сервисов,...", "url": "https://habrahabr.ru/company/pechkin/blog/314066/", "keywords": ["pechkin.com", "email-рассылки", "email-маркетинг", "newsletter", "рассылка писем"]}
