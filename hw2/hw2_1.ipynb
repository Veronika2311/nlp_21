{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36483d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#wget.download('http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/All_Beauty.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24eedacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5269\n",
      "As advertised. Reasonably priced\n",
      "5264\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "data = []\n",
    "with gzip.open('All_Beauty_5.json.gz') as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l.strip()).get('reviewText'))\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "print(data[0])\n",
    "\n",
    "data = [x for x in data if x!=None]\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f559d",
   "metadata": {},
   "source": [
    "В чём, собственно, проблема, о наличии которой можно подумать, увидев это высказывание -- в отзывы на конкретный продукт сам продукт можно и не упоминать"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b09feb",
   "metadata": {},
   "source": [
    "# 1. Как найти товары: способы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df9d24",
   "metadata": {},
   "source": [
    "*(3 балла) Предложите 3 способа найти упоминания товаров в отзывах. Например, использовать bootstrapping: составить шаблоны вида \"холодильник XXX\", найти все соответствующие n-граммы и выделить из них называние товара. Могут помочь заголовки и дополнительные данные с Amazon (Metadata здесь) Какие данные необходимы для каждого из способов? Какие есть достоинства/недостатки?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6a3c01",
   "metadata": {},
   "source": [
    "__1. Читать и размечать, как, например, именованные сущности. После определённого количества размеченного можно попробовать обучить модель.__\n",
    " <br>\n",
    "Плюсы: точно; не надо быть лингвистом; можно отдать на Толоку<br>\n",
    "Минусы: долго и трудозатртно; можеть быть дорого; может получиться далеко не так точно, как предполагалось, из-за несогласия разметчиков или неясности правил<br>\n",
    " <br>\n",
    "__2. Сложить всё в ворд-ту-век, надеяться на то, что упоминания товаров окажутся там в одном кластере__<br>\n",
    " <br>\n",
    "Плюсы: Если повезёт, можно сгруппировать упоминания одного товара/синонимы. Относительно быстро. Не надо привлекать людей<br>\n",
    "Минусы: Упоминания товаров часто не однословны, нужно что-то с биграммами придумывать. Или с триграммами. <br>\n",
    " <br>\n",
    "__3. Привлечь тяжёлую артиллерию, а именно млодели для извлечения именованных сущностей__<br>\n",
    " <br>\n",
    "Плюсы: Есть вероятность, что получится неплохая точность. Можно расширять список за счёт применения новых и новых идей<br>\n",
    "Минусы: сложно, получится, скорее всего, не идеально\n",
    " <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5338715",
   "metadata": {},
   "source": [
    "# Извлечение названий товаров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f336e13f",
   "metadata": {},
   "source": [
    "*(2 балла) Реализуйте один из предложенных вами способов.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c711424e",
   "metadata": {},
   "source": [
    "Ну что ж, попробуем. Посмотрим на наши данные!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[30:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508ec562",
   "metadata": {},
   "source": [
    "Здесь выделяются три типа упоминаний. <br>\n",
    "1. Никак не упоминаем продукт или называем его \"it\"\n",
    "2. this NOUN, ADJ + NOUN\n",
    "3. Собственно названия\n",
    " <br>\n",
    " \n",
    "И что же мы будем с этим делать? Ну, давайте действовать в два этапа. Даже в три. Пункт первый -- постараться извлечь именованные сущности. Пункт второй -- извлечь всё, что this + NOUN. Дальше ADJ + NOUN, но там будет много мусора"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b577275f",
   "metadata": {},
   "source": [
    "### Достаём именованные сущности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970145c2",
   "metadata": {},
   "source": [
    "Stanza очень хороша! Но при этом она работает достаточно долго. Поэтому давайте именно её запустим на небольшом датасете, подвыборке из нашего большого. Если всё закончится хорошо, можно будет запустить вторую тетрадку с тем же кодом -- но другими данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5453283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "from tqdm import tqdm\n",
    "#stanza.download('en')\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,ner')\n",
    "def stanza_result(text, nlp=nlp):\n",
    "    doc = nlp(text)\n",
    "    ent_texts = [ent.text for sent in doc.sentences for ent in sent.ents]\n",
    "    ent_types = [ent.type for sent in doc.sentences for ent in sent.ents]\n",
    "    #print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')\n",
    "    return ent_texts, ent_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f46473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_texts = [] \n",
    "ent_types = []\n",
    "for el in tqdm(data):\n",
    "    #print(i)\n",
    "    a = stanza_result(el)\n",
    "    ent_texts.extend(a[0])\n",
    "    ent_types.extend(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = []\n",
    "for i, el in enumerate(ent_types):\n",
    "    if el == 'PRODUCT':\n",
    "        products.append(i)\n",
    "        print(ent_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccecb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189182da",
   "metadata": {},
   "source": [
    "### Часть вторая"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ca4ced",
   "metadata": {},
   "source": [
    "Во-первых, stanza достатчно хороша в доставании названий продуктов. Даже очень хороша. Временами она достаёт названия фирм или компаний -- но во многих случаях это довольно логично: многие упоминания выглядят, как \"шампунь X\". А нам такое не очень нравится, наверное, потому что мы, вероятно, хотим знать, какой именно это продукт. Поэтому давайте экспериментировать с морфологией и отзывами.<br>\n",
    " <br>\n",
    "Можно сразу начать думать обо всех пунктах задания. Что нам, в общем-то, нужно? Нам нужны упоминания товаров. Желательно всех товаров, которые упоминаются в отзыве, а он там может быть не один. Чтобы такое добыть и, например, сформировать хорошие N-граммы с сущностями, по которым потом тоже можно искать, можно посмотреть на то, как наши упоминания распределяются по отзывам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df2aef",
   "metadata": {},
   "source": [
    "(1 балл) Соберите n-граммы с полученными сущностями (NE + левый сосед / NE + правый сосед)<br>\n",
    " <br>\n",
    "(3 балла) Ранжируйте n-граммы с помощью 3 коллокационных метрик (t-score, PMI и т.д.). Не забудьте про частотный фильтр / сглаживание. Выберите лучший результат (какая метрика ранжирует выше коллокации, подходящие для отчёта).<br>\n",
    " <br>\n",
    "(1 балл) Сгруппируйте полученные коллокации по NE, выведите примеры для 5 товаров. Должны получиться примерно такие группы:<br>\n",
    " <br>\n",
    "(2 балла): если придумаете способ объединить синонимичные упоминания (например, \"Samsung Galaxy Watch\", \"watch\", \"smartwatch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1605b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 21:33:50 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-12-06 21:33:50 INFO: Use device: cpu\n",
      "2021-12-06 21:33:50 INFO: Loading: tokenize\n",
      "2021-12-06 21:33:50 INFO: Loading: pos\n",
      "2021-12-06 21:33:50 INFO: Loading: lemma\n",
      "2021-12-06 21:33:50 INFO: Loading: depparse\n",
      "2021-12-06 21:33:50 INFO: Loading: ner\n",
      "2021-12-06 21:33:50 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "from tqdm import tqdm\n",
    "#stanza.download('en')\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,lemma,pos,depparse,ner', use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e878c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanza_doc(text, nlp=nlp):\n",
    "    doc = nlp(text)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68212619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanza_result(doc):\n",
    "    ent_texts = [ent.text for sent in doc.sentences for ent in sent.ents]\n",
    "    ent_types = [ent.type for sent in doc.sentences for ent in sent.ents]\n",
    "    ent_ngrams = []\n",
    "    this_list_1 = []\n",
    "    this_list_2 = []\n",
    "    one_ngram = []\n",
    "    for sent in doc.sentences:\n",
    "        #list_tokens = list(token for token in sent.tokens if token.upos != 'PUNCT')\n",
    "        list_tokens = list(token for token in sent.tokens)\n",
    "        for i, token in enumerate(list_tokens):\n",
    "            if token.words[0].lemma == 'this':\n",
    "                if i + 1 < len(list_tokens):\n",
    "                    this_list_1.append(list_tokens[i+1])\n",
    "                    if i + 2 < len(list_tokens):\n",
    "                        this_list_2.append(list_tokens[i+2])\n",
    "        #print(sent.ents)\n",
    "            if token.ner == 'B-ORG' or token.ner == 'B-PRODUCT':\n",
    "                ent_ngrams.append(one_ngram)\n",
    "                one_ngram = []\n",
    "                if i > 0:\n",
    "                    one_ngram.append(list_tokens[i-1])\n",
    "                else:\n",
    "                    one_ngram.append('START')\n",
    "                one_ngram.append(token)\n",
    "            elif token.ner == 'I-ORG' or token.ner == 'I-PRODUCT':\n",
    "                one_ngram.append(token)\n",
    "            elif token.ner == 'E-ORG' or token.ner == 'E-PRODUCT':\n",
    "                one_ngram.append(token)\n",
    "                if i + 1 < len(list_tokens):\n",
    "                    one_ngram.append(list_tokens[i+1])\n",
    "                else:\n",
    "                    one_ngram.append('END')\n",
    "            elif token.ner == 'S-ORG' or token.ner == 'S-PRODUCT':\n",
    "                ent_ngrams.append(one_ngram)\n",
    "                one_ngram = []\n",
    "                if i > 0:\n",
    "                    one_ngram.append(list_tokens[i-1])\n",
    "                else:\n",
    "                    one_ngram.append('START')\n",
    "                one_ngram.append(token)\n",
    "                if i + 1 < len(list_tokens):\n",
    "                    one_ngram.append(list_tokens[i+1])\n",
    "                else:\n",
    "                    one_ngram.append('END')\n",
    "        \n",
    "    ent_ngrams.append(one_ngram)\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    #print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')\n",
    "    return ent_texts, ent_types, ent_ngrams, this_list_1, this_list_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4bd338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5264/5264 [36:36<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "stanza_docs = []\n",
    "for text in tqdm(data):\n",
    "    stanza_docs.append(stanza_doc(text, nlp=nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc3ab8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5264/5264 [35:25<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35min 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_ent_texts = []\n",
    "all_ent_types = []\n",
    "all_ent_ngrams = []\n",
    "all_this_list_1 = []\n",
    "all_this_list_2 = []\n",
    "\n",
    "for text in tqdm(data):\n",
    "    ent_texts, ent_types, ent_ngrams, this_list_1, this_list_2 = stanza_result(stanza_doc(text, nlp=nlp))\n",
    "    all_ent_texts.append(ent_texts)\n",
    "    all_ent_types.append(ent_types)\n",
    "    all_ent_ngrams.append(ent_ngrams)\n",
    "    all_this_list_1.append(this_list_1)\n",
    "    all_this_list_2.append(this_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a7d33b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = []\n",
    "for one_doc in stanza_docs:\n",
    "    for sent in one_doc.sentences:\n",
    "        all_text.extend([word.text.lower() for word in sent.words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2855f717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e05c940c",
   "metadata": {},
   "source": [
    "## Считаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc118a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_freq(our_ngram, all_texts):\n",
    "    stops = ['START', 'END']\n",
    "    left_context = len([i for i in all_text if i == our_ngram[0] and not i in stops])\n",
    "    right_context = len([i for i in  all_text if i == our_ngram[-1] and not i in stops])\n",
    "    our_ent_freq = 0\n",
    "    our_ent = our_ngram[1:-1]\n",
    "    \n",
    "    index_first = []\n",
    "    index_second = []\n",
    "    if len(our_ent) == 1:\n",
    "        our_ent = our_ent[0]\n",
    "        for word in all_text:\n",
    "            if our_ent == word:\n",
    "                our_ent_freq += 1\n",
    "    \n",
    "    else:\n",
    "        for i, word in enumerate(all_texts):\n",
    "            if word == our_ent[0]:\n",
    "                index_first.append(i)\n",
    "                \n",
    "        for i, word in enumerate(our_ent[1:]):\n",
    "            for el in index_first:\n",
    "                if all_texts[el + i + 1] == word:\n",
    "                    index_second.append(el)\n",
    "            index_first = index_second\n",
    "            index_second = []\n",
    "        our_ent_freq = len(index_first)\n",
    "        \n",
    "    return left_context, right_context, our_ent_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7572a770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_freq_ngram(our_ngram, all_texts):\n",
    "    index_first = []\n",
    "    index_second = []    \n",
    "    for i, word in enumerate(all_texts):\n",
    "        if word == our_ngram[0]:\n",
    "            index_first.append(i)\n",
    "\n",
    "    for i, word in enumerate(our_ngram[1:]):\n",
    "        for el in index_first:\n",
    "            if all_texts[el + i + 1] == word:\n",
    "                index_second.append(el)\n",
    "        index_first = index_second\n",
    "        index_second = []\n",
    "        \n",
    "    return len(index_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12050b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_word_ngrams = []\n",
    "\n",
    "for one_text in all_ent_ngrams:\n",
    "    for one_ngram in one_text:\n",
    "        one_ngram_words = []\n",
    "        for word in one_ngram:\n",
    "            if word == 'START' or word == 'END':\n",
    "                 one_ngram_words.append(word)\n",
    "            else:\n",
    "                one_ngram_words.append(word.text)\n",
    "        if one_ngram_words != []:\n",
    "            all_word_ngrams.append(one_ngram_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72633b91",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['but', 'the', 'Williams', 'Company', 'ran'],\n",
       " ['an', 'AQUA', 'VELVA', 'MAN', '\"'],\n",
       " ['about', 'Aqua', 'Velva', 'is'],\n",
       " ['have', 'Ambergris', 'in'],\n",
       " ['in', 'Wal', '-', 'Mart', 'and'],\n",
       " ['START', 'Selenium', 'appeared'],\n",
       " ['at', 'Amazon', 'END'],\n",
       " ['an', 'Airbnb', '.'],\n",
       " ['at', 'a', 'Dave', '&', 'Buster', \"'s\", 'in'],\n",
       " ['am', 'Uber', 'pleased'],\n",
       " ['and', 'the', 'D&G', 'Lifht', 'Blue', 'is'],\n",
       " ['with', 'Uhuru', 'Naturals', 'Hair'],\n",
       " ['START', 'Google', 'the'],\n",
       " ['with', 'Northern', 'Fir', \"'s\", 'beard'],\n",
       " ['START', 'Eau', 'de', 'Hadrien', 'is'],\n",
       " ['but', 'the', 'Tangle', 'Taming', 'Conditioner', 'is'],\n",
       " ['tried', 'Kerastase', ','],\n",
       " [',', 'PHYTO', 'and'],\n",
       " ['wish', 'Redken', 'had'],\n",
       " ['with',\n",
       "  'the',\n",
       "  'Federal',\n",
       "  'Trade',\n",
       "  'Commission',\n",
       "  'Guidelines',\n",
       "  'on',\n",
       "  'Testimony',\n",
       "  'and',\n",
       "  'Advertising',\n",
       "  '.'],\n",
       " ['from', 'Sally', \"'s\", 'Beauty', 'Supply', '.'],\n",
       " ['START', 'The', 'PRELL', 'Conditioner', 'is'],\n",
       " ['through', 'Amazon', 'I'],\n",
       " ['by', 'Bain', 'De', 'Terre', 'END'],\n",
       " ['used', 'Mousse', 'products'],\n",
       " ['START', 'Wish', 'Walgreens', 'kept'],\n",
       " ['from', 'Pureology', '.'],\n",
       " ['product', 'Pantene', 'made'],\n",
       " ['START', 'Perlier', 'makes'],\n",
       " ['at', 'Big', 'Lots', 'were'],\n",
       " ['bought', 'Channel', 'No', '.', '5', 'thinking'],\n",
       " ['the', 'H20', 'shampoo'],\n",
       " ['in', 'Disney', 'World', 'END'],\n",
       " ['at', 'Disney', 'world'],\n",
       " ['START', 'HALE', 'BERRY', 'Pure', 'Orchid', 'is'],\n",
       " ['for', 'Amazon', '!'],\n",
       " ['using', 'Calibra', 'eye'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['with', 'Amazon', '.'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['for', 'my', 'Mother', 'for', 'Christmas', 'and'],\n",
       " ['using', 'Neutrogena', 'to'],\n",
       " ['from', 'Bare', 'Escentuals', '.'],\n",
       " ['from', 'Sally', 'Beauty', 'Supply', '.'],\n",
       " ['the', 'Green', 'Tea', 'cologne'],\n",
       " ['for', 'the', 'Green', 'Tea', 'Body'],\n",
       " ['for', 'Green', 'Tea', '.'],\n",
       " ['original', 'Creme', 'Perfume', 'in'],\n",
       " ['is', 'the', 'Body', 'Lotion', '.'],\n",
       " ['the', '32oz', '.'],\n",
       " ['the', 'Bare', 'Minerals', 'loose'],\n",
       " ['original',\n",
       "  'Matrix',\n",
       "  'Amplifying',\n",
       "  '/',\n",
       "  'Volumizing',\n",
       "  'System',\n",
       "  'Shampoo',\n",
       "  'with'],\n",
       " ['than', 'Matrix', \"'s\"],\n",
       " ['START', 'Matrix', 'should'],\n",
       " [',', 'Detangler', 'and'],\n",
       " ['local', 'Sally', 'Beauty', 'Supply', 'nor'],\n",
       " ['use', 'Estee', 'Lauder', 'products'],\n",
       " [',', 'Amnazon', 'is'],\n",
       " ['with', 'Estee', 'Lauder', 'foundation'],\n",
       " ['with', 'MOP', 'c-straight'],\n",
       " ['the', 'Matrix', 'conditioner'],\n",
       " ['START', 'Matrix', 'Biolage', 'Fortifying', 'conditioner'],\n",
       " ['worn', 'Chanel', '#', '5', 'since'],\n",
       " ['always', 'Bare', 'Minerals', 'never'],\n",
       " ['the', 'HBL', 'products'],\n",
       " ['the', 'HBL', 'volumizing'],\n",
       " ['and', 'Seal', '.'],\n",
       " ['using', 'the', 'Reflection', 'Chroma', 'Thermique', 'also'],\n",
       " ['used', 'Biolage', 'products'],\n",
       " ['the', 'Macallan', 'single'],\n",
       " ['again', 'Amazon', '&'],\n",
       " ['at', 'Amazon', '.'],\n",
       " ['with', 'the', 'Bvlgari', 'Conditioner', ','],\n",
       " ['the', 'Ritz-Carlton', 'in'],\n",
       " ['buy', 'Kerastase', 'Fusio-', 'Dose', 'Systeme', 'Professionnel', '.'],\n",
       " ['is', 'the', 'Sea', 'Salt', '&', 'Kelp', ';'],\n",
       " [';', 'the', 'Winter', 'Spice', 'is'],\n",
       " ['the', 'Sea', 'Salt', 'w', '/', 'Kelp', 'soap'],\n",
       " ['START', 'NARS', 'is'],\n",
       " ['by', 'NARS', 'is'],\n",
       " ['up', 'Avalon', 'Active', 'Organics', 'Vitamin'],\n",
       " ['Certified', 'Organic', 'Lavender', 'Floral', 'Water', ','],\n",
       " [',',\n",
       "  'Herbal',\n",
       "  'Infusion',\n",
       "  'of',\n",
       "  'Certified',\n",
       "  'Organic',\n",
       "  'Green',\n",
       "  'Tea',\n",
       "  ','],\n",
       " [',', 'Chamomile', ','],\n",
       " [',', 'Althea', ','],\n",
       " [',', 'Sage', ','],\n",
       " [',', 'Caprylic', '/'],\n",
       " [',', 'Shea', 'Butter', ','],\n",
       " ['Organic', 'Rosemary', 'Extract', ','],\n",
       " [',', 'Sorbitol', ','],\n",
       " [',', 'NaPCA', ','],\n",
       " ['up', 'Avalon', 'Active', 'Organics', 'Vitamin'],\n",
       " ['Certified', 'Organic', 'Lavender', 'Floral', 'Water', ','],\n",
       " [',',\n",
       "  'Herbal',\n",
       "  'Infusion',\n",
       "  'of',\n",
       "  'Certified',\n",
       "  'Organic',\n",
       "  'Green',\n",
       "  'Tea',\n",
       "  ','],\n",
       " [',', 'Chamomile', ','],\n",
       " [',', 'Althea', ','],\n",
       " [',', 'Sage', ','],\n",
       " [',', 'Caprylic', '/'],\n",
       " [',', 'Shea', 'Butter', ','],\n",
       " ['Organic', 'Rosemary', 'Extract', ','],\n",
       " [',', 'Sorbitol', ','],\n",
       " [',', 'NaPCA', ','],\n",
       " ['makes', 'Zum', 'Bars', 'a'],\n",
       " ['makes', 'Zum', 'Bars', 'a'],\n",
       " ['makes', 'Zum', 'Bars', 'a'],\n",
       " ['makes', 'Zum', 'Bars', 'a'],\n",
       " ['the', 'Spongelle', '.'],\n",
       " ['prolong', 'Spongelle', \"'s\"],\n",
       " ['see', 'P&G', 'bring'],\n",
       " ['favorite', 'Bath', 'and'],\n",
       " ['and', 'Body', 'Works', 'collection'],\n",
       " ['the', 'Amazon', 'marketplaces'],\n",
       " ['whey', 'Old', 'Spice', 'discontinued'],\n",
       " ['to', 'Amazon', 'I'],\n",
       " ['START', 'Amazon', 'fixed'],\n",
       " ['of', 'Dial', 'Soap', 'over'],\n",
       " ['I', 'Coloniali', 'product'],\n",
       " ['with', 'Acqua', 'di', 'Parma', ','],\n",
       " ['the', 'Olay', 'Age', 'Defying', 'moisturizer'],\n",
       " ['this', 'Azur', 'brand'],\n",
       " ['on', 'Amazon', ','],\n",
       " ['on', 'Amazon', 'went'],\n",
       " ['from', 'Tree', 'Hut', '.'],\n",
       " ['you', 'Amazon', 'for'],\n",
       " ['START', 'Bath', 'and'],\n",
       " ['and', 'Body', 'Works', 'quit'],\n",
       " ['on', 'Amazon', ':'],\n",
       " ['START', 'Monoi', 'Tiare', 'Tahiti', 'Coconut', 'Oil'],\n",
       " ['has', 'Tiare', 'flower'],\n",
       " ['the', 'Bath', '&', 'Body', 'Works', 'formula'],\n",
       " ['as', 'Vitamin', 'E', 'and'],\n",
       " ['the', 'B&BW', 'formula'],\n",
       " ['of', 'Dial', 'Mountain', 'Fresh', 'and'],\n",
       " ['promotes', 'Antibacterial', 'Wash', '.'],\n",
       " ['a', 'Popsugar', 'box'],\n",
       " ['START', 'Fragarant', 'is'],\n",
       " ['on', 'Amazon', 'and'],\n",
       " ['an', 'Hermes', 'product'],\n",
       " ['START', 'Henkel', 'quit'],\n",
       " ['on', 'Amazon', 'because'],\n",
       " ['the', 'Thymes', 'collection'],\n",
       " ['The', 'Azur', 'has'],\n",
       " ['(', 'TSA', 'regulations'],\n",
       " ['when', 'BedBathandBeyond', 'discontinued'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['buy', 'Moon', 'Sparkle', 'again'],\n",
       " ['a', 'Ross', 'store'],\n",
       " ['on', 'Amazon', 'but'],\n",
       " ['and', 'Amazon', 'is'],\n",
       " ['have', 'the', 'Shower', 'Gel', 'to'],\n",
       " ['the', 'Shower', 'Gel', 'fragrance'],\n",
       " ['love', 'Body', 'Shop', 'items'],\n",
       " ['from', 'Amazon', '.'],\n",
       " ['of', 'The', 'Body', 'Shop', \"'s\", 'best'],\n",
       " ['The', 'Amazon', 'price'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['on', 'Amazon.com', '.'],\n",
       " ['on', 'Amazon', ','],\n",
       " ['from', 'Whole', 'Foods', 'and'],\n",
       " ['the', 'Axe', 'line'],\n",
       " ['love',\n",
       "  'Clarins',\n",
       "  'Eau',\n",
       "  'Ensoleillante',\n",
       "  'Moisturizing',\n",
       "  'Body',\n",
       "  'Lotion',\n",
       "  '.'],\n",
       " ['that', 'Avon', 'discontinued'],\n",
       " ['the', 'Body', 'shop'],\n",
       " ['and', 'Bath', '&', 'Body', 'Works', '.'],\n",
       " ['for', 'Amazon', 'sites'],\n",
       " ['favorite', 'Bath', '&', 'Body', 'Works', 'scent'],\n",
       " ['by', 'AXE', '.'],\n",
       " ['with', 'Savannah', 'Bee', 'Mint', 'Julep', 'when'],\n",
       " ['from', 'Bath', 'and', 'Body', '.'],\n",
       " ['on', 'Amazon', 'because'],\n",
       " ['that', 'Pattern', 'Body', 'Wash', 'has'],\n",
       " ['the', 'Boots', 'products'],\n",
       " ['of', \"J'Adore\", 'lotion'],\n",
       " ['START', 'Dove', 'no'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['at', 'Bath', 'and', 'Body', 'during'],\n",
       " ['why', 'Bath', '&', 'Body', 'stopped'],\n",
       " ['find', 'Amazon', 'has'],\n",
       " ['via', 'Amazon', ','],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['until', 'Thymes', 'discontinued'],\n",
       " ['using', 'Vitamin', 'E', 'gel'],\n",
       " ['take', 'Softsoap', 'with'],\n",
       " ['of', 'Olay', \"'s\"],\n",
       " ['on', 'Amazon', 'sells'],\n",
       " ['as', 'Sephora', 'and'],\n",
       " ['my', 'FPO', 'address'],\n",
       " ['single', 'Escada', 'fragrance'],\n",
       " ['from', 'B&BW', '.'],\n",
       " ['the', 'Thymes', 'comany'],\n",
       " ['the', 'Filigree', ','],\n",
       " ['the', 'SPA', ','],\n",
       " ['using', 'BeautiControl', 'for'],\n",
       " ['of', 'Molton', 'Brown', 'products'],\n",
       " ['Reviving', 'Cempaka', 'Bath', '&', 'Shower', 'gel'],\n",
       " ['However', 'Tea', 'Tree', 'is'],\n",
       " ['purchased', 'Chanel', 'Antaeus', 'Bath', 'and'],\n",
       " ['shower', 'Gel', '.'],\n",
       " ['used', 'Bellmira', 'Herbaflor', 'Herbal', 'Baths', 'for'],\n",
       " ['by', 'Solstis', 'is'],\n",
       " ['the', 'Spongelle', '.'],\n",
       " ['prolong', 'Spongelle', \"'s\"],\n",
       " ['see', 'P&G', 'bring'],\n",
       " ['favorite', 'Bath', 'and'],\n",
       " ['and', 'Body', 'Works', 'collection'],\n",
       " ['the', 'Amazon', 'marketplaces'],\n",
       " ['whey', 'Old', 'Spice', 'discontinued'],\n",
       " ['to', 'Amazon', 'I'],\n",
       " ['START', 'Amazon', 'fixed'],\n",
       " ['of', 'Dial', 'Soap', 'over'],\n",
       " ['I', 'Coloniali', 'product'],\n",
       " ['with', 'Acqua', 'di', 'Parma', ','],\n",
       " ['the', 'Olay', 'Age', 'Defying', 'moisturizer'],\n",
       " ['this', 'Azur', 'brand'],\n",
       " ['on', 'Amazon', ','],\n",
       " ['on', 'Amazon', 'went'],\n",
       " ['from', 'Tree', 'Hut', '.'],\n",
       " ['you', 'Amazon', 'for'],\n",
       " ['START', 'Bath', 'and'],\n",
       " ['and', 'Body', 'Works', 'quit'],\n",
       " ['on', 'Amazon', ':'],\n",
       " ['START', 'Monoi', 'Tiare', 'Tahiti', 'Coconut', 'Oil'],\n",
       " ['has', 'Tiare', 'flower'],\n",
       " ['the', 'Bath', '&', 'Body', 'Works', 'formula'],\n",
       " ['as', 'Vitamin', 'E', 'and'],\n",
       " ['the', 'B&BW', 'formula'],\n",
       " ['of', 'Dial', 'Mountain', 'Fresh', 'and'],\n",
       " ['promotes', 'Antibacterial', 'Wash', '.'],\n",
       " ['a', 'Popsugar', 'box'],\n",
       " ['START', 'Fragarant', 'is'],\n",
       " ['on', 'Amazon', 'and'],\n",
       " ['an', 'Hermes', 'product'],\n",
       " ['START', 'Henkel', 'quit'],\n",
       " ['on', 'Amazon', 'because'],\n",
       " ['the', 'Thymes', 'collection'],\n",
       " ['The', 'Azur', 'has'],\n",
       " ['(', 'TSA', 'regulations'],\n",
       " ['when', 'BedBathandBeyond', 'discontinued'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['buy', 'Moon', 'Sparkle', 'again'],\n",
       " ['a', 'Ross', 'store'],\n",
       " ['on', 'Amazon', 'but'],\n",
       " ['and', 'Amazon', 'is'],\n",
       " ['have', 'the', 'Shower', 'Gel', 'to'],\n",
       " ['the', 'Shower', 'Gel', 'fragrance'],\n",
       " ['love', 'Body', 'Shop', 'items'],\n",
       " ['from', 'Amazon', '.'],\n",
       " ['of', 'The', 'Body', 'Shop', \"'s\", 'best'],\n",
       " ['The', 'Amazon', 'price'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['on', 'Amazon.com', '.'],\n",
       " ['on', 'Amazon', ','],\n",
       " ['from', 'Whole', 'Foods', 'and'],\n",
       " ['the', 'Axe', 'line'],\n",
       " ['love',\n",
       "  'Clarins',\n",
       "  'Eau',\n",
       "  'Ensoleillante',\n",
       "  'Moisturizing',\n",
       "  'Body',\n",
       "  'Lotion',\n",
       "  '.'],\n",
       " ['that', 'Avon', 'discontinued'],\n",
       " ['the', 'Body', 'shop'],\n",
       " ['and', 'Bath', '&', 'Body', 'Works', '.'],\n",
       " ['for', 'Amazon', 'sites'],\n",
       " ['favorite', 'Bath', '&', 'Body', 'Works', 'scent'],\n",
       " ['by', 'AXE', '.'],\n",
       " ['with', 'Savannah', 'Bee', 'Mint', 'Julep', 'when'],\n",
       " ['from', 'Bath', 'and', 'Body', '.'],\n",
       " ['on', 'Amazon', 'because'],\n",
       " ['that', 'Pattern', 'Body', 'Wash', 'has'],\n",
       " ['the', 'Boots', 'products'],\n",
       " ['of', \"J'Adore\", 'lotion'],\n",
       " ['START', 'Dove', 'no'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['at', 'Bath', 'and', 'Body', 'during'],\n",
       " ['why', 'Bath', '&', 'Body', 'stopped'],\n",
       " ['find', 'Amazon', 'has'],\n",
       " ['via', 'Amazon', ','],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['until', 'Thymes', 'discontinued'],\n",
       " ['using', 'Vitamin', 'E', 'gel'],\n",
       " ['take', 'Softsoap', 'with'],\n",
       " ['of', 'Olay', \"'s\"],\n",
       " ['on', 'Amazon', 'sells'],\n",
       " ['as', 'Sephora', 'and'],\n",
       " ['my', 'FPO', 'address'],\n",
       " ['single', 'Escada', 'fragrance'],\n",
       " ['from', 'B&BW', '.'],\n",
       " ['the', 'Thymes', 'comany'],\n",
       " ['the', 'Filigree', ','],\n",
       " ['the', 'SPA', ','],\n",
       " ['using', 'BeautiControl', 'for'],\n",
       " ['of', 'Molton', 'Brown', 'products'],\n",
       " ['Reviving', 'Cempaka', 'Bath', '&', 'Shower', 'gel'],\n",
       " ['However', 'Tea', 'Tree', 'is'],\n",
       " ['purchased', 'Chanel', 'Antaeus', 'Bath', 'and'],\n",
       " ['shower', 'Gel', '.'],\n",
       " ['used', 'Bellmira', 'Herbaflor', 'Herbal', 'Baths', 'for'],\n",
       " ['by', 'Solstis', 'is'],\n",
       " ['but', 'the', 'Williams', 'Company', 'ran'],\n",
       " ['an', 'AQUA', 'VELVA', 'MAN', '\"'],\n",
       " ['about', 'Aqua', 'Velva', 'is'],\n",
       " ['have', 'Ambergris', 'in'],\n",
       " ['in', 'Wal', '-', 'Mart', 'and'],\n",
       " ['the', 'Waterpik', 'does'],\n",
       " ['with', 'Oral-B', 'Superfloss', '.'],\n",
       " ['the', 'Waterpik', 'but'],\n",
       " ['the', 'Waterpik', 'away'],\n",
       " ['the', 'Waterpik', 'lasted'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['held', 'WP', '-', '450', 'model'],\n",
       " ['a', 'Sonicare', '.'],\n",
       " ['the', 'Waterpik', 'to'],\n",
       " ['with', 'Amazon', 'completed'],\n",
       " ['a', 'Waterpik', 'as'],\n",
       " ['the', 'Waterpik', 'has'],\n",
       " ['The', 'Waterpik', 'is'],\n",
       " ['a', 'Yugo', 'compared'],\n",
       " ['this', 'Lexus', 'of'],\n",
       " ['little', 'Godsend', 'also'],\n",
       " ['a', 'Waterpik', 'instead'],\n",
       " ['the', 'Waterpik', '.'],\n",
       " ['the', 'Sonicare', 'I'],\n",
       " ['a', 'Waterpik', 'because'],\n",
       " ['a', 'Waterpik', 'before'],\n",
       " ['put', 'Listerine', 'in'],\n",
       " ['the', 'Waterpik', 'at'],\n",
       " ['and', 'Listerine', 'worth'],\n",
       " ['first', 'WaterPik', 'that'],\n",
       " ['a', 'WaterPik', '.'],\n",
       " ['on', 'Amazon', 'are'],\n",
       " ['the', 'WaterPik', 'like'],\n",
       " ['past', 'WaterPik', 'units'],\n",
       " ['using', 'Listerine', '.'],\n",
       " ['of', 'Crest', 'rinse'],\n",
       " ['of', 'Crest', 'toothpaste'],\n",
       " ['of', 'Crest', \"'s\"],\n",
       " ['\"', 'Invigorating', 'Clean', 'Mint', '\"', 'mouthwash'],\n",
       " ['that', 'Crest', 'mouthwashes'],\n",
       " ['the', 'Crest', 'Pro-Health', 'mouthwashes'],\n",
       " ['other', 'Crest', 'formulas'],\n",
       " ['the', 'Scope', 'mouthwash'],\n",
       " ['this', 'Crest', 'formula'],\n",
       " ['that', 'Crest', 'did'],\n",
       " ['use', 'Yellow', '#', '5', 'food'],\n",
       " ['that', 'Crest', 'has'],\n",
       " ['used', 'Yellow', '#', '6', 'instead'],\n",
       " ['the', 'Invigorating', 'Clean', 'version'],\n",
       " ['use', 'Yellow', '#', '5', ','],\n",
       " ['3', 'Crest', 'Mouthwashes', 'in'],\n",
       " ['START', 'Crest', 'Crest', 'Pro'],\n",
       " ['to', 'Listerine', 'Total', 'Care', '.'],\n",
       " ['been', 'FDA', 'approved'],\n",
       " ['the', 'Crest', 'pro'],\n",
       " ['using', 'Norelco', 'rotary'],\n",
       " ['line', 'Norelco', 'that'],\n",
       " ['START', 'The', 'Arcitec', '1090', 'looked'],\n",
       " ['my', 'Quadra', 'Action', 'or'],\n",
       " ['or', 'SmartTouch', 'XL', 'models'],\n",
       " ['new', 'Philips', 'Norelco', 'drive-'],\n",
       " ['from', 'B&BW', '.'],\n",
       " ['the', 'Thymes', 'comany'],\n",
       " ['the', 'Filigree', ','],\n",
       " ['at', 'Amazon', '.'],\n",
       " ['with', 'the', 'Bvlgari', 'Conditioner', ','],\n",
       " ['START', 'Selenium', 'appeared'],\n",
       " ['at', 'Amazon', 'END'],\n",
       " ['an', 'Airbnb', '.'],\n",
       " ['the', 'Spongelle', '.'],\n",
       " ['prolong', 'Spongelle', \"'s\"],\n",
       " ['see', 'P&G', 'bring'],\n",
       " ['favorite', 'Bath', 'and'],\n",
       " ['and', 'Body', 'Works', 'collection'],\n",
       " ['at', 'a', 'Dave', '&', 'Buster', \"'s\", 'in'],\n",
       " ['the', 'Amazon', 'marketplaces'],\n",
       " ['am', 'Uber', 'pleased'],\n",
       " ['and', 'the', 'D&G', 'Lifht', 'Blue', 'is'],\n",
       " ['with', 'Uhuru', 'Naturals', 'Hair'],\n",
       " ['whey', 'Old', 'Spice', 'discontinued'],\n",
       " ['START', 'Google', 'the'],\n",
       " ['with', 'Northern', 'Fir', \"'s\", 'beard'],\n",
       " ['START', 'Eau', 'de', 'Hadrien', 'is'],\n",
       " ['but', 'the', 'Tangle', 'Taming', 'Conditioner', 'is'],\n",
       " ['to', 'Amazon', 'I'],\n",
       " ['START', 'Amazon', 'fixed'],\n",
       " ['of', 'Dial', 'Soap', 'over'],\n",
       " ['tried', 'Kerastase', ','],\n",
       " [',', 'PHYTO', 'and'],\n",
       " ['I', 'Coloniali', 'product'],\n",
       " ['with', 'Acqua', 'di', 'Parma', ','],\n",
       " ['Thanks', 'Amazon', 'for'],\n",
       " ['the', 'Olay', 'Age', 'Defying', 'moisturizer'],\n",
       " ['wish', 'Redken', 'had'],\n",
       " ['with',\n",
       "  'the',\n",
       "  'Federal',\n",
       "  'Trade',\n",
       "  'Commission',\n",
       "  'Guidelines',\n",
       "  'on',\n",
       "  'Testimony',\n",
       "  'and',\n",
       "  'Advertising',\n",
       "  '.'],\n",
       " ['from', 'Sally', \"'s\", 'Beauty', 'Supply', '.'],\n",
       " ['this', 'Azur', 'brand'],\n",
       " ['START', 'The', 'PRELL', 'Conditioner', 'is'],\n",
       " ['on', 'Amazon', ','],\n",
       " ['on', 'Amazon', 'went'],\n",
       " ['from', 'Tree', 'Hut', '.'],\n",
       " ['through', 'Amazon', 'I'],\n",
       " ['by', 'Bain', 'De', 'Terre', 'END'],\n",
       " ['used', 'Mousse', 'products'],\n",
       " ['START', 'Wish', 'Walgreens', 'kept'],\n",
       " ['you', 'Amazon', 'for'],\n",
       " ['from', 'Pureology', '.'],\n",
       " ['product', 'Pantene', 'made'],\n",
       " ['START', 'Bath', 'and'],\n",
       " ['and', 'Body', 'Works', 'quit'],\n",
       " ['on', 'Amazon', ':'],\n",
       " ['START', 'Monoi', 'Tiare', 'Tahiti', 'Coconut', 'Oil'],\n",
       " ['has', 'Tiare', 'flower'],\n",
       " ['the', 'Bath', '&', 'Body', 'Works', 'formula'],\n",
       " ['as', 'Vitamin', 'E', 'and'],\n",
       " ['the', 'B&BW', 'formula'],\n",
       " ['START', 'Perlier', 'makes'],\n",
       " ['at', 'Big', 'Lots', 'were'],\n",
       " ['of', 'Dial', 'Mountain', 'Fresh', 'and'],\n",
       " ['promotes', 'Antibacterial', 'Wash', '.'],\n",
       " ['bought', 'Channel', 'No', '.', '5', 'thinking'],\n",
       " ['the', 'H20', 'shampoo'],\n",
       " ['in', 'Disney', 'World', 'END'],\n",
       " ['at', 'Disney', 'world'],\n",
       " ['START', 'HALE', 'BERRY', 'Pure', 'Orchid', 'is'],\n",
       " ['for', 'Amazon', '!'],\n",
       " ['a', 'Popsugar', 'box'],\n",
       " ['using', 'Calibra', 'eye'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['with', 'Amazon', '.'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['START', 'Fragarant', 'is'],\n",
       " ['for', 'my', 'Mother', 'for', 'Christmas', 'and'],\n",
       " ['using', 'Neutrogena', 'to'],\n",
       " ['on', 'Amazon', 'and'],\n",
       " ['from', 'Bare', 'Escentuals', '.'],\n",
       " ['an', 'Hermes', 'product'],\n",
       " ['START', 'Henkel', 'quit'],\n",
       " ['on', 'Amazon', 'because'],\n",
       " ['the', 'Thymes', 'collection'],\n",
       " ['The', 'Azur', 'has'],\n",
       " ['from', 'Sally', 'Beauty', 'Supply', '.'],\n",
       " ['the', 'Green', 'Tea', 'cologne'],\n",
       " ['for', 'the', 'Green', 'Tea', 'Body'],\n",
       " ['for', 'Green', 'Tea', '.'],\n",
       " ['original', 'Creme', 'Perfume', 'in'],\n",
       " ['is', 'the', 'Body', 'Lotion', '.'],\n",
       " ['(', 'TSA', 'regulations'],\n",
       " ['the', '32oz', '.'],\n",
       " ['when', 'BedBathandBeyond', 'discontinued'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['buy', 'Moon', 'Sparkle', 'again'],\n",
       " ['a', 'Ross', 'store'],\n",
       " ['on', 'Amazon', 'but'],\n",
       " ['and', 'Amazon', 'is'],\n",
       " ['have', 'the', 'Shower', 'Gel', 'to'],\n",
       " ['the', 'Shower', 'Gel', 'fragrance'],\n",
       " ['love', 'Body', 'Shop', 'items'],\n",
       " ['from', 'Amazon', '.'],\n",
       " ['the', 'Bare', 'Minerals', 'loose'],\n",
       " ['of', 'The', 'Body', 'Shop', \"'s\", 'best'],\n",
       " ['original',\n",
       "  'Matrix',\n",
       "  'Amplifying',\n",
       "  '/',\n",
       "  'Volumizing',\n",
       "  'System',\n",
       "  'Shampoo',\n",
       "  'with'],\n",
       " ['than', 'Matrix', \"'s\"],\n",
       " ['START', 'Matrix', 'should'],\n",
       " ['The', 'Amazon', 'price'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['on', 'Amazon.com', '.'],\n",
       " ['on', 'Amazon', ','],\n",
       " [',', 'Detangler', 'and'],\n",
       " ['local', 'Sally', 'Beauty', 'Supply', 'nor'],\n",
       " ['use', 'Estee', 'Lauder', 'products'],\n",
       " [',', 'Amnazon', 'is'],\n",
       " ['from', 'Whole', 'Foods', 'and'],\n",
       " ['the', 'Axe', 'line'],\n",
       " ['love',\n",
       "  'Clarins',\n",
       "  'Eau',\n",
       "  'Ensoleillante',\n",
       "  'Moisturizing',\n",
       "  'Body',\n",
       "  'Lotion',\n",
       "  '.'],\n",
       " ['that', 'Avon', 'discontinued'],\n",
       " ['the', 'Body', 'shop'],\n",
       " ['and', 'Bath', '&', 'Body', 'Works', '.'],\n",
       " ['for', 'Amazon', 'sites'],\n",
       " ['favorite', 'Bath', '&', 'Body', 'Works', 'scent'],\n",
       " ['with', 'Estee', 'Lauder', 'foundation'],\n",
       " ['with', 'MOP', 'c-straight'],\n",
       " ['the', 'Matrix', 'conditioner'],\n",
       " ['by', 'AXE', '.'],\n",
       " ['START', 'Matrix', 'Biolage', 'Fortifying', 'conditioner'],\n",
       " ['with', 'Savannah', 'Bee', 'Mint', 'Julep', 'when'],\n",
       " ['from', 'Bath', 'and', 'Body', '.'],\n",
       " ['on', 'Amazon', 'because'],\n",
       " ['that', 'Pattern', 'Body', 'Wash', 'has'],\n",
       " ['worn', 'Chanel', '#', '5', 'since'],\n",
       " ['the', 'Boots', 'products'],\n",
       " ['of', \"J'Adore\", 'lotion'],\n",
       " ['always', 'Bare', 'Minerals', 'never'],\n",
       " ['START', 'Dove', 'no'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['at', 'Bath', 'and', 'Body', 'during'],\n",
       " ['why', 'Bath', '&', 'Body', 'stopped'],\n",
       " ['find', 'Amazon', 'has'],\n",
       " ['via', 'Amazon', ','],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['until', 'Thymes', 'discontinued'],\n",
       " ['the', 'HBL', 'products'],\n",
       " ['the', 'HBL', 'volumizing'],\n",
       " ['and', 'Seal', '.'],\n",
       " ['using', 'Vitamin', 'E', 'gel'],\n",
       " ['using', 'the', 'Reflection', 'Chroma', 'Thermique', 'also'],\n",
       " ['take', 'Softsoap', 'with'],\n",
       " ['of', 'Olay', \"'s\"],\n",
       " ['on', 'Amazon', 'sells'],\n",
       " ['used', 'Biolage', 'products'],\n",
       " ['as', 'Sephora', 'and'],\n",
       " ['my', 'FPO', 'address'],\n",
       " ['single', 'Escada', 'fragrance'],\n",
       " ['the', 'Macallan', 'single'],\n",
       " ['again', 'Amazon', '&'],\n",
       " ['my', 'Sonicare', 'does'],\n",
       " ['a', 'Sonicare', 'toothbrush'],\n",
       " ['(', 'Oral', '-', 'B-', 'FlexiSoft', 'and'],\n",
       " ['and', 'FlossAction', 'and'],\n",
       " ['most', 'Sonicare', 'models'],\n",
       " ['the', 'Sanitizer', '.'],\n",
       " ['an', 'Essie', 'product'],\n",
       " ['with', 'FTC', 'regulations'],\n",
       " [',', 'Womens', '.'],\n",
       " ['from', 'Urban', 'Spa', '.'],\n",
       " ['gave', 'the', 'Urban', 'Spa', 'Loofah', 'a'],\n",
       " ['START', 'The', 'Urban', 'Spa', 'Microfiber', 'Bath', 'Pillow', 'makes'],\n",
       " ['since', 'Amazon', 'has'],\n",
       " ['a', 'QC', 'issue'],\n",
       " ['START', 'Urban', 'Spa', 'Get'],\n",
       " ['a', 'Grip', 'Trio', 'Manicure', 'and'],\n",
       " ['START', 'Avalon', 'Organics', 'has'],\n",
       " [',', 'Stearic', 'Acid', ','],\n",
       " [',', 'Myristic', 'Acid', ','],\n",
       " [',', 'Squalane', ','],\n",
       " [',', 'Glycerin', ','],\n",
       " [',', 'Potassium', 'Hydroxide', ','],\n",
       " [',', 'Organic', 'Coconut', 'Oil', ','],\n",
       " [',', 'Glycol', 'Distearate', ','],\n",
       " [',', 'Fragrance', ','],\n",
       " [',',\n",
       "  'Organic',\n",
       "  'Jojoba',\n",
       "  'Seed',\n",
       "  'Oil',\n",
       "  ',',\n",
       "  'Organic',\n",
       "  'Pomegranate',\n",
       "  'Oil',\n",
       "  ',',\n",
       "  'Organic',\n",
       "  'Green',\n",
       "  'Tea',\n",
       "  'Leaf',\n",
       "  'Extract',\n",
       "  ',',\n",
       "  'Organic',\n",
       "  'Shea',\n",
       "  'Butter',\n",
       "  'Fruit',\n",
       "  ','],\n",
       " [',', 'Phenoxyethanol', ','],\n",
       " [',', 'Tetrahydroxypropyl', 'Ethylenediamine', ','],\n",
       " [',', 'Ethylhexyl', '('],\n",
       " ['(', 'Octyl', ')', 'Palmitate', ','],\n",
       " [',', 'Ethylhexylglycerin', ','],\n",
       " [',', 'Tocopherol', ','],\n",
       " [',', 'Limonene', '.'],\n",
       " ['used', 'Bellmira', 'Herbaflor', 'Herbal', 'Baths', 'for'],\n",
       " ['START', 'Selenium', 'appeared'],\n",
       " ['at', 'Amazon', 'END'],\n",
       " ['an', 'Airbnb', '.'],\n",
       " ['the', 'Spongelle', '.'],\n",
       " ['prolong', 'Spongelle', \"'s\"],\n",
       " ['see', 'P&G', 'bring'],\n",
       " ['favorite', 'Bath', 'and'],\n",
       " ['and', 'Body', 'Works', 'collection'],\n",
       " ['at', 'a', 'Dave', '&', 'Buster', \"'s\", 'in'],\n",
       " ['the', 'Amazon', 'marketplaces'],\n",
       " ['am', 'Uber', 'pleased'],\n",
       " ['and', 'the', 'D&G', 'Lifht', 'Blue', 'is'],\n",
       " ['with', 'Uhuru', 'Naturals', 'Hair'],\n",
       " ['whey', 'Old', 'Spice', 'discontinued'],\n",
       " ['START', 'Google', 'the'],\n",
       " ['with', 'Northern', 'Fir', \"'s\", 'beard'],\n",
       " ['START', 'Eau', 'de', 'Hadrien', 'is'],\n",
       " ['but', 'the', 'Tangle', 'Taming', 'Conditioner', 'is'],\n",
       " ['to', 'Amazon', 'I'],\n",
       " ['START', 'Amazon', 'fixed'],\n",
       " ['of', 'Dial', 'Soap', 'over'],\n",
       " ['tried', 'Kerastase', ','],\n",
       " [',', 'PHYTO', 'and'],\n",
       " ['I', 'Coloniali', 'product'],\n",
       " ['with', 'Acqua', 'di', 'Parma', ','],\n",
       " ['Thanks', 'Amazon', 'for'],\n",
       " ['the', 'Olay', 'Age', 'Defying', 'moisturizer'],\n",
       " ['wish', 'Redken', 'had'],\n",
       " ['with',\n",
       "  'the',\n",
       "  'Federal',\n",
       "  'Trade',\n",
       "  'Commission',\n",
       "  'Guidelines',\n",
       "  'on',\n",
       "  'Testimony',\n",
       "  'and',\n",
       "  'Advertising',\n",
       "  '.'],\n",
       " ['from', 'Sally', \"'s\", 'Beauty', 'Supply', '.'],\n",
       " ['this', 'Azur', 'brand'],\n",
       " ['START', 'The', 'PRELL', 'Conditioner', 'is'],\n",
       " ['on', 'Amazon', ','],\n",
       " ['on', 'Amazon', 'went'],\n",
       " ['from', 'Tree', 'Hut', '.'],\n",
       " ['through', 'Amazon', 'I'],\n",
       " ['by', 'Bain', 'De', 'Terre', 'END'],\n",
       " ['used', 'Mousse', 'products'],\n",
       " ['START', 'Wish', 'Walgreens', 'kept'],\n",
       " ['you', 'Amazon', 'for'],\n",
       " ['from', 'Pureology', '.'],\n",
       " ['product', 'Pantene', 'made'],\n",
       " ['START', 'Bath', 'and'],\n",
       " ['and', 'Body', 'Works', 'quit'],\n",
       " ['on', 'Amazon', ':'],\n",
       " ['START', 'Monoi', 'Tiare', 'Tahiti', 'Coconut', 'Oil'],\n",
       " ['has', 'Tiare', 'flower'],\n",
       " ['the', 'Bath', '&', 'Body', 'Works', 'formula'],\n",
       " ['as', 'Vitamin', 'E', 'and'],\n",
       " ['the', 'B&BW', 'formula'],\n",
       " ['START', 'Perlier', 'makes'],\n",
       " ['at', 'Big', 'Lots', 'were'],\n",
       " ['of', 'Dial', 'Mountain', 'Fresh', 'and'],\n",
       " ['promotes', 'Antibacterial', 'Wash', '.'],\n",
       " ['bought', 'Channel', 'No', '.', '5', 'thinking'],\n",
       " ['the', 'H20', 'shampoo'],\n",
       " ['in', 'Disney', 'World', 'END'],\n",
       " ['at', 'Disney', 'world'],\n",
       " ['START', 'HALE', 'BERRY', 'Pure', 'Orchid', 'is'],\n",
       " ['for', 'Amazon', '!'],\n",
       " ['a', 'Popsugar', 'box'],\n",
       " ['using', 'Calibra', 'eye'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['with', 'Amazon', '.'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['START', 'Fragarant', 'is'],\n",
       " ['for', 'my', 'Mother', 'for', 'Christmas', 'and'],\n",
       " ['using', 'Neutrogena', 'to'],\n",
       " ['on', 'Amazon', 'and'],\n",
       " ['from', 'Bare', 'Escentuals', '.'],\n",
       " ['an', 'Hermes', 'product'],\n",
       " ['START', 'Henkel', 'quit'],\n",
       " ['on', 'Amazon', 'because'],\n",
       " ['the', 'Thymes', 'collection'],\n",
       " ['The', 'Azur', 'has'],\n",
       " ['from', 'Sally', 'Beauty', 'Supply', '.'],\n",
       " ['the', 'Green', 'Tea', 'cologne'],\n",
       " ['for', 'the', 'Green', 'Tea', 'Body'],\n",
       " ['for', 'Green', 'Tea', '.'],\n",
       " ['original', 'Creme', 'Perfume', 'in'],\n",
       " ['is', 'the', 'Body', 'Lotion', '.'],\n",
       " ['(', 'TSA', 'regulations'],\n",
       " ['the', '32oz', '.'],\n",
       " ['when', 'BedBathandBeyond', 'discontinued'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['buy', 'Moon', 'Sparkle', 'again'],\n",
       " ['a', 'Ross', 'store'],\n",
       " ['on', 'Amazon', 'but'],\n",
       " ['and', 'Amazon', 'is'],\n",
       " ['have', 'the', 'Shower', 'Gel', 'to'],\n",
       " ['the', 'Shower', 'Gel', 'fragrance'],\n",
       " ['love', 'Body', 'Shop', 'items'],\n",
       " ['from', 'Amazon', '.'],\n",
       " ['the', 'Bare', 'Minerals', 'loose'],\n",
       " ['of', 'The', 'Body', 'Shop', \"'s\", 'best'],\n",
       " ['original',\n",
       "  'Matrix',\n",
       "  'Amplifying',\n",
       "  '/',\n",
       "  'Volumizing',\n",
       "  'System',\n",
       "  'Shampoo',\n",
       "  'with'],\n",
       " ['than', 'Matrix', \"'s\"],\n",
       " ['START', 'Matrix', 'should'],\n",
       " ['The', 'Amazon', 'price'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['on', 'Amazon.com', '.'],\n",
       " ['on', 'Amazon', ','],\n",
       " [',', 'Detangler', 'and'],\n",
       " ['local', 'Sally', 'Beauty', 'Supply', 'nor'],\n",
       " ['use', 'Estee', 'Lauder', 'products'],\n",
       " [',', 'Amnazon', 'is'],\n",
       " ['from', 'Whole', 'Foods', 'and'],\n",
       " ['the', 'Axe', 'line'],\n",
       " ['love',\n",
       "  'Clarins',\n",
       "  'Eau',\n",
       "  'Ensoleillante',\n",
       "  'Moisturizing',\n",
       "  'Body',\n",
       "  'Lotion',\n",
       "  '.'],\n",
       " ['that', 'Avon', 'discontinued'],\n",
       " ['the', 'Body', 'shop'],\n",
       " ['and', 'Bath', '&', 'Body', 'Works', '.'],\n",
       " ['for', 'Amazon', 'sites'],\n",
       " ['favorite', 'Bath', '&', 'Body', 'Works', 'scent'],\n",
       " ['with', 'Estee', 'Lauder', 'foundation'],\n",
       " ['with', 'MOP', 'c-straight'],\n",
       " ['the', 'Matrix', 'conditioner'],\n",
       " ['by', 'AXE', '.'],\n",
       " ['START', 'Matrix', 'Biolage', 'Fortifying', 'conditioner'],\n",
       " ['with', 'Savannah', 'Bee', 'Mint', 'Julep', 'when'],\n",
       " ['from', 'Bath', 'and', 'Body', '.'],\n",
       " ['on', 'Amazon', 'because'],\n",
       " ['that', 'Pattern', 'Body', 'Wash', 'has'],\n",
       " ['worn', 'Chanel', '#', '5', 'since'],\n",
       " ['the', 'Boots', 'products'],\n",
       " ['of', \"J'Adore\", 'lotion'],\n",
       " ['always', 'Bare', 'Minerals', 'never'],\n",
       " ['START', 'Dove', 'no'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['at', 'Bath', 'and', 'Body', 'during'],\n",
       " ['why', 'Bath', '&', 'Body', 'stopped'],\n",
       " ['find', 'Amazon', 'has'],\n",
       " ['via', 'Amazon', ','],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['until', 'Thymes', 'discontinued'],\n",
       " ['the', 'HBL', 'products'],\n",
       " ['the', 'HBL', 'volumizing'],\n",
       " ['and', 'Seal', '.'],\n",
       " ['using', 'Vitamin', 'E', 'gel'],\n",
       " ['using', 'the', 'Reflection', 'Chroma', 'Thermique', 'also'],\n",
       " ['take', 'Softsoap', 'with'],\n",
       " ['of', 'Olay', \"'s\"],\n",
       " ['on', 'Amazon', 'sells'],\n",
       " ['used', 'Biolage', 'products'],\n",
       " ['as', 'Sephora', 'and'],\n",
       " ['my', 'FPO', 'address'],\n",
       " ['single', 'Escada', 'fragrance'],\n",
       " ['the', 'Macallan', 'single'],\n",
       " ['again', 'Amazon', '&'],\n",
       " ['from', 'B&BW', '.'],\n",
       " ['the', 'Thymes', 'comany'],\n",
       " ['the', 'Filigree', ','],\n",
       " ['at', 'Amazon', '.'],\n",
       " ['with', 'the', 'Bvlgari', 'Conditioner', ','],\n",
       " ['the', 'Ritz-Carlton', 'in'],\n",
       " ['buy', 'Kerastase', 'Fusio-', 'Dose', 'Systeme', 'Professionnel', '.'],\n",
       " ['the', 'SPA', ','],\n",
       " ['using', 'BeautiControl', 'for'],\n",
       " ['of', 'Molton', 'Brown', 'products'],\n",
       " ['Reviving', 'Cempaka', 'Bath', '&', 'Shower', 'gel'],\n",
       " ['However', 'Tea', 'Tree', 'is'],\n",
       " ['purchased', 'Chanel', 'Antaeus', 'Bath', 'and'],\n",
       " ['shower', 'Gel', '.'],\n",
       " ['is', 'the', 'Sea', 'Salt', '&', 'Kelp', ';'],\n",
       " [';', 'the', 'Winter', 'Spice', 'is'],\n",
       " ['the', 'Sea', 'Salt', 'w', '/', 'Kelp', 'soap'],\n",
       " ['buy', 'Kerastase', 'Fusio-', 'Dose', 'Systeme', 'Professionnel', '.'],\n",
       " ['the', 'SPA', ','],\n",
       " ['using', 'BeautiControl', 'for'],\n",
       " ['of', 'Molton', 'Brown', 'products'],\n",
       " ['Reviving', 'Cempaka', 'Bath', '&', 'Shower', 'gel'],\n",
       " ['However', 'Tea', 'Tree', 'is'],\n",
       " ['purchased', 'Chanel', 'Antaeus', 'Bath', 'and'],\n",
       " ['shower', 'Gel', '.'],\n",
       " ['is', 'the', 'Sea', 'Salt', '&', 'Kelp', ';'],\n",
       " [';', 'the', 'Winter', 'Spice', 'is'],\n",
       " ['the', 'Sea', 'Salt', 'w', '/', 'Kelp', 'soap'],\n",
       " ['used', 'Bellmira', 'Herbaflor', 'Herbal', 'Baths', 'for'],\n",
       " [',', 'Combe', 'Inc', '.'],\n",
       " ['keep', 'the', 'Lectric', 'Shave', '.'],\n",
       " ['added', 'Lectric', 'Shave', 'with'],\n",
       " ['to', 'Amazon', '.'],\n",
       " ['used', 'Lectric', 'Shave', 'for'],\n",
       " ['for', 'Lectric', 'Shave', '.'],\n",
       " ['used', 'Lectric', 'Shave', 'on'],\n",
       " ['1973', 'Mark', '4', 'Remington', ','],\n",
       " ['store', \"Norelco's\", ','],\n",
       " ['horrible', 'Sunbeam', 'and'],\n",
       " ['a', 'Braun', '320s'],\n",
       " ['Braun', '320s', '-', '4', '('],\n",
       " ['ms-3/4700', 'Remington', 'micro'],\n",
       " ['razor', 'Rem', 'ever'],\n",
       " ['a', 'Military', 'base'],\n",
       " ['And', 'the', 'Axe', 'Detailer', 'Shower', 'Tool', 'is'],\n",
       " ['end', 'the', 'Ax', 'Shower', 'Tool', 'does'],\n",
       " ['an', 'Essie', 'product'],\n",
       " ['with', 'FTC', 'regulations'],\n",
       " [',', 'Womens', '.'],\n",
       " ['from', 'Urban', 'Spa', '.'],\n",
       " ['gave', 'the', 'Urban', 'Spa', 'Loofah', 'a'],\n",
       " ['START', 'The', 'Urban', 'Spa', 'Microfiber', 'Bath', 'Pillow', 'makes'],\n",
       " ['since', 'Amazon', 'has'],\n",
       " ['a', 'QC', 'issue'],\n",
       " ['START', 'Urban', 'Spa', 'Get'],\n",
       " ['a', 'Grip', 'Trio', 'Manicure', 'and'],\n",
       " ['START', 'Avalon', 'Organics', 'has'],\n",
       " [',', 'Stearic', 'Acid', ','],\n",
       " [',', 'Myristic', 'Acid', ','],\n",
       " [',', 'Squalane', ','],\n",
       " [',', 'Glycerin', ','],\n",
       " [',', 'Potassium', 'Hydroxide', ','],\n",
       " [',', 'Organic', 'Coconut', 'Oil', ','],\n",
       " [',', 'Glycol', 'Distearate', ','],\n",
       " [',', 'Fragrance', ','],\n",
       " [',',\n",
       "  'Organic',\n",
       "  'Jojoba',\n",
       "  'Seed',\n",
       "  'Oil',\n",
       "  ',',\n",
       "  'Organic',\n",
       "  'Pomegranate',\n",
       "  'Oil',\n",
       "  ',',\n",
       "  'Organic',\n",
       "  'Green',\n",
       "  'Tea',\n",
       "  'Leaf',\n",
       "  'Extract',\n",
       "  ',',\n",
       "  'Organic',\n",
       "  'Shea',\n",
       "  'Butter',\n",
       "  'Fruit',\n",
       "  ','],\n",
       " [',', 'Phenoxyethanol', ','],\n",
       " [',', 'Tetrahydroxypropyl', 'Ethylenediamine', ','],\n",
       " [',', 'Ethylhexyl', '('],\n",
       " ['(', 'Octyl', ')', 'Palmitate', ','],\n",
       " [',', 'Ethylhexylglycerin', ','],\n",
       " [',', 'Tocopherol', ','],\n",
       " [',', 'Limonene', '.'],\n",
       " ['used', 'Bellmira', 'Herbaflor', 'Herbal', 'Baths', 'for'],\n",
       " ['START', 'Selenium', 'appeared'],\n",
       " ['at', 'Amazon', 'END'],\n",
       " ['an', 'Airbnb', '.'],\n",
       " ['the', 'Spongelle', '.'],\n",
       " ['prolong', 'Spongelle', \"'s\"],\n",
       " ['see', 'P&G', 'bring'],\n",
       " ['favorite', 'Bath', 'and'],\n",
       " ['and', 'Body', 'Works', 'collection'],\n",
       " ['at', 'a', 'Dave', '&', 'Buster', \"'s\", 'in'],\n",
       " ['the', 'Amazon', 'marketplaces'],\n",
       " ['am', 'Uber', 'pleased'],\n",
       " ['and', 'the', 'D&G', 'Lifht', 'Blue', 'is'],\n",
       " ['with', 'Uhuru', 'Naturals', 'Hair'],\n",
       " ['whey', 'Old', 'Spice', 'discontinued'],\n",
       " ['START', 'Google', 'the'],\n",
       " ['with', 'Northern', 'Fir', \"'s\", 'beard'],\n",
       " ['START', 'Eau', 'de', 'Hadrien', 'is'],\n",
       " ['but', 'the', 'Tangle', 'Taming', 'Conditioner', 'is'],\n",
       " ['to', 'Amazon', 'I'],\n",
       " ['START', 'Amazon', 'fixed'],\n",
       " ['of', 'Dial', 'Soap', 'over'],\n",
       " ['tried', 'Kerastase', ','],\n",
       " [',', 'PHYTO', 'and'],\n",
       " ['I', 'Coloniali', 'product'],\n",
       " ['with', 'Acqua', 'di', 'Parma', ','],\n",
       " ['Thanks', 'Amazon', 'for'],\n",
       " ['the', 'Olay', 'Age', 'Defying', 'moisturizer'],\n",
       " ['wish', 'Redken', 'had'],\n",
       " ['with',\n",
       "  'the',\n",
       "  'Federal',\n",
       "  'Trade',\n",
       "  'Commission',\n",
       "  'Guidelines',\n",
       "  'on',\n",
       "  'Testimony',\n",
       "  'and',\n",
       "  'Advertising',\n",
       "  '.'],\n",
       " ['from', 'Sally', \"'s\", 'Beauty', 'Supply', '.'],\n",
       " ['this', 'Azur', 'brand'],\n",
       " ['START', 'The', 'PRELL', 'Conditioner', 'is'],\n",
       " ['on', 'Amazon', ','],\n",
       " ['on', 'Amazon', 'went'],\n",
       " ['from', 'Tree', 'Hut', '.'],\n",
       " ['through', 'Amazon', 'I'],\n",
       " ['by', 'Bain', 'De', 'Terre', 'END'],\n",
       " ['used', 'Mousse', 'products'],\n",
       " ['START', 'Wish', 'Walgreens', 'kept'],\n",
       " ['you', 'Amazon', 'for'],\n",
       " ['from', 'Pureology', '.'],\n",
       " ['product', 'Pantene', 'made'],\n",
       " ['START', 'Bath', 'and'],\n",
       " ['and', 'Body', 'Works', 'quit'],\n",
       " ['on', 'Amazon', ':'],\n",
       " ['START', 'Monoi', 'Tiare', 'Tahiti', 'Coconut', 'Oil'],\n",
       " ['has', 'Tiare', 'flower'],\n",
       " ['the', 'Bath', '&', 'Body', 'Works', 'formula'],\n",
       " ['as', 'Vitamin', 'E', 'and'],\n",
       " ['the', 'B&BW', 'formula'],\n",
       " ['START', 'Perlier', 'makes'],\n",
       " ['at', 'Big', 'Lots', 'were'],\n",
       " ['of', 'Dial', 'Mountain', 'Fresh', 'and'],\n",
       " ['promotes', 'Antibacterial', 'Wash', '.'],\n",
       " ['bought', 'Channel', 'No', '.', '5', 'thinking'],\n",
       " ['the', 'H20', 'shampoo'],\n",
       " ['in', 'Disney', 'World', 'END'],\n",
       " ['at', 'Disney', 'world'],\n",
       " ['START', 'HALE', 'BERRY', 'Pure', 'Orchid', 'is'],\n",
       " ['for', 'Amazon', '!'],\n",
       " ['a', 'Popsugar', 'box'],\n",
       " ['using', 'Calibra', 'eye'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['with', 'Amazon', '.'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['START', 'Fragarant', 'is'],\n",
       " ['for', 'my', 'Mother', 'for', 'Christmas', 'and'],\n",
       " ['using', 'Neutrogena', 'to'],\n",
       " ['on', 'Amazon', 'and'],\n",
       " ['from', 'Bare', 'Escentuals', '.'],\n",
       " ['an', 'Hermes', 'product'],\n",
       " ['START', 'Henkel', 'quit'],\n",
       " ['on', 'Amazon', 'because'],\n",
       " ['the', 'Thymes', 'collection'],\n",
       " ['The', 'Azur', 'has'],\n",
       " ['from', 'Sally', 'Beauty', 'Supply', '.'],\n",
       " ['the', 'Green', 'Tea', 'cologne'],\n",
       " ['for', 'the', 'Green', 'Tea', 'Body'],\n",
       " ['for', 'Green', 'Tea', '.'],\n",
       " ['original', 'Creme', 'Perfume', 'in'],\n",
       " ['is', 'the', 'Body', 'Lotion', '.'],\n",
       " ['(', 'TSA', 'regulations'],\n",
       " ['the', '32oz', '.'],\n",
       " ['when', 'BedBathandBeyond', 'discontinued'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['buy', 'Moon', 'Sparkle', 'again'],\n",
       " ['a', 'Ross', 'store'],\n",
       " ['on', 'Amazon', 'but'],\n",
       " ['and', 'Amazon', 'is'],\n",
       " ['have', 'the', 'Shower', 'Gel', 'to'],\n",
       " ['the', 'Shower', 'Gel', 'fragrance'],\n",
       " ['love', 'Body', 'Shop', 'items'],\n",
       " ['from', 'Amazon', '.'],\n",
       " ['the', 'Bare', 'Minerals', 'loose'],\n",
       " ['of', 'The', 'Body', 'Shop', \"'s\", 'best'],\n",
       " ['original',\n",
       "  'Matrix',\n",
       "  'Amplifying',\n",
       "  '/',\n",
       "  'Volumizing',\n",
       "  'System',\n",
       "  'Shampoo',\n",
       "  'with'],\n",
       " ['than', 'Matrix', \"'s\"],\n",
       " ['START', 'Matrix', 'should'],\n",
       " ['The', 'Amazon', 'price'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['on', 'Amazon.com', '.'],\n",
       " ['on', 'Amazon', ','],\n",
       " [',', 'Detangler', 'and'],\n",
       " ['local', 'Sally', 'Beauty', 'Supply', 'nor'],\n",
       " ['use', 'Estee', 'Lauder', 'products'],\n",
       " [',', 'Amnazon', 'is'],\n",
       " ['from', 'Whole', 'Foods', 'and'],\n",
       " ['the', 'Axe', 'line'],\n",
       " ['love',\n",
       "  'Clarins',\n",
       "  'Eau',\n",
       "  'Ensoleillante',\n",
       "  'Moisturizing',\n",
       "  'Body',\n",
       "  'Lotion',\n",
       "  '.'],\n",
       " ['that', 'Avon', 'discontinued'],\n",
       " ['the', 'Body', 'shop'],\n",
       " ['and', 'Bath', '&', 'Body', 'Works', '.'],\n",
       " ['for', 'Amazon', 'sites'],\n",
       " ['favorite', 'Bath', '&', 'Body', 'Works', 'scent'],\n",
       " ['with', 'Estee', 'Lauder', 'foundation'],\n",
       " ['with', 'MOP', 'c-straight'],\n",
       " ['the', 'Matrix', 'conditioner'],\n",
       " ['by', 'AXE', '.'],\n",
       " ['START', 'Matrix', 'Biolage', 'Fortifying', 'conditioner'],\n",
       " ['with', 'Savannah', 'Bee', 'Mint', 'Julep', 'when'],\n",
       " ['from', 'Bath', 'and', 'Body', '.'],\n",
       " ['on', 'Amazon', 'because'],\n",
       " ['that', 'Pattern', 'Body', 'Wash', 'has'],\n",
       " ['worn', 'Chanel', '#', '5', 'since'],\n",
       " ['the', 'Boots', 'products'],\n",
       " ['of', \"J'Adore\", 'lotion'],\n",
       " ['always', 'Bare', 'Minerals', 'never'],\n",
       " ['START', 'Dove', 'no'],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['at', 'Bath', 'and', 'Body', 'during'],\n",
       " ['why', 'Bath', '&', 'Body', 'stopped'],\n",
       " ['find', 'Amazon', 'has'],\n",
       " ['via', 'Amazon', ','],\n",
       " ['on', 'Amazon', '.'],\n",
       " ['until', 'Thymes', 'discontinued'],\n",
       " ['the', 'HBL', 'products'],\n",
       " ['the', 'HBL', 'volumizing'],\n",
       " ['and', 'Seal', '.'],\n",
       " ['using', 'Vitamin', 'E', 'gel'],\n",
       " ['using', 'the', 'Reflection', 'Chroma', 'Thermique', 'also'],\n",
       " ['take', 'Softsoap', 'with'],\n",
       " ['of', 'Olay', \"'s\"],\n",
       " ['on', 'Amazon', 'sells'],\n",
       " ['used', 'Biolage', 'products'],\n",
       " ['as', 'Sephora', 'and'],\n",
       " ['my', 'FPO', 'address'],\n",
       " ['single', 'Escada', 'fragrance'],\n",
       " ['the', 'Macallan', 'single'],\n",
       " ['again', 'Amazon', '&'],\n",
       " ['from', 'B&BW', '.'],\n",
       " ['the', 'Thymes', 'comany'],\n",
       " ['the', 'Filigree', ','],\n",
       " ['at', 'Amazon', '.'],\n",
       " ['with', 'the', 'Bvlgari', 'Conditioner', ','],\n",
       " ['the', 'Ritz-Carlton', 'in'],\n",
       " ['buy', 'Kerastase', 'Fusio-', 'Dose', 'Systeme', 'Professionnel', '.'],\n",
       " ['the', 'SPA', ','],\n",
       " ['using', 'BeautiControl', 'for'],\n",
       " ['of', 'Molton', 'Brown', 'products'],\n",
       " ['Reviving', 'Cempaka', 'Bath', '&', 'Shower', 'gel'],\n",
       " ['However', 'Tea', 'Tree', 'is'],\n",
       " ['purchased', 'Chanel', 'Antaeus', 'Bath', 'and'],\n",
       " ['shower', 'Gel', '.'],\n",
       " ['is', 'the', 'Sea', 'Salt', '&', 'Kelp', ';'],\n",
       " [';', 'the', 'Winter', 'Spice', 'is'],\n",
       " ['the', 'Sea', 'Salt', 'w', '/', 'Kelp', 'soap'],\n",
       " ['buy', 'Kerastase', 'Fusio-', 'Dose', 'Systeme', 'Professionnel', '.'],\n",
       " ['the', 'SPA', ','],\n",
       " ['using', 'BeautiControl', 'for'],\n",
       " ['of', 'Molton', 'Brown', 'products'],\n",
       " ['Reviving', 'Cempaka', 'Bath', '&', 'Shower', 'gel'],\n",
       " ['However', 'Tea', 'Tree', 'is'],\n",
       " ['purchased', 'Chanel', 'Antaeus', 'Bath', 'and'],\n",
       " ['shower', 'Gel', '.'],\n",
       " ['is', 'the', 'Sea', 'Salt', '&', 'Kelp', ';'],\n",
       " [';', 'the', 'Winter', 'Spice', 'is'],\n",
       " ['the', 'Sea', 'Salt', 'w', '/', 'Kelp', 'soap'],\n",
       " ['used', 'Bellmira', 'Herbaflor', 'Herbal', 'Baths', 'for'],\n",
       " [',', 'Combe', 'Inc', '.'],\n",
       " ['keep', 'the', 'Lectric', 'Shave', '.'],\n",
       " ['added', 'Lectric', 'Shave', 'with'],\n",
       " ['to', 'Amazon', '.'],\n",
       " ['used', 'Lectric', 'Shave', 'for'],\n",
       " ['for', 'Lectric', 'Shave', '.'],\n",
       " ['used', 'Lectric', 'Shave', 'on'],\n",
       " ['1973', 'Mark', '4', 'Remington', ','],\n",
       " ['store', \"Norelco's\", ','],\n",
       " ['horrible', 'Sunbeam', 'and'],\n",
       " ['a', 'Braun', '320s'],\n",
       " ['Braun', '320s', '-', '4', '('],\n",
       " ['ms-3/4700', 'Remington', 'micro'],\n",
       " ['razor', 'Rem', 'ever'],\n",
       " ['a', 'Military', 'base'],\n",
       " ['And', 'the', 'Axe', 'Detailer', 'Shower', 'Tool', 'is'],\n",
       " ['end', 'the', 'Ax', 'Shower', 'Tool', 'does'],\n",
       " ['got', 'this', 'Clean', '&', 'Clear', 'Cleanser', 'to'],\n",
       " ['START', 'Clean', '&', 'Clear', 'sure'],\n",
       " ['use', 'Crest', 'but'],\n",
       " ['like', 'Colgate', 'better'],\n",
       " ['of', 'the', 'Colgate', 'Kids', 'Maximum', 'Cavity', 'Protection', '.'],\n",
       " [',', 'Cellulose', 'Gum', ','],\n",
       " [',', 'Sodium', 'Lauryl', 'Sulfate', ','],\n",
       " [',', 'Flavor', ','],\n",
       " [',', 'Titanium', 'Dioxide', ','],\n",
       " [',', 'FD&C', 'Blue'],\n",
       " ['this', 'Colgate', 'Maximum', 'Cavity', 'Protection', 'toothpaste'],\n",
       " ['use', 'Colgate', 'Kids', 'toothpaste'],\n",
       " ['START', 'Colgate', 'is'],\n",
       " ['use', 'Optic', 'White', '.'],\n",
       " ['for', 'Maximum', 'Cavity', 'Protection', 'for'],\n",
       " ['like', 'Colgate', 'Optic', 'White', ')'],\n",
       " ['the', 'Colgate', 'pumps'],\n",
       " ['of', 'Colgate', 'Maximum', 'Cavity', 'Protection', 'in'],\n",
       " ['of', 'Glide', 'and'],\n",
       " ['using', 'Glide', 'floss'],\n",
       " ['original', 'Glide', '('],\n",
       " ['a', \"Sam's\", 'Club', 'member'],\n",
       " ['original', 'Glide', '.'],\n",
       " ['try', 'Glide', 'Comfort', 'Plus', 'Unflavored', 'next'],\n",
       " ['how', 'Amazon', 'throws'],\n",
       " ['love', 'Pre', 'de', 'Provence', 'soaps'],\n",
       " ['one', 'Pre', 'de', 'Provence', 'product'],\n",
       " ['the', 'Pre', 'de', 'Provence', 'spray'],\n",
       " ['START',\n",
       "  'The',\n",
       "  'Pre',\n",
       "  'De',\n",
       "  'Provence',\n",
       "  'Maison',\n",
       "  'French',\n",
       "  'Lavender',\n",
       "  'Blossom',\n",
       "  'Linen',\n",
       "  'END'],\n",
       " [',', 'Maison', 'has'],\n",
       " ['and', 'Methylchloroisothiazolinone', '('],\n",
       " ['and', 'FD&C', 'Blue', '1', 'and'],\n",
       " ['and', 'Red', '33', ','],\n",
       " ['the', 'Pre', 'De', 'Provence', 'product'],\n",
       " ['START', 'This', 'Lavender', 'Blossom', 'Water', 'is'],\n",
       " ['reviewing', 'the', 'Bath', 'Salts', '.'],\n",
       " ['START', 'Pre', 'De', 'Provence', 'Maison', 'French', 'Lavender', 'bath'],\n",
       " ['START', 'Selenium', 'appeared'],\n",
       " ['at', 'Amazon', 'END'],\n",
       " ...]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_word_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6472e8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fbc8cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_metrics(our_ngram, all_text):\n",
    "    freq_of_bigram = count_freq_ngram(our_ngram, all_text)\n",
    "    left_context, center, right_context = count_freq(our_ngram, all_text)\n",
    "    num_bigrams = len(all_text)/2\n",
    "    #print(freq_of_bigram)\n",
    "    if freq_of_bigram != 0 and left_context != 0 and right_context != 0 and center != 0:\n",
    "        t_score_left = (freq_of_bigram - (left_context * center)/num_bigrams)/(freq_of_bigram**(1/2))\n",
    "        t_score_right = (freq_of_bigram - (right_context * center)/num_bigrams)/(freq_of_bigram**(1/2))\n",
    "        dice_left = (2*freq_of_bigram)/(left_context + center)\n",
    "        dice_right = (2*freq_of_bigram)/(right_context + center)\n",
    "        pmi_left = math.log2(freq_of_bigram / (left_context * center))\n",
    "        pmi_right = math.log2(freq_of_bigram / (right_context * center))\n",
    "        \n",
    "    else:\n",
    "        t_score_left, t_score_right, dice_left, dice_right, pmi_left, pmi_right = [0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    return t_score_left, t_score_right, dice_left, dice_right, pmi_left, pmi_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2dca8632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1454/1454 [01:03<00:00, 22.86it/s]\n"
     ]
    }
   ],
   "source": [
    "t_scores_left, t_scores_right, dices_left, dices_right, pmis_left, pmis_right = [], [], [], [], [], []\n",
    "\n",
    "for ngram in tqdm(all_word_ngrams):\n",
    "    ngram = [word.lower() for word in ngram]\n",
    "    t_score_left, t_score_right, dice_left, dice_right, pmi_left, pmi_right = count_metrics(ngram, all_text)\n",
    "    t_scores_left.append(t_score_left)\n",
    "    t_scores_right.append(t_score_right)\n",
    "    dices_left.append(dice_left)\n",
    "    dices_right.append(dice_right)\n",
    "    pmis_left.append(pmi_left)\n",
    "    pmis_right.append(pmi_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40e25bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'Sanitizer', '.']\n",
      "['the', 'Sonicare', '.']\n",
      "['the', 'Sonicare', '.']\n",
      "[',', 'Womens', '.']\n",
      "[',', 'Womens', '.']\n",
      "[',', 'Limonene', '.']\n",
      "[',', 'Limonene', '.']\n",
      "['to', 'Sensodyne', '.']\n",
      "['to', 'Listerine', 'Total', 'Care', '.']\n",
      "['the', 'Aquaphor', ',']\n",
      "['the', 'Sensodyne', ',']\n",
      "['the', 'Clinique', ',']\n",
      "['the', 'Waterpik', '.']\n",
      "['the', 'Waterpik', '.']\n",
      "[',', 'Combe', 'Inc', '.']\n",
      "[',', 'Combe', 'Inc', '.']\n",
      "[',', 'Combe', 'Inc', '.']\n",
      "['my', 'Sonicare', '.']\n",
      "['a', 'WaterPik', '.']\n",
      "['a', 'Sonicare', '.']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.argsort(t_scores_left)[:20]\n",
    "for i in a:\n",
    "    print(all_word_ngrams[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2238208a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', 'Fragrance', ',']\n",
      "[',', 'Fragrance', ',']\n",
      "['to', 'Amazon', '.']\n",
      "['to', 'Amazon', '.']\n",
      "['to', 'Amazon', '.']\n",
      "['from', 'Amazon', ',']\n",
      "['by', 'Pre', 'de', 'Provence', '.']\n",
      "['with', 'Amazon', '.']\n",
      "['from', 'Amazon', '.']\n",
      "['from', 'Amazon', '.']\n",
      "['at', 'Amazon', '.']\n",
      "['from', 'Amazon', '.']\n",
      "['at', 'Amazon', '.']\n",
      "['at', 'Amazon', '.']\n",
      "['with', 'Amazon', '.']\n",
      "['with', 'Amazon', '.']\n",
      "['with', 'Amazon', '.']\n",
      "['at', 'Amazon', '.']\n",
      "['with', 'Amazon', '.']\n",
      "['at', 'Amazon', '.']\n"
     ]
    }
   ],
   "source": [
    "a = np.argsort(t_scores_right)[:20]\n",
    "for i in a:\n",
    "    print(all_word_ngrams[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3fd45887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['START', 'Dove', 'no']\n",
      "['START', 'Crest', 'Crest', 'Pro']\n",
      "['START', 'Eau', 'de', 'Hadrien', 'is']\n",
      "['START', 'Amazon', 'fixed']\n",
      "['START', 'Fragarant', 'is']\n",
      "['START', 'Colgate', 'Enamel', 'Health', 'Anticavity', 'Fluoride', 'Sparkling', 'Fresh', 'Mint', 'Mouthwash', 'is']\n",
      "['START', 'Henkel', 'quit']\n",
      "['START', 'Dove', 'was']\n",
      "['START', 'Colgate', 'claims']\n",
      "['START', 'Henkel', 'quit']\n",
      "['START', 'Colgate', 'Enamel', 'Health', 'Anticavity', 'Fluoride', 'Sparkling', 'Fresh', 'Mint', 'Mouthwash', 'is']\n",
      "['START', 'Pre', 'de', 'Provence', 'Soap', ',']\n",
      "['START', 'Pre', 'de', 'Provence', 'soaps']\n",
      "['START', 'Weleda', 'has']\n",
      "['START', 'Pre', 'de', 'Provence', 'has']\n",
      "['START', 'Pre', 'de', 'Provence', 'does']\n",
      "['START', 'Dove', 'no']\n",
      "['START', 'Apple', 'Pear']\n",
      "['START', 'The', 'Arcitec', '1090', 'looked']\n",
      "['START', 'Apple', 'Pear']\n"
     ]
    }
   ],
   "source": [
    "a = np.argsort(dices_left)[:20]\n",
    "for i in a:\n",
    "    print(all_word_ngrams[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "804154dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['START', 'Avalon', 'Organics', 'has']\n",
      "['START', 'Henkel', 'quit']\n",
      "['START', 'Crest', 'Crest', 'Pro']\n",
      "['START', 'Urban', 'Spa', 'Get']\n",
      "['START', 'The', 'Urban', 'Spa', 'Microfiber', 'Bath', 'Pillow', 'makes']\n",
      "['START', 'Wish', 'Walgreens', 'kept']\n",
      "['START', 'Perlier', 'makes']\n",
      "['START', 'This', 'Lavender', 'Blossom', 'Water', 'is']\n",
      "['START', 'Matrix', 'should']\n",
      "['START', 'Fragarant', 'is']\n",
      "['START', 'Crest', 'certainly']\n",
      "['START', 'Pre', 'de', 'Provence', 'Shea', 'Butter', 'Enriched']\n",
      "['START', 'The', 'Pre', 'De', 'Provence', 'Maison', 'French', 'Lavender', 'Blossom', 'Linen', 'END']\n",
      "['START', 'Matrix', 'Biolage', 'Fortifying', 'conditioner']\n",
      "['START', 'Amazon', 'fixed']\n",
      "['START', 'Dove', 'no']\n",
      "['START', 'Fekkai', 'does']\n",
      "['START', 'Dove', 'no']\n",
      "['in', 'Disney', 'World', 'END']\n",
      "['by', 'Bain', 'De', 'Terre', 'END']\n"
     ]
    }
   ],
   "source": [
    "a = np.argsort(dices_right)[:20]\n",
    "for i in a:\n",
    "    print(all_word_ngrams[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "65212c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'Sanitizer', '.']\n",
      "['to', 'Sensodyne', '.']\n",
      "['to', 'Listerine', 'Total', 'Care', '.']\n",
      "['the', 'Sensodyne', ',']\n",
      "['the', 'Aquaphor', ',']\n",
      "['the', 'Clinique', ',']\n",
      "['the', 'Sonicare', '.']\n",
      "['the', 'Sonicare', '.']\n",
      "['my', 'Sonicare', '.']\n",
      "[',', 'Tocopheryl', 'Acetate', ',']\n",
      "[',', 'Cinnamomum', 'Cassia', 'Leaf', 'Oil', ',']\n",
      "[',', 'Lavender', 'Oil', ',']\n",
      "[',', 'Soybean', 'Oil', ',']\n",
      "[',', 'Pectin', ',']\n",
      "[',', 'Ceteareth', '-', '20', ',']\n",
      "[',', 'Potassium', 'Sorbate', ',']\n",
      "[',', 'Dehydroxanthan', 'Gum', ',']\n",
      "[',', 'Orange', 'Oil', ',']\n",
      "[',', 'Pogostemon', 'Cablin', 'Oil', ',']\n",
      "[',', 'Bergamot', 'Fruit', 'Oil', ',']\n"
     ]
    }
   ],
   "source": [
    "a = np.argsort(pmis_left)[:20]\n",
    "for i in a:\n",
    "    print(all_word_ngrams[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c6dc4231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'Amazon', ',']\n",
      "['by', 'Pre', 'de', 'Provence', '.']\n",
      "[',', 'Fragrance', ',']\n",
      "[',', 'Fragrance', ',']\n",
      "['to', 'Amazon', '.']\n",
      "['to', 'Amazon', '.']\n",
      "['to', 'Amazon', '.']\n",
      "['from', 'Pre', 'de', 'Provence', 'and']\n",
      "['with', 'Amazon', '.']\n",
      "['from', 'Amazon', '.']\n",
      "['at', 'Amazon', '.']\n",
      "['with', 'Amazon', '.']\n",
      "['at', 'Amazon', '.']\n",
      "['at', 'Amazon', '.']\n",
      "['with', 'Amazon', '.']\n",
      "['with', 'Amazon', '.']\n",
      "['at', 'Amazon', '.']\n",
      "['from', 'Amazon', '.']\n",
      "['from', 'Amazon', '.']\n",
      "['with', 'Amazon', '.']\n"
     ]
    }
   ],
   "source": [
    "a = np.argsort(pmis_right)[:20]\n",
    "for i in a:\n",
    "    print(all_word_ngrams[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f7d1ae",
   "metadata": {},
   "source": [
    "Метрика DICE с правым контекстом больше всех похожа на правду. А ещё стоило избавиться от всей пунктуации, перезапустив тетрадку, но я заметила, что это не та тетрадка, слишклм поздно"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c75abdd",
   "metadata": {},
   "source": [
    "## Выводим тип продуктов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "10304b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shampoo\n",
      "____________________\n",
      "['the', 'H20', 'shampoo']\n",
      "['the', 'H20', 'shampoo']\n",
      "['the', 'H20', 'shampoo']\n",
      "['the', 'H20', 'shampoo']\n",
      "['the', 'H20', 'shampoo']\n",
      "['This', 'Volume', 'Conditioner', 'shampoo']\n",
      "conditioner\n",
      "____________________\n",
      "['the', 'Matrix', 'conditioner']\n",
      "['START', 'Matrix', 'Biolage', 'Fortifying', 'conditioner']\n",
      "['the', 'Matrix', 'conditioner']\n",
      "['START', 'Matrix', 'Biolage', 'Fortifying', 'conditioner']\n",
      "['the', 'Matrix', 'conditioner']\n",
      "['START', 'Matrix', 'Biolage', 'Fortifying', 'conditioner']\n",
      "['the', 'Matrix', 'conditioner']\n",
      "['START', 'Matrix', 'Biolage', 'Fortifying', 'conditioner']\n",
      "['the', 'Matrix', 'conditioner']\n",
      "['START', 'Matrix', 'Biolage', 'Fortifying', 'conditioner']\n",
      "soap\n",
      "____________________\n",
      "['the', 'Sea', 'Salt', 'w', '/', 'Kelp', 'soap']\n",
      "['the', 'Sea', 'Salt', 'w', '/', 'Kelp', 'soap']\n",
      "['the', 'Sea', 'Salt', 'w', '/', 'Kelp', 'soap']\n",
      "['the', 'Sea', 'Salt', 'w', '/', 'Kelp', 'soap']\n",
      "['the', 'Sea', 'Salt', 'w', '/', 'Kelp', 'soap']\n",
      "['the', 'Sea', 'Salt', 'w', '/', 'Kelp', 'soap']\n",
      "['of', 'Plantlife', 'Sandalwood', 'soap']\n",
      "['safer', 'Pre', 'de', 'Provence', 'soap']\n",
      "['sudzing', 'Girley', 'soap']\n",
      "['fourth', 'Pre', 'de', 'Provence', 'soap']\n",
      "['basic', 'Ivory', 'soap']\n",
      "['scented', 'Shea', 'Butter', 'soap']\n",
      "butter\n",
      "____________________\n",
      "['The', 'Pre', 'De', 'Provence', 'Shea', 'butter']\n",
      "['with', 'Shea', 'butter']\n",
      "['has', 'Shea', 'butter']\n",
      "oil\n",
      "____________________\n",
      "['made', 'Patchouli', 'oil']\n",
      "['this', 'Olive', 'oil', '&', 'Lavender', 'bar']\n"
     ]
    }
   ],
   "source": [
    "for word in ['shampoo', 'conditioner', 'soap', 'butter', 'oil']:\n",
    "    print(word)\n",
    "    print('____________________')\n",
    "    for ngram in all_word_ngrams:\n",
    "        ngram_new = [el.lower() for el in ngram]\n",
    "        if word in ngram:\n",
    "            print(ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3d6018",
   "metadata": {},
   "source": [
    "У нас полуичилось найти упоминания. Это хорошо. Объёмный препроцессинг надо бы перезапустить -- это плохо. Но тем не менее, мы посчитали метрики и мы нашли упоминания в текстах вместе с n-граммами. Это тоже хорошо. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422f10b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e41ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
